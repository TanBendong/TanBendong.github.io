{"pages":[{"title":"404","text":"/* don't remove. */ .about-cover { height: 75vh; } 404 // 每天切换 banner 图. Switch banner image every day. $('.bg-cover').css('background-image', 'url(/medias/banner/' + new Date().getDay() + '.jpg)');","link":"/404/index.html"},{"title":"","text":"关于我基本信息姓名：谭本东 Email：2013302540270@whu.edu.cn 简介：我只是个想认识世界的小菜鸡，前途漫漫，不忘初心，牢记使命！这个过程中希望能喝最烈的威士忌、日最野的哈士奇、做最难的Research！这个中文博客无关科研，但会掺杂一些技术杂文，个人科研博客请移步：Bendong Tan。 教育经历 电气工程及其自动化学士学位（2013-2017） 武汉大学电气工程学院 电力系统及其自动化硕士学位（2017-2020） 武汉大学电气与自动化学院 研究方向 数据挖掘在电力系统中的应用研究，目前关注基于机器学习的电力系统暂态稳定评估 电力系统稳定与控制 兴趣 运动：乒乓球除了兴趣比较高，其他技术水平都比较低； 影视：香港黄金时代80s-90s的港片，朱茵、周星驰、周润发这些人的电影百看不厌；金庸作品，值得拥有； 读书：金庸、古龙小说，历史、社科、专业书籍 编程：MATLAB、PYTHON，略懂C语言 书法：硬笔田英章老师、毛笔颜真卿，入门选手 欢迎留言有朋自远方来，不亦乐乎！不论技术或是兴趣，如果有什么建议和想法，都可以在知乎中私信，欢迎交流！","link":"/about/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"2018年研二计划","text":"您好！这篇博文需要密码，输入正确密码后回车即可阅读。 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","link":"/2018/09/07/2018%E5%B9%B4%E7%A0%94%E4%BA%8C%E8%AE%A1%E5%88%92/"},{"title":"2020年总结","text":"首页摘要： 2020年是不平凡的一年，大部分时间是居家工作生活，不过这也给了我难得的思考时间。相比往年，感觉2020年做了更多的事情，读了更多的书，可能是梁静茹给我的错觉（大雾）。 完成了一些论文 成功写完毕业论文和答辩； 发表了第二篇SCI论文； 发表了第三篇中文期刊论文； 写完了博士第一篇英文综述，对博士研究对象有了一个比较清晰的认识； 读了一些书 《家庭、私有制和国家的起源》：对婚姻家庭的本质有了初步的认识； 《凸优化》： 凸优化入门； 《 Reinforcement Learning》：强化学习及深度强化学习入门； 《被讨厌的勇气》： 学会和这个世界和解，也学会接纳了自己； 《Power System Stability and Control (Kundur)》、《电力系统分析》、《电机学》：加深了对同步电机的理解； 《枪炮、病菌和钢铁》：对人类社会的发展规律有了新的认识； 《君主论》 ：看的第一本厚黑学； 《爱你就像爱生命》：表示憧憬王小波那种精神上势均力敌的爱情，这本书读了一遍还想再读几遍，太美了。 学会了一些技能 第一次坚持练硬笔书法超过160天，完整练完一本硬笔楷书字帖 后记2020年还剩下四分之一，争取在这有限的时间里，能够做一些对自己而言有趣而有意义的事情。","link":"/2020/09/06/2020%E5%B9%B4%E6%80%BB%E7%BB%93/"},{"title":"A Novel Temporal Feature Selection for  Time-Adaptive Transient Stabiity Assessment","text":"首页摘要： ISGT Europe 2019 于2019年9月底在罗马尼亚首都举办，简单总结了一篇论文投稿。主要内容是针对自适应电力系统暂态稳定评估提出了一种时间序列特征选择方法，仿真结果表明能够在保持评估精度的前提下有效减少训练时间以及降低平均评估时间。 以下为主要实现代码（1）特征重要性计算程序（MATLAB)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336function [ranked,weight] = relieff_tan(X,Y,K,varargin)% 计算多维时间序列的特征重要性% X为输入特征，格式为N*n*T，其中N为样本数目，n为特征维数，T为时间商都% Y为类别标签if nargin&lt;3 error(message('stats:relieff:TooFewInputs'));end% 检查X数据格式是否正确if ~isnumeric(X) error(message('stats:relieff:BadX'));end% Parse input argumentsvalidArgs = {'method' 'prior' 'updates' 'categoricalx' 'sigma'};defaults = { '' [] 'all' 'off' []};% Get optional args[method,prior,numUpdates,categoricalX,sigma] ... = internal.stats.parseArgs(validArgs,defaults,varargin{:});[X,Y] = removeNaNs(X,Y); % Group Y for classification. Get class counts and probabilities.% Get groups and matrix of class countsif isa(Y,'categorical') Y = removecats(Y);end[Y,grp] = grp2idx(Y);[X,Y] = removeNaNs(X,Y);Ngrp = numel(grp); % 两类就是2个，有几类就有几个N = size(X,1);C = false(N,Ngrp);C(sub2ind([N Ngrp],(1:N)',Y)) = true;% Get class probsif isempty(prior) || strcmpi(prior,'empirical') classProb = sum(C,1);elseif strcmpi(prior,'uniform') classProb = ones(1,Ngrp);elseif isstruct(prior) if ~isfield(prior,'group') || ~isfield(prior,'prob') error(message('stats:relieff:PriorWithMissingField')); end if iscell(prior.group) usrgrp = prior.group; else usrgrp = cellstr(prior.group); end [tf,pos] = ismember(grp,usrgrp); if any(~tf) error(message('stats:relieff:PriorWithClassNotFound', grp{ find( ~tf, 1 ) })); end classProb = prior.prob(pos);elseif isnumeric(prior) if ~isfloat(prior) || length(prior)~=Ngrp || any(prior&lt;0) || all(prior==0) error(message('stats:relieff:BadNumericPrior', Ngrp)); end classProb = prior;else error(message('stats:relieff:BadPrior'));end % Normalize class probs classProb = classProb/sum(classProb); % If there are classes with zero probs, remove them zeroprob = classProb==0; if any(zeroprob) t = zeroprob(Y); if sum(t)==length(Y) error(message('stats:relieff:ZeroWeightPrior')); end Y(t) = []; X(t,:) = []; C(t,:) = []; C(:,zeroprob) = []; classProb(zeroprob) = []; end% Do we have enough observations?if length(Y)&lt;2 error(message('stats:relieff:NotEnoughObs'));end% Check the number of nearest neighborsif ~isnumeric(K) || ~isscalar(K) || K&lt;=0 error(message('stats:relieff:BadK'));endK = ceil(K);% 检查迭代数目if (~ischar(numUpdates) || ~strcmpi(numUpdates,'all')) &amp;&amp; ... (~isnumeric(numUpdates) || ~isscalar(numUpdates) || numUpdates&lt;=0) error(message('stats:relieff:BadNumUpdates'));endif ischar(numUpdates) numUpdates = size(X,1);else numUpdates = ceil(numUpdates);end% Check the type of Xif ~ischar(categoricalX) || ... (~strcmpi(categoricalX,'on') &amp;&amp; ~strcmpi(categoricalX,'off')) error(message('stats:relieff:BadCategoricalX'));endcategoricalX = strcmpi(categoricalX,'on');% Check sigmaif ~isempty(sigma) &amp;&amp; ... (~isnumeric(sigma) || ~isscalar(sigma) || sigma&lt;=0) error(message('stats:relieff:BadSigma'));endif isempty(sigma) sigma = Inf;end% The # updates cannot be more than the # observationsnumUpdates = min(numUpdates, size(X,1));% Choose the distance function depending upon the categoricalXif ~categoricalX distFcn = 'cityblock';end% Find max and min for every predictorp = size(X,2); % 样本数目Xmax = max(X,[],[1 3]); % 时间序列每个特征值的最大值Xmin = min(X,[],[1 3]);% 时间序列每个特征值的最小值Xdiff = Xmax-Xmin;% Exclude single-valued attributesisOneValue = Xdiff &lt; eps(Xmax); % eps是一个函数，可以返回某一个数N的最小浮点数精度if all(isOneValue) ranked = 1:p; weight = NaN(1,p); return;endX(:,isOneValue) = [];Xdiff(isOneValue) = [];rejected = find(isOneValue);accepted = find(~isOneValue);% 标准化if ~categoricalX X = bsxfun(@rdivide,bsxfun(@minus,X,mean(X,[1,3])),Xdiff); % (X-X_mean)/(Xmax-Xmin)标准化end% Get appropriate distance function in one dimension.% thisx must be a row-vector for one observation.% x can have more than one row.if ~categoricalX dist1D = @(thisx,x) cityblock(thisx,x);end% Call ReliefF. By default all weights are set to NaN.weight = NaN(1,p);weight(accepted) = RelieffClass(X,C,classProb,numUpdates,K,distFcn,dist1D,sigma);% Assign ranks to attributes[~,sorted] = sort(weight(accepted),'descend');ranked = accepted(sorted);ranked(end+1:p) = rejected;% -------------------------------------------------------------------------function attrWeights = RelieffClass(scaledX,C,classProb,numUpdates,K,... distFcn,dist1D,sigma)% ReliefF for classification[numObs,numAttr,Time] = size(scaledX);attrWeights = zeros(1,numAttr);Nlev = size(C,2);% Choose the random instancesrndIdx = randsample(numObs,numUpdates);idxVec = (1:numObs)';% Make searcher objects, one object per class. searchers = cell(Nlev,1);for c=1:Nlev searchers{c} = createns(scaledX(C(:,c),:),'Distance',distFcn); % 这里要进行修改，构建kdtreeend% Outer loop, for updating attribute weights iterativelyfor i = 1:numUpdates thisObs = rndIdx(i); % Choose the correct random observation selectedX = scaledX(thisObs,:,:); % Find the class for this observation thisC = C(thisObs,:); % Find the k-nearest hits sameClassIdx = idxVec(C(:,thisC)); sameClassX=scaledX(sameClassIdx,:,:); % we may not always find numNeighbor Hits lenHits = min(length(sameClassIdx)-1,K); % find nearest hits % It is not guaranteed that the first hit is the same as thisObs. Since % they have the same class, it does not matter. If we add observation % weights in the future, we will need here something similar to what we % do in ReliefReg. Hits = []; if lenHits&gt;0 SameDistance=[]; for i =1:length(sameClassIdx) distance=sqrt(sum(sum((selectedX-sameClassX(i,:,:)).^2))); SameDistance=[SameDistance,distance]; end [B,IS]=sort(SameDistance); idxH = IS(1:K); % 这里要进行修改 idxH(1) = []; Hits = sameClassIdx(idxH); end % Process misses missClass = find(~thisC); Misses = []; if ~isempty(missClass) % Make sure there are misses! % Find the k-nearest misses Misses(C,:) for each class C ~= class(selectedX) % Misses will be of size (no. of classes -1)x(K) Misses = zeros(Nlev-1,min(numObs,K+1)); % last column has class index for mi = 1:length(missClass) % find all observations of this miss class missClassIdx = idxVec(C(:,missClass(mi))); missClassX=scaledX(missClassIdx,:,:); % we may not always find K misses lenMiss = min(length(missClassIdx),K); % find nearest misses MissDistance=[]; for i =1:length(missClassIdx) distance=sqrt(sum(sum((selectedX-missClassX(i,:,:)).^2))); MissDistance=[MissDistance,distance]; end [B,IM]=sort(MissDistance); idxM =IM(1:K); % 这里要进行修改 Misses(mi,1:lenMiss) = missClassIdx(idxM); end % Misses contains obs indices for miss classes, sorted by dist. Misses(:,end) = missClass; end %***************** ATTRIBUTE UPDATE ***************************** % Inner loop to update weights for each attribute: for j = 1:numAttr dH = diffH(j,scaledX,thisObs,Hits,dist1D,sigma)/numUpdates; dM = diffM(j,scaledX,thisObs,Misses,dist1D,sigma,classProb)/numUpdates; attrWeights(j) = attrWeights(j) - dH + dM; end %****************************************************************end%Helper functions RelieffClass%--------------------------------------------------------------------------% DIFFH (for RelieffClass): Function to calculate difference measure% for an attribute between the selected instance and its hitsfunction distMeas = diffH(a,X,thisObs,Hits,dist1D,sigma)% If no hits, return zero by defaultif isempty(Hits) distMeas = 0; return;end% Get distance weightsdistWts = exp(-((1:length(Hits))/sigma).^2)';distWts = distWts/sum(distWts);% Calculate weighted sum of distancesdistMeas = sum(dist1D(X(thisObs,a,:),X(Hits,a,:)).*distWts);%--------------------------------------------------------------------------% DIFFM (for RelieffClass) : Function to calculate difference measure% for an attribute between the selected instance and its missesfunction distMeas = diffM(a,X,thisObs,Misses,dist1D,sigma,classProb)distMeas = 0;% If no misses, return zeroif isempty(Misses) return;end% Loop over missesfor mi = 1:size(Misses,1) ismiss = Misses(mi,1:end-1)~=0; if any(ismiss) cls = Misses(mi,end); nmiss = sum(ismiss); distWts = exp(-((1:nmiss)/sigma).^2)'; distWts = distWts/sum(distWts); distMeas = distMeas + ... sum(dist1D(X(thisObs,a,:),X(Misses(mi,ismiss),a,:)).*distWts(1:nmiss)) ... *classProb(cls); endend% Normalize class probabilities.% This is equivalent to P(C)/(1-P(class(R))) in ReliefF paper.totProb = sum(classProb(Misses(:,end)));distMeas = distMeas/totProb;function [X,Y] = removeNaNs(X,Y)% Remove observations with missing dataNaNidx = bsxfun(@or,isnan(Y),any(isnan(X),2));X(NaNidx,:) = [];Y(NaNidx,:) = [];function d = cityblock(thisX,X)d = sqrt(sum((thisX-X).^2,[2,3])); （2）电力系统暂态自适应评估程序（PYTHON）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155# ----------------------------------------------------# Description: Class for DynamicLSTM Network# Created by: Bendong Tan# Created time: Friday, Jan 25, 2019# Last Modified: Monday, Jan 30, 2019# Wuhan University# ----------------------------------------------------import osos.environ['KERAS_BACKEND']='tensorflow'import timeimport numpy as npfrom keras.models import Sequentialfrom keras.layers import Dense,Masking,Flatten,Dropout,LSTMfrom keras.preprocessing.sequence import pad_sequencesfrom keras.utils import to_categoricalfrom keras.callbacks import ModelCheckpointfrom keras import backend as Kfrom keras import regularizersclass DynamicLSTM: ''' 初始化 ''' def __init__(self, X_train, y_train, X_test, y_test): n_trainsample, n_timesteps, n_features = np.shape(X_train) # 训练数据 self.X_train = X_train # 测试文件 self.X_test = X_test # 训练数据 self.y_train = y_train # 测试文件 self.y_test = y_test # 最后输出 self.n_outputs = 1 # 每个时刻的输入特征数量 self.n_features = n_features # 时序持续长度为 self.n_timesteps = n_timesteps # 层数 self.layer_num = 1 # 隐含层神经元数目 self.hidden_size=100 # 每代训练模型步数 self.batch_size=n_trainsample # 学习率 self.learningRate = 1e-3 # 训练代数 self.epochs=200 # 保存模型数据目录 self.storePath = None ''' 搭建LSTM网络 ''' def build(self): # 开始搭建浒关模型 model = Sequential() # 针对自适应评估模式设计补零操作以保持模型输入长度 model.add(Masking(mask_value=0, input_shape=(self.n_timesteps, self.n_features))) # LSTM层 model.add(LSTM(self.hidden_size,return_sequences=True)) # 设置dropout防止过拟合 model.add(Dropout(0.05)) # model.add(LSTM(self.hidden_size, return_sequences=True)) # model.add(Dropout(0.05)) model.add(LSTM(self.hidden_size)) # sigmoid层 model.add(Dense(self.n_outputs, activation='sigmoid')) # 编译模型 model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) return model ''' 训练模型 ''' def fit(self,model): # 记录最好模型 filepath = r&quot;.\\model\\model_best.h5&quot; checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max') callbacks_list = [checkpoint] # 训练模型 model.fit(self.X_train, self.y_train, epochs=self.epochs, batch_size=self.batch_size, validation_data=(self.X_test, self.y_test), callbacks=callbacks_list, verbose=1) return model ''' 标准评估模型 ''' def evaluation(self,model,X_test, y_test): _, accuracy = model.evaluate(X_test, y_test,batch_size=len(X_test), verbose=1) # 标准评估准确率 return accuracy ''' 自适应评估模型 ''' def Adaptive_TSA(self,model,X_test, y_test,delta): miss = 0 # 记录分类错误分数 right = np.zeros((len(y_test), 20)) # 记录每个样本在每个时刻的评估情况，做了评估记为1 y_pred = np.zeros((len(y_test), 1)) # 最终评估分类结果 # 自适应评估过程 for i in range(len(y_test)): for t in range(20): # 最大评估时刻数 # 如果在时间窗口内采取按照时刻逐步增加采样点的方式进行评估 if t&lt;self.n_timesteps: Input=pad_sequences(np.reshape(X_test[i,0:t+1,:], (-1,t+1,self.n_features)), maxlen=self.n_timesteps, padding='post') predictions = model.predict(Input) if predictions &gt;= delta and predictions &lt;= 1: right[i, 0:t + 1] = 1 y_pred[i] = 1 break if predictions &gt;=0 and predictions &lt; 1-delta: right[i, 0:t + 1] = 1 y_pred[i] = 0 break # 如果评估时刻超出时间窗口，则采取滑动时间窗口的方式评估 if t &gt;= self.n_timesteps: Input = np.reshape(X_test[i, t-self.n_timesteps+1:t + 1, :], (-1, self.n_timesteps, self.n_features)) predictions = model.predict(Input) if predictions &gt;= delta and predictions &lt;= 1: right[i, 0:t + 1] = 1 break if predictions &gt;= 0 and predictions &lt; 1 - delta: right[i, 0:t + 1] = 1 y_pred[i] = 0 break # 超出最大时刻的均视为失稳处理 if t + 1 == 20: if predictions&gt;=0.5: y_pred[i] = 1 if predictions&lt;0.5: y_pred[i] = 0 right[i, 0:t + 1] = np.ones((1, t+1)) break # 计算自适应评估准确率 for i in range(len(y_test)): if y_pred[i]!=y_test[i]: miss = miss + 1 # 记录平均评估时间 ART = sum(sum(right)) / len(y_test) # 记录自适应评估准确率 Accuracy=(len(y_test)-miss)/len(y_test)*100 return ART , Accuracy","link":"/2019/02/18/A%20Novel%20Temporal%20Feature%20Selection%20for%20%20Time-Adaptive%20Transient%20Stabiity%20Assessment/"},{"title":"HEXO中显示数学公式","text":"首页摘要： HEXO本身是不支持显示公式的，但是安装mathJax插件即可对浏览器进行公式渲染，也就是说安装了mathJax就可以像Latex一样显示美观的数学公式。折腾了两个小时，本博客于2019年3月25日支持数学公式显示了！ 安装与配置在git中运行如下命令1npm install hexo-math --save 在站点配置文件 _config.yml 中添加：123456math: engine: 'mathjax' # or 'katex' mathjax: # src: custom_mathjax_source config: # MathJax config 在 主题配置文件中 themes/…./_config.yml 中将 mathJax 设为 true:12345# MathJax Supportmathjax: enable: true per_page: false cdn: //cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML 但是目前为止还存在一些语义冲突的问题，例如“\\\\”是无法识别的，这样会导致一些分段函数公式无法渲染成功，需要更换 Hexo 的 markdown 渲染引擎，hexo-renderer-kramed 引擎是在默认的渲染引擎 hexo-renderer-marked 的基础上修改了一些 bug ，两者比较接近，也比较轻量级。 12npm uninstall hexo-renderer-marked --savenpm install hexo-renderer-kramed --save 执行上面的命令即可，先卸载原来的渲染引擎，再安装新的。 然后，跟换引擎后行间公式可以正确渲染了，但是这样还没有完全解决问题，行内公式的渲染还是有问题，因为 hexo-renderer-kramed 引擎也有语义冲突的问题。接下来到博客根目录下，找到node_modules\\kramed\\lib\\rules\\inline.js，把第11行的 escape 变量的值做相应的修改： 12//escape: /^\\\\([\\\\`*{}\\[\\]()#$+\\-.!_&gt;])/,escape: /^\\\\([`*\\[\\]()#$+\\-.!_&gt;])/, 这一步是在原基础上取消了对\\,{,}的转义(escape)。 同时把第20行的em变量也要做相应的修改。 12//em: /^\\b_((?:__|[\\s\\S])+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/, em: /^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/, 至此大功告成！ 备注：在电脑端的浏览器要允许加载mathJax的脚本才能正常显示，这都是血的教训啊！！！","link":"/2019/03/25/HEXO%E4%B8%AD%E6%98%BE%E7%A4%BA%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/"},{"title":"Latex with Vs code and Texlive安装方法","text":"首页摘要： Latex在本文中在本文中专指文本排版工具而非类似markdown这样的标记语言，主要介绍如何利用Vs code和Texlive对Latex进行配置，Texlive是Latex的内核而Vs code是IDE，因此重点是如何将两者连接。当然，也有其它优秀的工具可以使用，本文会稍微提一下。 Latex简介 LaTeX（LATEX，音译“拉泰赫”）是一种基于ΤΕΧ的排版系统，由美国计算机学家莱斯利·兰伯特（Leslie Lamport）在20世纪80年代初期开发，利用这种格式，即使使用者没有排版和程序设计的知识也可以充分发挥由TeX所提供的强大功能，能在几天，甚至几小时内生成很多具有书籍质量的印刷品。对于生成复杂表格和数学公式，这一点表现得尤为突出。因此它非常适用于生成高印刷质量的科技和数学类文档。这个系统同样适用于生成从简单的信件到完整书籍的所有其他种类的文档。 以上是知乎对Latex的定义，一言蔽之，Latex是利用规范语言且格式变换灵活地排版工具，但是无法所见所得；而word是用户界面，排版称得上是所见即所得。虽然还没有正式开始使用Latex，但是IEEE英文期刊绝大多数都提供了Latex模板使用，因此使用Latex比word在这种场景下排版的工作量会小很多。正常而言，要达到一般使用的水平，学习的有效时间1天足矣。 如何配置Vs code和Texlive1.在清华镜像中下载Texlive2018（反正下最新版就是了），以管理员身份运行安装文件，默认安装即可，不默认容易出错啊。安装完毕之后最好把安装目录（bin文件夹路径）添加至环境变量。 2.安装Vs code，百度就可以找到官网下载，安装路径随意。这一步最重要的是安装插件Latex Workshop和Latex Preview，这里我要说的是不需要像网上各种修改json文件来让Vs code下支持Latex中文显示，只需要在Latex文档中文章开头加一句“\\usepackage[UTF8]{ctex}”，就可以支持中文了，就是这么简单。 PS：其它的工具如Texstudio直接安装无需任何配置即可使用，只是颜值比较低。作为颜控，只有Vs code才能吸引我。下面给出Latex的经典入门模板，里面包含了指定中文显示的语句，注意一下。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091\\documentclass{article}%\\documentclass[journal]{IEEEtran}%\\documentclass{report}%\\documentclass{ActaOulu}\\usepackage[UTF8]{ctex}\\begin{document}\\title{Introduction to \\LaTeX{}}\\author{Author's Name}\\maketitle\\begin{abstract}This is abstract text: This simple document shows very basic features of \\LaTeX{}.\\end{abstract}%\\chapter{First Chapter}\\section{Introduction}Here is the text of your introduction. We use some Latin nonsense text to fillthe paragraphs. This way the resulting document will look more like an actualscientific paper or so. Here is an equation:\\begin{equation} \\label{simple_equation} \\alpha = \\sqrt{ \\beta }\\end{equation}Now you don't need to read the text any further because it's just Lorem ipsum.Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod temporincididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quisnostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eufugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt inculpa qui officia deserunt mollit anim id est laborum. Lorem ipsum dolor sitamet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut laboreet dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitationullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolorin reprehenderit in voluptate velit esse cillum dolore eu fugiat nullapariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa quiofficia deserunt mollit anim id est laborum.Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod temporincididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quisnostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eufugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt inculpa qui officia deserunt mollit anim id est laborum.\\subsection{Subsection Heading Here}Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod temporincididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quisnostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eufugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt inculpa qui officia deserunt mollit anim id est laborum.Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod temporincididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quisnostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eufugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt inculpa qui officia deserunt mollit anim id est laborum.Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod temporincididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quisnostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eufugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt inculpa qui officia deserunt mollit anim id est laborum.\\section{Conclusion}Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod temporincididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quisnostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eufugiat nulla pariatur.\\end{document}","link":"/2018/09/11/Latex%20with%20Vs%20code%20and%20Texlive%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/"},{"title":"PMU可观性分析","text":"首页摘要： 本文旨在说明任意数量、位置的PMU安装在电网中，这些PMU的可观性如何。基本规则由实验室师弟周挺分析得到，具体编程工作由本人实现，聊以一份说明书记录。 具体实现代码如下（python）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171#-*- coding: utf-8 -*-# ----------------------------------------------------# Description: Find Optimal Feature Set algorithm# Created by: Bendong Tan# Created time: Saturday, August 04, 2018# Last Modified: Monday, September 11, 2018# Wuhan University# ----------------------------------------------------##############输入输出说明################ 所有矩阵均采用0-1编码# 节点矩阵 bus_mat# 线路矩阵 branch_mat# pmu位置矩阵 pmu_locimport numpy as npclass PMU_Place(object): def __init__(self, bus_mat=None, branch_mat=None, load_mat=None, gen_mat=None, pmu_loc=np.array([8])): if bus_mat == None or branch_mat == None or pmu_loc == None: # 默认新英格兰39节点系统，输入请按照下述格式构造 # 节点矩阵,节点编号 self.bus_mat = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]) # 线路矩阵，线路首端和末端编号 self.branch_mat = np.array([[1, 2], [1, 39], [2, 3], [2, 25], [2, 30], [3, 4], [3, 18], [4, 5], [4, 14], [5, 6], [5, 8], [6, 7], [6, 11], [6, 31], [7, 8], [8, 9], [9, 39], [10, 11], [10, 13], [10, 32], [12, 11], [12, 13], [13, 14], [14, 15], [15, 16], [16, 17], [16, 19], [16, 21], [16, 24], [17, 18], [17, 27], [19, 20], [19, 33], [20, 34], [21, 22], [22, 23], [22, 35], [23, 24], [23, 36], [25, 26], [25, 37], [26, 27], [26, 28], [26, 29], [28, 29], [29, 38]]) # 负荷矩阵，负荷所在节点编号 self.load_mat = np.array([3, 4, 7, 8, 12, 15, 16, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 39]) # 发电机矩阵，发电机所在节点编号 self.gen_mat = np.array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39]) # pmu位置矩阵，PMU所在节点编号 self.pmu_loc = pmu_loc else: self.bus_mat = bus_mat self.branch_mat = branch_mat self.pmu_loc = pmu_loc # 构造邻接矩阵、pmu位置数组、零注入节点数组 def Construct_matrix(self): # 初始化 N = len(self.bus_mat) link_array = np.zeros((N, N)) pmu_array = np.zeros((N, 1)) ZIB_array = np.ones((N, 1)) # 构造邻接矩阵 branch = self.branch_mat for i in range(len(branch)): link_array[branch[i, 0] - 1, branch[i, 1] - 1] = 1 link_array[branch[i, 1] - 1, branch[i, 0] - 1] = 1 # 构造pmu位置数组 pmu_array[self.pmu_loc - 1] = 1 # 减1是因为numpy从0数起 # 构造零注入节点数组,除去发电机以及负荷节点之外的节点 ZIB_array[self.load_mat - 1] = 0 ZIB_array[self.gen_mat - 1] = 0 return link_array, pmu_array, ZIB_array def Observation(self, link_array, pmu_array, ZIB_array): # 初始化 N = len(self.bus_mat) V = np.zeros((N, 1)) # 电压矩阵 I = np.zeros((N, N)) # 电流矩阵，电流已知那么线路功率也是已知的 G = np.zeros((len(self.gen_mat), 1)) # 发电机矩阵 L = np.zeros((len(self.load_mat), 1)) # 负荷矩阵 # 中间变量 A = np.zeros((N, N)) B = np.zeros((N, 1)) # 按照规则进行可观性描述 # 先确定安装有PMU的点 # 安装PMU的节点其节点电压和相连支路电流、相连节点电压可观 for i in range(N): # if pmu_array[i] == 1: for j in range(N): if j != i: V[i] = pmu_array[i] or (pmu_array[j] and link_array[i, j]) I[i, j] = (pmu_array[i] or pmu_array[j]) and link_array[i, j] I[j, i] = (pmu_array[i] or pmu_array[j]) and link_array[i, j] for i in range(100): # 进行迭代直至收敛 # 支路两端电压可观，则该支路电流可观 for i in range(N): for j in range(N): if j != i: if V[i] == 1 and V[j] == 1 and I[i, j] == 0 and link_array[i, j] == 1: I[i, j] = V[i] and V[j] I[j, i] = V[i] and V[j] # 支路电流和另一端电压可知，则该支路另一端电压已知 for i in range(N): for j in range(N): if j != i and V[i] == 0: V[i] = V[i] or (I[i, j] and V[j]) # 零注入节点未配置PMU，且仅有一条相连支路电流未知，该支路电流可观 for i in range(N): if ZIB_array[i] == 1: for j in range(N): if i != j: for k in range(N): A[k] = link_array[i, k] and I[i, k] if A.sum(axis=0)[0] == link_array[i, :].sum(axis=0) - 1 and I[i, j] == 0: I[i, j] = ZIB_array[i] and link_array[i, j] I[j, i] = ZIB_array[i] and link_array[i, j] # 零注入节点未配置PMU，且所有相邻节点电压已知，则该节点电压已知 for i in range(N): if ZIB_array[i] == 1 and V[i] == 0: for j in range(N): if i != j: for k in range(N): B[k] = link_array[i, k] and V[k] if B.sum(axis=0)[0] == link_array[i, :].sum(axis=0) and V[i] == 0: V[i] = ZIB_array[i] return V, I, G, L # 物理量索引转换 def Index(self,V, I,link_array): N = len(self.bus_mat) G = [] # 发电机矩阵 L = [] # 负荷矩阵 V_Bus = np.nonzero(V) I_Line = np.nonzero(I) # 由于Python从0计数，节点电压矩阵元素值+1 for i in range(len(V_Bus[0])): V_Bus[0][i] += 1 V_Bus = V_Bus[0].tolist() for i in range(len(I_Line[0])): I_Line[0][i] += 1 for i in range(len(I_Line[0])): I_Line[1][i] += 1 I_Line = list(I_Line) I_Line_1 = I_Line[0].tolist() I_Line_2 = I_Line[1].tolist() I_Line_Result = [] for i in range(len(I_Line_1)): I_Line_Result.append((I_Line_1[i], I_Line_2[i])) # 由于支路电流会计算两次，这里删去支路两端节点相同的一半元素，把不存在于原线路矩阵中的编号去除 for i in range(len(I_Line_1)): if [I_Line_1[i],I_Line_2[i]] not in self.branch_mat.tolist(): I_Line_Result.remove((I_Line_1[i], I_Line_2[i])) for i in range(len(self.gen_mat)): if V[self.gen_mat[i]-1]!=0 and sum(I[self.gen_mat[i]-1,:])==sum(link_array[self.gen_mat[i]-1,:]): G.append(self.gen_mat[i]) for i in range(len(self.load_mat)): if V[self.load_mat[i]-1]!=0 and sum(I[self.load_mat[i]-1,:])==sum(link_array[self.load_mat[i]-1,:]): L.append(self.load_mat[i]) return V_Bus,I_Line_Result,np.array(G),np.array(L)if __name__ == '__main__': PMU = PMU_Place(bus_mat=None, branch_mat=None, load_mat=None, gen_mat=None, pmu_loc=np.array([3,8,10,16,20,23,25,29])) link_array, pmu_array, ZIB_array = PMU.Construct_matrix() V, I, G, L = PMU.Observation(link_array, pmu_array, ZIB_array) V_Bus, I_Line_Result, G, L=PMU.Index(V, I,link_array) print('电压可观节点总数为：', sum(sum(V))) print('电压可观节点为:', V_Bus) print('发电机可观节点为:', G) print('负荷可观节点为:', L) print('电流可观支路总数为：', sum(sum(I)) / 2) # 由于支路电流会计算两次，这里删去支路两端节点相同的一半元素 print('电流可观支路两端节点编号为：', I_Line_Result) 2018.10.24补充matlab版代码（1）定义类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170classdef PMU_Place % 定义类 properties bus_mat; branch_mat; load_mat; gen_mat; pmu_loc; end methods %定义方法 function obj=PMU_Place(pmu_loc) % 默认网络为新英格兰39节点 % 节点矩阵 obj.bus_mat=[1,2,3,4,5,6,7,8,9,10,11,12,13,... 14,15,16,17,18,19,20,21,22,23,24,25,26,... 27,28,29,30,31,32,33,34,35,36,37,38,39]; % 线路矩阵 obj.branch_mat=[1,2; 1,39; 2,3; 2,25;... 2, 30; 3, 4; 3, 18; 4, 5;... 4, 14; 5, 6; 5, 8; 6, 7;... 6, 11; 6, 31; 7, 8; 8, 9;... 9, 39; 10, 11; 10, 13; 10, 32;... 12, 11; 12, 13; 13, 14; 14, 15;... 15, 16; 16, 17; 16, 19; 16, 21;... 16, 24; 17, 18; 17, 27; 19, 20;... 19, 33; 20, 34; 21, 22; 22, 23;... 22, 35; 23, 24; 23, 36; 25, 26;... 25, 37; 26, 27; 26, 28; 26, 29;... 28, 29; 29, 38]; % 负荷矩阵 obj.load_mat=[3,4,7,8,12,15,16,18,20,21,23,24,25,26,27,28,29,31,39]; % 发电机矩阵 obj.gen_mat=[30,31,32,33,34,35,36,37,38,39]; % PMU位置矩阵 obj.pmu_loc=pmu_loc; end % 构造邻接矩阵、pmu位置数组、零注入节点数组 function [link_array, pmu_array, ZIB_array]=Construct_matrix(obj) % 初始化 N = length(obj.bus_mat); link_array = zeros(N, N); pmu_array = zeros(N, 1); ZIB_array = ones(N, 1); % 构造邻接矩阵 branch=obj.branch_mat; [BN,BM]=size(obj.branch_mat); for i = 1:BN link_array(branch(i, 1), branch(i, 2)) = 1; link_array(branch(i, 2), branch(i, 1)) = 1; end % 构造pmu位置数组 pmu_array(obj.pmu_loc) = 1; % 减1是因为numpy从0数起 % 构造零注入节点数组,除去发电机以及负荷节点之外的节点 ZIB_array(obj.load_mat) = 0; ZIB_array(obj.gen_mat) = 0; end function [V, I]=Observation(obj, link_array, pmu_array, ZIB_array) % 初始化 N = length(obj.bus_mat); V = zeros(N, 1); % 电压矩阵 I = zeros(N, N); % 电流矩阵，电流已知那么线路功率也是已知的 G = zeros(length(obj.gen_mat), 1); % 发电机矩阵 L = zeros(length(obj.load_mat), 1); % 负荷矩阵 % 中间变量 A = zeros(N, 1); B = zeros(N, 1); % 按照规则进行可观性描述 % 先确定安装有PMU的点 % 安装PMU的节点其节点电压和相连支路电流、相连节点电压可观 for i =1:N % if pmu_array[i] == 1: for j =1:N if j ~= i V(i) = pmu_array(i) || (pmu_array(j) &amp;&amp; link_array(i, j)); I(i, j) = (pmu_array(i) || pmu_array(j)) &amp;&amp; link_array(i, j); I(j, i) = (pmu_array(i) || pmu_array(j)) &amp;&amp; link_array(i, j); end end end for K =1:10 % 进行迭代直至收敛 % 支路两端电压可观，则该支路电流可观 for i = 1:N for j = 1:N if j ~= i if V(i) == 1 &amp;&amp; V(j) == 1 &amp;&amp; I(i, j) == 0 &amp;&amp; link_array(i, j) == 1 I(i, j) = V(i) &amp;&amp; V(j); I(j, i) = V(i) &amp;&amp; V(j); end end end end % 支路电流和另一端电压可知，则该支路另一端电压已知 for i = 1:N for j = 1:N if j ~= i &amp;&amp; V(i) == 0 V(i) = V(i) || (I(i, j) &amp;&amp; V(j)); end end end % 零注入节点未配置PMU，且仅有一条相连支路电流未知，该支路电流可观 for i = 1:N if ZIB_array(i) == 1 for j = 1:N if i ~= j for k = 1:N A(k) = link_array(i, k) &amp;&amp; I(i, k); end if sum(A) == sum(link_array(i, :)) - 1 &amp;&amp; I(i, j) == 0 I(i, j) = ZIB_array(i) &amp;&amp; link_array(i, j); I(j, i) = ZIB_array(i) &amp;&amp; link_array(i, j); end end end end end % 零注入节点未配置PMU，且所有相邻节点电压已知，则该节点电压已知 for i = 1:N if ZIB_array(i) == 1 &amp;&amp; V(i) == 0 for j = 1:N if i ~= j for k = 1:N B(k) = link_array(i, k) &amp;&amp; V(k); end if (sum(B) == sum(link_array(i, :))) &amp;&amp; (V(i) == 0) V(i) = ZIB_array(i); end end end end end end end function [V_Bus,I_Line_Result,G,L]=Index(obj,V, I,link_array) N = length(obj.bus_mat); G = []; % 发电机矩阵 L = []; % 负荷矩阵 V_Bus = find( V ~= 0 ); [I_Linerow, I_Linecol]= find( I ~= 0 ); I_Line = []; I_Line_Result = []; % 由于支路电流会计算两次，这里删去支路两端节点相同的一半元素，把不存在于原线路矩阵中的编号去除 for i =1:length(I_Linerow) P=[I_Linerow(i), I_Linecol(i)]==obj.branch_mat; index=find(sum(P,2) == 2); I_Line_Result=[I_Line_Result;obj.branch_mat(index,:)]; end for i =1:length(obj.gen_mat) if V(obj.gen_mat(i))~=0 &amp;&amp; sum(I(obj.gen_mat(i),:))==sum(link_array(obj.gen_mat(i),:)) G=[G,obj.gen_mat(i)]; end end for i =1:length(obj.load_mat) if V(obj.load_mat(i))~=0 &amp;&amp; sum(I(obj.load_mat(i),:))==sum(link_array(obj.load_mat(i),:)) L=[L,obj.load_mat(i)]; end end end end end （2）主程序 1234567891011121314151617181920clc;clear allticPMU = PMU_Place([3,8,10,16,20,23,25,29]);[link_array, pmu_array, ZIB_array] = PMU.Construct_matrix();[V, I] = PMU.Observation(link_array, pmu_array, ZIB_array);[V_Bus, I_Line_Result, G, L]=PMU.Index(V, I,link_array);disp('==============计*算*结*果=============')disp('1、电压可观节点总数为：');disp(sum(sum(V)))disp('2、电压可观节点编号为:')disp(V_Bus')disp('3、发电机可观节点编号为:')disp(G)disp('4、负荷可观节点编号为:')disp(L)disp('5、电流可观支路总数为：') % 由于支路电流会计算两次，这里删去支路两端节点相同的一半元素disp(sum(sum(I)) / 2)disp('6、电流可观支路两端节点编号（第一行为行编号，第二行为列编号）为：')disp(I_Line_Result')toc","link":"/2018/08/09/PMU%E5%8F%AF%E8%A7%82%E6%80%A7%E5%88%86%E6%9E%90/"},{"title":"HEXO博客更换主题","text":"首页摘要： 笔记本硬盘不知怎么地就坏了，还好抢救出一些文件，原来建立的个人网站文件却损失了一部分。在这之前以为只能重新搭建网站，现在才懂只要posts还在就能够还原原来的网站，一把辛酸泪啊。只需要恢复主题或者更换主题就可以完成，这篇文章主要推荐在我更换主题过程中借鉴的很有用的网站。 从零开始搭建HEXO+GITHUB博客这篇文章关于配置文件及添加一些小控件非常详细，参考网站：Hexo+Github博客搭建完全教程 Hexo+icarus主题配置一个非常棒的教程，要使用icarus主题的可以参考网站：Hexo+icarus主题配置， 可以说，从头到尾直接一步一步参考即可， Hexo中渲染MathJax数学公式的问题显示公式是HEXO博客一个头疼的问题，不完美但够用解决方法参考网站：Hexo中渲染MathJax数学公式的问题 。","link":"/2020/02/03/HEXO%E5%8D%9A%E5%AE%A2%E6%9B%B4%E6%8D%A2%E4%B8%BB%E9%A2%98/"},{"title":"Power System Stability and Control (Kundur)----前言","text":"首页摘要： Power System Stability and Control (Prabha Kundur)这本书被称为电力系统领域的圣经，本系列文章旨在记录阅读此书的一些总结。本章为前言部分，介绍了写此书的目的和架构。 这本书是Kundur老先生对之前的一些文献并结合自己大量的授课心得总结而成，为电力系统领域学生和电力工程师提供详细的理论指导和实际运行经验。 第一章和第二章介绍了电力系统的宏观框架。第一章包括电力系统的历史沿革、运行控制结构，第二章包括电力系统稳定问题的定义与分类。 第三章至第十一章对电力系统各个元件建模并分析其特性。第三章至第十章包括了电力系统发电机、励磁系统、原动机、交流及直流输电、系统负荷；第十一章则是对有功无功控制设备的建模分析。 第十二章至第十七章对各种电力系统稳定现象及其相应的控制措施进行了分析。","link":"/2020/03/17/Power%20System%20Stability%20and%20Control%20(Kundur)----%E5%89%8D%E8%A8%80/"},{"title":"Power System Stability and Control (Kundur)----第一章","text":"首页摘要： 本章主要介绍电力发展的历史沿革、电力系统的结构（包括物理组成结构和控制结构）、电力系统运行与控制概要。 电力发展的历史沿革电力系统的发展，一方面体现了技术的进步，另一方面是伴随着各种标准的形成，例如电压等级、频率大小的制定等。但是，电力系统的复杂程度也在不断提高，安全稳定问题也更难分析。 电力系统的结构电力系统可以分成发电（generation）、输电（transmission）和配电（distribution）三个环节。发电主要有发电站（generation station）组成，输电和配电根据连接的对象可以进一步分成主网（transmission system）、次网（subtransmission system）、配网（distribution system）。主网运行电压在230KV以上，主要用于远距离输电；次网运行电压在69KV到138KV之间，主要用于供电给工业负荷；配网运行电压在4KV到34.5KV之间的称之为主馈线，用于小型工业负荷，而运行电压在120/240V的称之为次级馈线，用于商业负荷和居民负荷。上述电压等级和中国不同，这不在本文讨论范围之内，仅作为对电网结构的简单理解。 电力系统运行状态分类 电力系统运行状态分为五种：正常、警戒、事故、崩溃、恢复，具体如下所示： （1）正常状态：电力系统运行在规定范围内，不存在过载等现象，遇到故障稳定下来后也不存在越限。这种状态离稳定边界较远。 （2）警戒状态：电力系统没有发生越限，但是发生故障稳定后会发生设备过载，甚至发生故障后崩溃。这种状态离稳定边界较近。 （3）事故状态：电力系统正在遭受严重的故障，但是启动保护控制能够回到警戒状态 （4）崩溃状态：如果遭受严重故障后，任何措施都无法阻止连锁事件，电力系统则处于崩溃状态。 （5）恢复状态：电网崩溃后，重新恢复到正常状态或者警戒状态的过程，类似国内定义的黑启动。 为了保证电力系统尽可能的处于正常运行状态，需要有相配套的控制体系，目前控制手段主要是控制设备就地控制相邻的元件，系统控制中心（类似省调）会通过SCADA监测这些控制行为，而下图中的Pool Control Center是对多个系统进行监控的中心（类似总调）。调度员就是系统控制中心和Pool Control Center的关键技术人员，用以保证电力系统的安全运行。 电力系统控制结构 电力系统控制目的是使正常运行状态更加经济、警戒运行状态到正常运行状态、事故和崩溃状态能够回到正常运行状态或者警戒状态。总而言之，通过一系列控制使电力系统安全稳定经济运行，主要保证电压和频率能够维持在很小的范围波动，而同时又具有很高的可靠性。从宏观上来简化理解电力系统控制结构，电力系统可以控制的对象包括发电侧和输电侧。而这里又可以分为系统发电控制（system generation control）、发电单元控制（generating unit control）、输电控制（transimission control）。系统发电控制主要通过协调联络线功率、发电功率来保证电力系统的安全稳定经济运行。发电单元控制则是通过自身原动机、励磁系统等来响应系统发电控制对它的要求，如输出功率等。输电控制是利用各种控制设备如无功补偿设备来响应系统发电的要求，如电压、无功等。","link":"/2020/03/18/Power%20System%20Stability%20and%20Control%20(Kundur)----%E7%AC%AC%E4%B8%80%E7%AB%A0/"},{"title":"基于hexo和github搭建个人博客","text":"首页摘要： 本身对CCS和HEXO完全没有接触过，在知乎上搜索发现很多人都是用hexo结合github来搭建个人博客，这种方式可以在不购买域名的情况下直接搭建，只需要安装一些特定的软件和注册github账号就可以，我了解其中大概的原理花了3个晚上，之后重新搭建十分钟就可以独立搭完一个博客的，所以现在来一步步介绍怎么搭建，同时我也会说明为什么要有这些步骤。 当然我的博客也还没完全搭好，毕竟对博客一些CSS文件不了解，今后慢慢完善评论功能以及添加域名 环境准备 安装Node.js 这个可以编译Javascript代码 ，也就是处理网页文件需要的工具 Github 注册Github网站账号，用来存储Node.js生成的文件，这样就能在网站中看到内容了 安装Git 一款上传Node.js生成的文件到Github的工具 注册Github1. 点击“+”注册，首先得有一个账号 2. 注册完之后就需要创建repository，这个就是我们保存Node.js生成文件的地方了 填写地址，这个就是以后博客的地址了，一般是username.github.io，username是英文名，这个随意 配置和使用Github1. 开始—所有应用—找到git bash 2. 接下来是配置SSH keys，SSH keys是一个包含了保存在你本地文件地址等信息的密码，需要复制到githu里面，这样本地文件和github就达成了联系但是又具有保密性首先要检查自己电脑上现有的 SSH key ： 在Git bash中输入cd ~/. ssh 如果显示“No such file or directory”，说明这是你第一次使用 git 这个时候就需要生成心的SSH key 12345`$ ssh-keygen -t rsa -C &quot;邮件地址@youremail.com&quot;` Generating public/private rsa key pair. `Enter file in which to save the key (/Users/your_user_directory/.ssh/id_rsa):&lt;回车就好&gt;` 【提示1】这里的邮箱地址，输入注册 Github 的邮箱地址； 【提示2】「-C」的是大写的「C」 然后系统会要你输入密码： 12Enter passphrase (empty for no passphrase):&lt;设置密码&gt;Enter same passphrase again:&lt;再次输入密码&gt; 在回车中会提示你输入一个密码，这个密码会在你提交项目时使用，如果为空的话提交项目时则不用输入。这个设置是防止别人往你的项目里提交内容。 注意：输入密码的时候没有输入痕迹的，不要以为什么也没有输入。 最后看到这样的界面，就成功设置ssh key了： 3. 添加SSH Key到GitHub在本地文件夹找到id_rsa.pub文件，看上面的图片第四行的位置告诉你存在哪里了 没找到的勾选一下文件扩展名 隐藏的项目 .ssh文件夹里记事本打开这个文件复制全部内容到 github相应位置。 具体位置是： Title最好写，随便写。网上有说不写title也有可能后期出现乱七八糟的错误 Key部分就是放刚才复制的内容啦 点击Add SSH key 4. 测试是否完成git bash 里 输入以下代码 不要改任何一个字 我就是自作聪明以为代表的是自己注册时候的邮箱然后… 1$ ssh -T git@github.com 如果得到以下反馈 123The authenticity of host 'GitHub.com (207.97.227.239)' can't be established.RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.Are you sure you want to continue connecting (yes/no) 输入yes回车，出现 1`Enter passphrase for key '/f/Github_manage/TanBendong.github.io/.ssh/id_rsa':` 输入刚才设置的密码回车就可以了（注意在git bash里面输入密码是不可见的)，结果如图 5. 设置用户信息现在已经可以通过 SSH 链接到 GitHub 啦!当然还需要完善一些个人信息: 12$ git config --global user.name &quot;wuyalan&quot;//输入注册时的username$ git config --global user.email &quot;alan.wyl@foxmail.com&quot;//填写注册邮箱 GitHub 也是用这些信息来做权限的处理，输入下面的代码进行个人信息的设置，把名称和邮箱替换成你自己的，名字必须是你的真名，而不是GitHub的昵称。 6. SSH Key配置成功本机已成功连接到 github。 利用hexo搭建博客利用npm命令安装hexo，这些命令都是在git bash里面输入的 12$ cd$ npm install -g hexo 1. 创建独立博客项目文件夹安装完成后，关掉前面那个 Git Bash 窗口。在本地创建一个与 Repository 中博客项目同名的文件夹（如E:[http://username.github.io](https://link.zhihu.com/?target=http%3A//username.github.io)）在文件夹上点击鼠标右键，选择 Git bash here； 【提示】在进行博客搭建工作时，每次使用命令都要在 H:[http://username.github.io](https://link.zhihu.com/?target=http%3A//username.github.io) 目录下。 执行下面的指令，Hexo 就会自动在 H:[http://username.github.io](https://link.zhihu.com/?target=http%3A//username.github.io) 文件夹建立独立博客所需要的所有文件啦！ 1$ hexo init 2. 安装依赖包1$ npm install 3. 确保git部署1$ npm install hexo-deployer-git --save 4. 本地查看现在已经搭建好本地的 Hexo 博客了，执行完下面的命令就可以到浏览器输入 localhost:4000 查看到啦 12$ hexo g$ hexo s hexo g 每次进行相应改动都要hexo g 生成一下，这一步是对本地文件用Node.js解析的过程，只要你的本地文件发生改动就必须用这个命令 hexo s 启动服务预览，这个命令可以将生成好的文件离线在本地浏览器查看，这时还没有上传到github 5. 用Hexo克隆主题执行完 hexo init 命令后会给一个默认的主题：landscape 你可以到官网找你喜欢的主题进行下载 hexo themes 知乎：有哪些好看的 Hexo 主题？ 找到它所在的 Github Repository ） 找到之后通过git命令下载 在主题的repository点击clone 复制一下那个地址 1$ git clone +复制的地址+themes/black-blue 后面就是clone之后放到你本地的博客文件夹themes文件夹下，black-blue就是我clone的主题，生成了一个文件夹。landscape是hexo默认生成的，这个时候当然用自己喜欢的啦。black-blue里面有Readme，作者一般会告诉你怎么改主题 6. 修改整站配置文件自己把 http://blog.io 中文件都点开看一遍，主要配置文件是 _config.yml（注意是username.github.io文件夹下的 _config.yml），可以用记事本打开，推荐使用 sublime 或者nodepad++打开。 修订清单如下，文档内有详细注释，可按注释逐个修订 博客名字及作者信息：_config.yml 个人介绍页面：about.md 代表作页面：milestone.md 这里贴一份网上看到的 可以复制替换原来的 但是替换之前最好备份 可能会出错 那要么你就对照着看一下改就好 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113# Hexo Configuration## Docs: http://zespia.tw/hexo/docs/configure.html## Source: https://github.com/tommy351/hexo/# Site 这里的配置，哪项配置反映在哪里，可以参考我的博客title: My Blog #博客名subtitle: to be continued... #副标题description: My blog #给搜索引擎看的，对网站的描述，可以自定义author: Yourname #作者，在博客底部可以看到email: yourname@yourmail.com #你的联系邮箱language: zh-CN #中文。如果不填则默认英文# URL #这项暂不配置，绑定域名后，欲创建sitemap.xml需要配置该项## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://yoursite.comroot: /permalink: :year/:month/:day/:title/tag_dir: tagsarchive_dir: archivescategory_dir: categories# Writing 文章布局、写作格式的定义，不修改new_post_name: :title.md # File name of new postsdefault_layout: postauto_spacing: false # Add spaces between asian characters and western characterstitlecase: false # Transform title into titlecasemax_open_file: 100filename_case: 0highlight: enable: true backtick_code_block: true line_number: true tab_replace:# Category &amp; Tagdefault_category: uncategorizedcategory_map:tag_map:# Archives 默认值为2，这里都修改为1，相应页面就只会列出标题，而非全文## 2: Enable pagination## 1: Disable pagination## 0: Fully Disablearchive: 1category: 1tag: 1# Server 不修改## Hexo uses Connect as a server## You can customize the logger format as defined in## http://www.senchalabs.org/connect/logger.htmlport: 4000logger: falselogger_format:# Date / Time format 日期格式，可以修改成自己喜欢的格式## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-M-Dtime_format: H:mm:ss# Pagination 每页显示文章数，可以自定义，贴主设置的是10## Set per_page to 0 to disable paginationper_page: 10pagination_dir: page# Disqus Disqus插件，我们会替换成“多说”，不修改disqus_shortname:# Extensions 这里配置站点所用主题和插件，暂时默认## Plugins: https://github.com/tommy351/hexo/wiki/Plugins## Themes: https://github.com/tommy351/hexo/wiki/Themestheme: landscapeexclude_generator:plugins:- hexo-generator-feed- hexo-generator-sitemap# Deployment 站点部署到github要配置## Docs: http://zespia.tw/hexo/docs/deploy.htmldeploy: type: git repository: branch: master 7. 启用新下载的主题在刚打开的的_config.yml 文件中，找到“# Extensions”，把默认主题 landscape 修改为刚刚下载下来的主题名： 【提示】http://username.github.io 里有两个 config.yml 文件，一个在根目录，一个在 theme 下，现在修改的是在根目录下的。 8. 更新主题git bash 里执行 12$ cd themes/主题名$ git pull 10. 本地查看调试每次修改都要hexo g 生成一下 12$ hexo g #生成$ hexo s #启动本地服务，进行文章预览调试，退出服务用Ctrl+c 浏览器输入 localhost：4000 预览效果 将博客部署到http://username.github.io1. 复制SSH码进入 Github 个人主页中的 Repository，复制新建的独立博客项目:http://username.github.io 的 SSH 码 2. 编辑整站配置文件打开 H:\\username.github.io_config.yml,把刚刚复制的 SSH 码粘贴到“repository：”后面，别忘了冒号后要空一格。 1234deploy: type: git repository: git@github.com:username/username.github.io.git branch: master 3. 执行下列指令即可完成部署【提示】每次修改本地文件后，需要 hexo g 才能保存。每次使用命令时，都要在你的博客文件夹目录下 12$ hexo g$ hexo d 【提示】如果在配置 SSH key 时设置了密码，执行 hexo d 命令上传文件时需要输入密码进行确认，会出现一个小框框，这个密码“配置和使用Github”步骤中设置的，输入即可。 输入密码之后在浏览器输入： username.github.io 如果得到你想要的效果，那么恭喜你，博客已经搭建好啦！ 参考文献 [1] https://zhuanlan.zhihu.com/p/32957389","link":"/2018/05/06/HEXO%E5%92%8CGITHUB%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"title":"如何写一篇好博客？","text":"首页摘要： 我的博客开张了！看了一篇博客的总结，觉得总结得很到位，转发过来，分享一下，写博客的时候时刻学习。 好博客，好文章是什么样的？ 文章名称鲜明，一看名称就知道关于什么的内容 整体结构清晰，把事件或者原理的始末按照‘什么样（what？）’，‘为什么（why）’，‘怎么做（how）’说明 简明扼要。太啰嗦，没人看。 难易适中，太高深也没人看 图文搭配，有句话说的好，一图胜千文，好的图片胜过千言万语 怎么写出好博客？ 定主题和文章名称。如果想写一个关于电力系统暂态分析的文章，名称要准确，就叫电力系统暂态分析，不要起啰嗦的名字，比如电力系统如何暂态分析 准备资料阶段，熟悉电力系统暂态分析相关资料，做好功课 定文章的结构和提纲。还拿这个电力系统暂态分析为例，你得说明什么是电力系统暂态分析？为什么要电力系统暂态分析？如何电力系统暂态分析？ 语言表单，简单直白，不用凑字数 深入主题，比如怎么挖掘电力系统暂态分析影响因素，把参数简要说明 找一个好图片，如果找不到，自己制作一个最契合自己主题的图片 把文章发给好友阅读，提出宝贵的意见 改进博客 坚持写博客","link":"/2018/05/05/bestblog/"},{"title":"Power System Stability and Control (Kundur)----同步电机","text":"首页摘要： 都说要拥有一个有趣的灵魂，同步电机可以说是电力系统的灵魂，稳定的时候它就像温文尔雅的君子，失稳的时候它又像犯了狂躁症。为了对其有所了解，这章主要从同步电机绕组排列和磁场分析、一般模型建立、稳态和动态分析模型来介绍。 这章的内容全部参考自如下文献，细节可查阅它们： [1] 辜承林,陈乔夫, 等. 电 机 学[J]. 武 汉: 华 中 科 技科技大学出本社, 2001. [2] 何仰赞, 温增银. 电力系统分析[M]. 华中科技大学出版社, 2002. [3] Kundur P, Balu N J, Lauby M G. Power system stability and control[M]. New York: McGraw-hill, 1994. 同步电机图示 图1 图1是一个凸极机，其中电枢是指发生能量转换的地方，而定子绕组和转子绕组都是等效后的图示。实质上，定子绕组是在转子相切的机壁上分散排列，通过合理的排列可以等效成图中的效果。 注：这里的符号表示中，a和后文的A符号可互相替换，${a}’$和后文的X符号可互相替换，其它相以此类推。 同步电机的绕组分析要制造出一个可用的同步电机，要满足以下条件： （1）转子产生的磁场沿着气隙是正弦分布的，这样才有可能产生正弦电压； （2）机端电压也是正弦变化的，如果是三相同步电机，每一相相角相差120度。 第一个条件在构造转子一定的形状可以实现，第二个条件可以通过合理地排列绕组来实现。此外，感性来理解，要想电机不时刻振动，定子三相电流产生的合成磁场必然也是正弦分布的，而且和转子磁场相对静止（可能差了一定角度）。换句话说，定子三相电流产生的合成磁场是和转子磁场一样在气隙中同步旋转的正弦形状的磁场。如果两者不相对静止，同步电机必然因为不均匀的磁场力而发生振动。因此定子绕组排列后的效果是： （1）三相绕组各自产生正弦分布的磁通（磁势），而且它们的合成磁场是和转子磁场相对静止的正弦旋转磁场； （2）为了节省制造成本，定子绕组在一定磁场下的感应电势是最大的。一般而言，采用60相带可以获得最大感应电势，即每隔60度电角度的导体都串联，如图2所示： 图2 这里两根导体之间电角度是20度是因为电机是双极转子，以A相为例，从1号导体到3号导体刚好占了60度电角度，而19号导体到21号导体则分别和它们相差360度电角度，因此把这两组导体相串联即可获得最大感应电势。X相其实也属于A相，从电角度可以发现，其电势角度和A相刚好相差180度，因此X相和A相反向串联就可以得到最后的A相。图3给了实现A相绕组的部分连接过程，部分具体连接顺序为：1——10——2。后续连接顺序类似。可以发现B-Y相和C-Z相都各自相差120度，形成了三相对称绕组。 图3 上述是单层绕组的排列方式，可以看到1号导体和10号导体构成的一个线圈电角度距离是180度，这种线圈成为整距线圈。为了降低谐波，可以采用双层绕组，这种绕组线圈电角度小于180度，但各相电角度还是相差120度，因此其产生的感应电势更小。每相的感应电动势幅值可以表示成： E_{\\phi}=4.44Nfk_{N}\\Phi其中，$N$为相绕组匝数，$k_{N}$是因为线圈的短距和分布特征造成的折扣系数，$\\Phi$是每极磁通。这个感应电势和绕组等效成图1所示的单个导体的感应电动势相等，图1的绕组也称为集中绕组，之后我们都将用集中绕组来说明，便于理解。 同步电机的磁场分析在知道每相感应电动势幅值之后，我们还需要知道同步电机磁场具体是如何变化的，以便求出每相感应电动势的相量表示，这样才能准确分析同步电机。为了明晰同步电机磁场，根据磁场理论，知道磁动势$F$和磁导$P $就能计算出磁通（磁场）： \\Phi =\\frac{F}{P }这节我们首先介绍磁动势的分布及计算，至于磁导会在后续内容介绍计算方法。 图4 先来看一相的磁动势分布，最后再将三相磁动势合成。首先，将A相按照电机圆周展开，以A相点作为起点，可以得到图4黄线所示的方波磁动势分布，其基波是如图4红线所示的正弦分布，可以看出，每一相在某个时刻的磁动势在同步电机圆周空间上的分布属于正弦分布。然而，我们知道，磁动势是和通过导体的电流成正比的，而每一相电流是随时刻成正弦变化的，假设A相电流的表达式是： i_{a}=I_{m} \\cos \\left(\\omega_{s} t\\right)其中，$i_{a}$是A相电流瞬时值，$I_{m}$是电流幅值，$\\omega_{s}$是同步电机电角速度。再考虑磁动势同步电机圆周空间上的正弦分布和磁动势相比导体电流的比例，可得A相磁动势分布的表达式： f_{Ac}=N_{a}I_{m}\\cos \\theta \\cos \\omega_{s} t其中，$N_{a}$是因为分布系数等因素而造成的磁动势和电流之间的等效匝数，$\\theta$是图四中距离原点的电角度。其余相和A相在时间和空间上分别相差120度倍数的相位，所以可以推知它们的磁动势分布表达式为： \\begin{array}{l} f_{Bc}=N_{a}I_{m} \\cos \\left(\\theta-\\frac{2}{3} \\pi\\right) \\cos \\left(\\omega_{s} t-\\frac{2}{3} \\pi\\right) \\\\ f_{Cc}=N_{a}I_{m} \\cos \\left(\\theta-\\frac{4}{3} \\pi\\right) \\cos \\left(\\omega_{s} t-\\frac{4}{3} \\pi\\right) \\end{array}因此，三相磁动势分布表达式如下： \\begin{array}{l} f_{Ac}=N_{a}I_{m}\\cos \\theta \\cos \\omega_{s} t \\\\ f_{Bc}=N_{a}I_{m} \\cos \\left(\\theta-\\frac{2}{3} \\pi\\right) \\cos \\left(\\omega_{s} t-\\frac{2}{3} \\pi\\right) \\\\ f_{Cc}=N_{a}I_{m} \\cos \\left(\\theta-\\frac{4}{3} \\pi\\right) \\cos \\left(\\omega_{s} t-\\frac{4}{3} \\pi\\right) \\end{array}通过三角函数分解可以将上式写成： \\begin{array}{l} f_{Ac}=\\frac{1}{2} N_{a}I_{m}\\cos(\\omega_{s} t-\\theta) + \\frac{1}{2} K_{c}I_{m}\\cos(\\omega_{s} t + \\theta)\\\\ f_{Bc}=\\frac{1}{2} N_{a}I_{m}\\cos(\\omega_{s} t-\\theta) + \\frac{1}{2} K_{c}I_{m}\\cos(\\omega_{s} t + \\theta-\\frac{4}{3} \\pi) \\\\ f_{Cc}=\\frac{1}{2} N_{a}I_{m}\\cos(\\omega_{s} t-\\theta) + \\frac{1}{2} K_{c}I_{m}\\cos(\\omega_{s} t + \\theta-\\frac{2}{3} \\pi)) \\end{array}三相磁动势分布相加可得合成磁动势$F_{s}$： F_{s}=\\frac{3}{2} N_{a}I_{m}\\cos(\\omega_{s} t-\\theta)从合成磁动势可以发现它实质上是一个在同步电机气隙中保持同步电角速度旋转的正弦波磁动势，这个性质对于后续的分析非常重要，特别是对现代同步电机模型建立的理解极其有帮助 同步电机模型的模型建立正方向的确定在建立模型之前首先需要明确正方向，以便避免出现符号方向的混乱，对于同步发电机，本文采用发电机惯例来规定正方向。但是发电机惯例在物理理解上会绕一些，所以先用电动机惯例来说明，如图5所示。 图5 图5中，根据电动机惯例，端口是外部电源，电流流入端口的方向是正方向，电压正方向和电流方向同向。以图5中绕组向上轴线作为磁场的正方向，那么其感应出来的电动势为$e_{k}=-\\frac{d\\psi_{k}}{dt}=-p\\psi_{k}$，其中$p$是微分算子。由于，由电流生成的磁链$\\Psi_{k}$总是阻止电流变化，因此$p\\psi_{k}$的方向和电流相反，至此所有物理量正方向规定完成。如果采用发电机惯例，只需要将电流正方向反向即可这时候所有物理量正方向如图6所示： 图6 从图6可以推知基本的电路方程： \\begin{array}{c} u_{k}=-i_{k} R_{k}+p \\psi_{k} \\\\ \\psi_{k}=-l_{k} i_{k} \\end{array}其中下标$k$可以替换成后面三相所用的”a”、”b”、”c”。需要注意的是，因为电流和磁场一般满足右手螺旋定则，所以第二个式子电感$l_{k}$前有个负号。 A-B-C坐标参考系下的同步电机模型 图7 根据上一小节的正方向，可以推出每一相的的端口方程： \\begin{array}{l} e_{a}=\\frac{d \\psi_{a}}{d t}-R_{a} i_{a}=p \\psi_{a}-R_{a} i_{a} \\\\ e_{b}=\\frac{d \\psi_{b}}{d t}-R_{a} i_{a}=p \\psi_{b}-R_{a} i_{b} \\\\ e_{c}=\\frac{d \\psi_{c}}{d t}-R_{a} i_{a}=p \\psi_{c}-R_{a} i_{c} \\end{array}$e_{a}$、$e_{b}$、$e_{b}$分别是三相端口电压，$R_{a}$是定子每一相的电阻。可以看出要求出每一相电压，需要求出每一相的磁链，以A相磁链来说明。一般而言，同步电机由六个绕组组成，分别是三相定子绕组、转子励磁绕组f、转子等值绕组D（起阻尼作用）、转子等值绕组Q（起阻尼作用），如图7所示。这六个绕组的磁链互相交链，所以，考虑一般情况（稳态和动态），A相的磁链可以通过A相绕组电流、B相绕组电流、C相绕组电流、励磁绕组电流和两个等值绕组感应生成，用公式写成： \\psi_{a}=-l_{a a} i_{a}-l_{a b} i_{b}-l_{a c} i_{c}+l_{a f d} i_{f d}+l_{a k d} i_{k d}+l_{a k q} i_{k q}在上式中，$l_{a a}$是A相的自感电感，$l_{a b}$是A、B相的互感电感，$l_{a f d}$是A相、励磁绕组的互感电感，$l_{a k d}$是A相、等值绕组D的互感电感，$l_{a k q}$是A相、等值绕组Q的互感电感。同理可得其它相的磁链计算公式： \\begin{array}{l} \\psi_{b}=-l_{b b} i_{b}-l_{a b} i_{a}-l_{b c} i_{c}+l_{b f d} i_{f d}+l_{b k d} i_{k d}+l_{b k q} i_{k q} \\\\ \\psi_{c}=-l_{c c} i_{c}-l_{a c} i_{a}-l_{a c} i_{c}+l_{c f d} i_{f d}+l_{c k d} i_{k d}+l_{c k q} i_{k q} \\end{array}综上所述，三相绕组的磁链公式为： \\begin{array}{l} \\psi_{a}=-l_{a a} i_{a}-l_{a b} i_{b}-l_{a c} i_{c}+l_{a f d} i_{f d}+l_{a k d} i_{k d}+l_{a k q} i_{k q} \\\\ \\psi_{b}=-l_{b b} i_{b}-l_{a b} i_{a}-l_{b c} i_{c}+l_{b f d} i_{f d}+l_{b k d} i_{k d}+l_{b k q} i_{k q} \\\\ \\psi_{c}=-l_{c c} i_{c}-l_{a c} i_{a}-l_{a c} i_{c}+l_{c f d} i_{f d}+l_{c k d} i_{k d}+l_{c k q} i_{k q} \\end{array}再来看转子侧的电路方程，在转子侧我们采用电动机惯例，因此方程写成： \\begin{aligned} e_{f d} &=p \\psi_{f d}+R_{f d} i_{f d} \\\\ 0 &=p \\psi_{k d}+R_{k d} i_{k d} \\\\ 0 &=p \\psi_{k q}+R_{k q} i_{k q} \\end{aligned}其磁链方程写成： \\begin{array}{l} \\psi_{f d}=L_{f d} i_{f d}+L_{f d d} i_{k d}-L_{a f d}\\left[i_{a} \\cos \\theta+i_{b} \\cos \\left(\\theta-\\frac{2 \\pi}{3}\\right)+i_{c} \\cos \\left(\\theta+\\frac{2 \\pi}{3}\\right)\\right] \\\\ \\psi_{k d}=L_{f d d} i_{f d}+L_{k k d} i_{d d}-L_{a k d}\\left[i_{a} \\cos \\theta+i_{b} \\cos \\left(\\theta-\\frac{2 \\pi}{3}\\right)+i_{c} \\cos \\left(\\theta+\\frac{2 \\pi}{3}\\right)\\right] \\\\ \\psi_{k q}=L_{k k q} i_{k q}+L_{a k q}\\left[i_{a} \\sin \\theta+i_{b} \\sin \\left(\\theta-\\frac{2 \\pi}{3}\\right)+i_{c} \\sin \\left(\\theta+\\frac{2 \\pi}{3}\\right)\\right] \\end{array}上式中，$L_{f d d}$是励磁绕组和等值绕组d之间的互感，$L_{k k d}$是等值绕组d的自感，出现$L_{k k q}$是等值绕组q的自感，负号是因为定子绕组正方向规定采用了发电机惯例。 这时候出现的问题是，各个电感怎么得到我们依然不清楚，所以下面介绍求取各个电感的公式。注：关于同步电机各个电感的感性理解可以看何仰赞老师编写的《电力系统分析》第三章内容，他用图示的方式解释了同步电机大部分电感为什么是周期性变化的，这篇文章主要从数学公式上来解释这个现象。 以A相为例，首先看它的自感$l_{a a}$，$l_{a a}$是由A相电流自身通过气隙交链而表现出的电磁感应。A相的磁势$F_{a}$为正弦分布，幅值是$N_{a}i_{a}$，其中$N_{a}$是等效匝数，而且三相的等效匝数一般是相等的，$i_{a}$是A相电流瞬时值。如图8所示，其中的d轴是和转子直轴重合的，因此d轴保持同步转速转动，可以沿着d轴和q轴分解$F_{s}$，其d轴分量$F_{a d}$和q轴分量$F_{a q}$分别是： \\begin{array}{l} F_{a d}=N_{a} i_{a} \\cos \\theta \\\\ F_{a q}=N_{a} i_{a} \\cos \\left(\\theta+90^{\\circ}\\right)=-N_{a} i_{a} \\sin \\theta \\end{array}之所以选择这两个轴，是因为实际测量同步电机参数的时候，这两个方向比较容易测量。那么可以求得这两个方向上的气隙磁通： \\begin{array}{l} \\Phi_{g a d}=\\left(N_{a} i_{a} \\cos \\theta\\right) P_{d} \\\\ \\Phi_{g a q}=\\left(-N_{a} i_{a} \\sin \\theta\\right) P_{q} \\end{array}其中，$P_{d}$是直轴磁导，$P_{q}$是交轴磁导。 图8 d轴和q轴两个方向上的气隙磁通合成到A相上即可得到A相电流感应到自身的通过气隙磁通： \\begin{aligned} \\Phi_{g a a} &=\\Phi_{g a d} \\cos \\theta-\\Phi_{g a q} \\sin \\theta \\\\ &=N_{a} i_{a}\\left(P_{d} \\cos ^{2} \\theta+P_{q} \\sin ^{2} \\theta\\right) \\\\ &=N_{a} i_{a}\\left(\\frac{P_{d}+P_{q}}{2}+\\frac{P_{d}-P_{q}}{2} \\cos 2 \\theta\\right) \\end{aligned}那么，A相自身交链的磁链为： \\psi_{gaa}=N_{a}\\Phi_{g a a}因此，A相气隙自感可以求得： \\begin{aligned} l_{g a a} &=\\frac{N_{a} \\Phi_{g a a}}{i_{a}} \\\\ &=N_{a}^{2}\\left(\\frac{P_{d}+P_{q}}{2}+\\frac{P_{d}-P_{q}}{2} \\cos 2 \\theta\\right) \\\\ &=L_{g 0}+L_{a a 2} \\cos 2 \\theta \\end{aligned}考虑到漏电感$L_{a l}$，那么最终A相总自感为： \\begin{aligned} l_{a a} &=L_{a l}+l_{g a a} \\\\ &=L_{a l}+L_{g 0}+L_{a a 2} \\cos 2 \\theta \\\\ &=L_{a a 0}+L_{a a 2} \\cos 2 \\theta \\end{aligned}可以看出，A相自感是一个周期为$\\pi$的函数，同理可得其它相的自感： \\begin{array}{l} l_{b b}=L_{a a 0}+L_{a a 2} \\cos 2\\left(\\theta-\\frac{2 \\pi}{3}\\right) \\\\ l_{c c}=L_{a a 0}+L_{a a 2} \\cos 2\\left(\\theta+\\frac{2 \\pi}{3}\\right) \\end{array}再看定子相绕组之间的互感，因为互感是客观存在的，所以和电流是否存在无关，那么我们可以用A相电流交链到其它相的磁链来计算，以交链到B相为例，之前我们已经求到了气隙磁通的d轴分量和q轴分量，那么它们俩交链到B相的磁通$\\Phi_{g b a}$可以通过投影到B相轴线得到： \\begin{aligned} \\Phi_{g b a} &=\\Phi_{g a d} \\cos \\left(\\theta-\\frac{2 \\pi}{3}\\right)-\\Phi_{g a q} \\sin \\left(\\theta-\\frac{2 \\pi}{3}\\right) \\\\ &=N_{a} i_{a}\\left[\\mathrm{P}_{d} \\cos \\theta \\cos \\left(\\theta-\\frac{2 \\pi}{3}\\right)+\\mathrm{P}_{q} \\sin \\theta \\sin \\left(\\theta-\\frac{2 \\pi}{3}\\right)\\right] \\\\ &=N_{a} i_{a}\\left[-\\frac{\\mathrm{P}_{d}+\\mathrm{P}_{q}}{4}+\\frac{\\mathrm{P}_{d}-\\mathrm{P}_{q}}{2} \\cos \\left(2 \\theta-\\frac{2 \\pi}{3}\\right)\\right] \\end{aligned}因此，A相和B相的气隙互感为： \\begin{aligned} l_{g b a} &=\\frac{N_{a} \\Phi_{g b a}}{i_{a}} \\\\ &=-\\frac{1}{2} L_{g 0}+L_{a b 2} \\cos \\left(2 \\theta-\\frac{2 \\pi}{3}\\right) \\end{aligned}考虑到漏感$L_{abl}$，A相和B相的总互感为： \\begin{aligned} l_{a b}=l_{b a} &=L_{abl}+l_{g b a} \\\\ &=L_{abl}+\\frac{N_{a} \\Phi_{g b a}}{i_{a}} \\\\ &=L_{abl}-\\frac{1}{2} L_{g o}+L_{a b 2} \\cos \\left(2 \\theta-\\frac{2 \\pi}{3}\\right) \\\\ &= -L_{a b 0}+L_{a b 2} \\cos \\left(2 \\theta-\\frac{2 \\pi}{3}\\right) \\\\ &= -L_{a b 0}-L_{a b 2} \\cos \\left(2 \\theta+\\frac{\\pi}{3}\\right) \\end{aligned}同理可得其它相的互感： \\begin{array}{l} l_{b c}=l_{c b}=-L_{a b 0}-L_{a b 2} \\cos (2 \\theta-\\pi) \\\\ l_{c a}=l_{a c}=-L_{a b 0}-L_{a b 2} \\cos \\left(2 \\theta-\\frac{\\pi}{3}\\right) \\end{array}最后再看定子绕组和转子绕组之间的互感，因为转子的构造使得其在气隙形成的磁通是正弦分布的，而转子的磁势是恒定不变的，考虑两种情况，当转子和A相轴平行时，转子产生经过A相绕组的磁通最大，当转子和A相轴垂直时，转子产生通过A相绕组的磁通为零。因此可以推出A相和转子励磁绕组、两个等值绕组之间的互感： \\begin{aligned} l_{f d a }=l_{a f d} &=L_{a f d} \\cos \\theta \\\\ l_{k d a }=l_{a k d} &=L_{a k d} \\cos \\theta \\\\ l_{k q a }=l_{a k q} &=L_{a k q} \\cos \\left(\\theta+\\frac{\\pi}{2}\\right) \\\\ &=-L_{a k q} \\sin \\theta \\end{aligned}其它相绕组表达式类似，但是转子励磁绕组和等值绕组d的互感是常数，等值绕组q和励磁绕组、等值绕组d因为互相垂直而互感为零。 从前面的分析可以看出，在ABC坐标系下的同步电机电感随着转子转动发生周期性改变，这对于我们求解包含了磁链方程的电力系统微分方程带来了极大困难，因此需要找到合适的方法来克服这个困难。 d-q-0坐标参考系下的同步电机模型A-B-C坐标参考系下之所以出现同步电机电感参数周期性变化的原因是转子和三相电流发生相对运动，且转子是关于直轴或者交轴对称而不是随意对称的。为了避免参数的周期性变化怎么办呢？本质上就是转子运动引起的，我们能不能让转子“静止”呢？前面研究过合成磁势$F$的性质，它相对转子是静止的，而且合成磁势$F$在各相轴线的投影是各相磁势的瞬时值的某个倍数关系。同时，磁势和电流是成比例的关系，也就是说，我们可以虚拟一个合成电流$I$，它和合成磁势$F$有着相同的相位，在幅值上成比例关系，但是在各相轴线的投影是各相电流的瞬时值。我们可以画出这些量的相量图，假设各相轴线是各相电流的正方向，那么可以得到图9： 图9 当得到这个合成电流时，因为转子是关于关于直轴或者交轴对称，这两个方向的磁导是确定的，我们可以将合成电流投影到这两个方向，从而能够保证这两个方向的电感参数是固定的（电感和磁导成正比关系），这样可得： \\begin{array}{l} i_{\\mathrm{d}}=I \\cos (\\theta -\\alpha) \\\\ i_{\\mathrm{q}}=-I \\sin (\\theta-\\alpha) \\end{array}而定子三相电流瞬时值可以表示成： \\begin{array}{l} i_{\\mathrm{a}}=I \\cos \\theta \\\\ i_{\\mathrm{b}}=I \\cos \\left(\\theta-120^{\\circ}\\right) \\\\ i_{\\mathrm{c}}=I \\cos \\left(\\theta+120^{\\circ}\\right) \\end{array}合并两式即可消掉$\\theta$，得到： \\begin{array}{l} i_{d}=\\frac{2}{3} \\left[i_{a} \\cos \\theta+i_{b} \\cos \\left(\\theta-\\frac{2 \\pi}{3}\\right)+i_{c} \\cos \\left(\\theta+\\frac{2 \\pi}{3}\\right)\\right] \\\\ i_{q}=-\\frac{2}{3}\\left[i_{a} \\sin \\theta+i_{b} \\sin \\left(\\theta-\\frac{2 \\pi}{3}\\right)+i_{c} \\sin \\left(\\theta+\\frac{2 \\pi}{3}\\right)\\right] \\end{array}也就是说，我们用$i_{d}$、$i_{q}$两个电流来表征三相电流，在三相平衡系统中是成立的，因为三相电流之和为0，也就是说只有两个自由度，用两个量就可以完整表征。但是在三相不平衡的情况中，因为存在零序电流，需要三个自由度来表征三相系统，所以我们单独将零序电流$i_{0}$拎出来表示： i_{0}=\\frac{1}{3}\\left(i_{a}+i_{b}+i_{c}\\right)用矩阵表示上述过程为： \\left[\\begin{array}{c} i_{d} \\\\ i_{q} \\\\ i_{0} \\end{array}\\right]=\\frac{2}{3}\\left[\\begin{array}{ccc} \\cos \\theta & \\cos \\left(\\theta-\\frac{2 \\pi}{3}\\right) & \\cos \\left(\\theta+\\frac{2 \\pi}{3}\\right) \\\\ -\\sin \\theta & -\\sin \\left(\\theta-\\frac{2 \\pi}{3}\\right) & -\\sin \\left(\\theta+\\frac{2 \\pi}{3}\\right) \\\\ \\frac{1}{2} & \\frac{1}{2} & \\frac{1}{2} \\end{array}\\right]\\left[\\begin{array}{c} i_{a} \\\\ i_{b} \\\\ i_{c} \\end{array}\\right]其中， \\Gamma =\\frac{2}{3}\\left[\\begin{array}{ccc} \\cos \\theta & \\cos \\left(\\theta-\\frac{2 \\pi}{3}\\right) & \\cos \\left(\\theta+\\frac{2 \\pi}{3}\\right) \\\\ -\\sin \\theta & -\\sin \\left(\\theta-\\frac{2 \\pi}{3}\\right) & -\\sin \\left(\\theta+\\frac{2 \\pi}{3}\\right) \\\\ \\frac{1}{2} & \\frac{1}{2} & \\frac{1}{2} \\end{array}\\right]$\\Gamma$称之为帕克矩阵，它能将三相物理量变换到d-q轴上，相应的逆变换为： \\left[\\begin{array}{c} i_{a} \\\\ i_{b} \\\\ i_{c} \\end{array}\\right]=\\left[\\begin{array}{ccc} \\cos \\theta & -\\sin \\theta & 1 \\\\ \\cos \\left(\\theta-\\frac{2 \\pi}{3}\\right) & -\\sin \\left(\\theta-\\frac{2 \\pi}{3}\\right) & 1 \\\\ \\cos \\left(\\theta+\\frac{2 \\pi}{3}\\right) & -\\sin \\left(\\theta+\\frac{2 \\pi}{3}\\right) & 1 \\end{array}\\right]\\left[\\begin{array}{c} i_{d} \\\\ i_{q} \\\\ i_{0} \\end{array}\\right]即： \\Gamma^{-1}=\\left[\\begin{array}{ccc} \\cos \\theta & -\\sin \\theta & 1 \\\\ \\cos \\left(\\theta-\\frac{2 \\pi}{3}\\right) & -\\sin \\left(\\theta-\\frac{2 \\pi}{3}\\right) & 1 \\\\ \\cos \\left(\\theta+\\frac{2 \\pi}{3}\\right) & -\\sin \\left(\\theta+\\frac{2 \\pi}{3}\\right) & 1 \\end{array}\\right]利用帕克矩阵对前述的$\\psi_{a}$，$ \\psi_{b}$ ，$\\psi_{c}$变换到d-q-0坐标下，可得： \\begin{array}{l} \\psi_{d}=-\\left(L_{a a 0}+L_{a b 0}+\\frac{3}{2} L_{a a 2}\\right) i_{d}+L_{a f d} i_{f a}+L_{a k d} i_{k d} \\\\ \\psi_{q}=-\\left(L_{a a 0}+L_{a b 0}-\\frac{3}{2} L_{a a 2}\\right) i_{q}+L_{a k q} i_{k q} \\\\ \\psi_{0}=-\\left(L_{a a l}-2 L_{a b 0}\\right) i_{0} \\end{array}令 \\begin{array}{l} L_{d}=L_{a a 0}+L_{a b 0}+\\frac{3}{2} L_{a a 2}\\\\ L_{q}=L_{a a 0}+L_{a b 0}-\\frac{3}{2} L_{a a 2} \\\\ L_{0}=L_{a a 0}-2 L_{a b 0} \\end{array}那么有： \\begin{array}{l} \\psi_{d}=-L_{d} i_{d}+L_{a f d} i_{f d}+L_{a k d} i_{k d} \\\\ \\psi_{q}=-L_{q} i_{q}+L_{a k q} i_{k q} \\\\ \\psi_{0}=-L_{0} i_{0} \\end{array}可以看到，在d-q-0坐标系下，所有的定子侧电感参数为常数，大大降低了计算复杂度。 在转子侧，也能对其中的三相电流用d-q-0电流替换得到： \\begin{array}{l} \\psi_{f d}=L_{ff d} i_{f d}+L_{f d d} i_{d d}-\\frac{3}{2} L_{a f d} i_{d} \\\\ \\psi_{k d}=L_{f d} i_{f d}+L_{k k d} i_{k d}-\\frac{3}{2} L_{a k d} i_{d} \\\\ \\psi_{k q}=L_{k k q} i_{k q}-\\frac{3}{2} L_{a k q} i_{q} \\end{array}对定子每一相的的端口方程$e_{a}$、$e_{b}$、$e_{b}$进行帕克变换可以得到： \\begin{array}{l} e_{d}=p \\psi_{d}-\\psi_{q} p \\theta-R_{a} i_{d}=p \\psi_{d}-\\psi_{q} \\omega_{s}-R_{a} i_{d} \\\\ e_{q}=p \\psi_{q}+\\psi_{d} p \\theta-R_{a} i_{q} =p \\psi_{q}+\\psi_{d} \\omega_{s}-R_{a} i_{q} \\\\ e_{0}=p \\psi_{0}-R_{a} i_{0} \\end{array}注：何仰赞老师的《电力系统分析》第三章有更加清楚的推导过程，这里不再赘述（其实是因为这个变换算起来真滴是太恐怖了！）。从d-q-0坐标系下的电压方程可以看出，电压主要由两部分组成：表征变压器电压的$p \\psi_{d}$和表征切割电势的$\\psi_{q} \\omega_{s}$。在这里，我们可以大概地理解一下，首先，因为转子产生的正弦磁场切割导体，所以必然产生正弦电压；其次，转子磁势利用磁场对转子绕组和定子绕组进行耦合，进行能量转换，因此这相当一台变压器，但因为转子磁势相对于定子合成磁势是静止的，只要两个磁势没有发生变化，磁链也不会改变，因此在稳态下是不会有变压器电压的，在暂态下，因为改变了耦合磁链的大小，因此产生了变压器电压。总而言之，d-q-0坐标系下的电压方程是适合稳态和动态情况的一般方程。 在获得d-q-0坐标系下的电压电流后，同步电机的输出功率也可以求出来了： \\begin{aligned} P_{t}&=e_{a} i_{a}+e_{b} i_{b}+e_{c} i_{c} \\\\ &= \\frac{3}{2}(e_{d} i_{d}+e_{q} i_{q}+2 e_{0} i_{0})\\\\ \\end{aligned}进一步用磁链替换掉电压可得： \\begin{array}{c} P_{t}=\\frac{3}{2}\\left[\\left(i_{d} p \\psi_{d}+i_{q} p \\psi_{q}+2 i_{0} p \\psi_{0}\\right)\\right. \\\\ +\\left(\\psi_{d} i_{q}-\\psi_{q} i_{d}\\right) \\omega_{s} \\\\ \\left.-\\left(i_{d}^{2}+i_{q}^{2}+2 i_{0}^{2}\\right) R_{a}\\right] \\end{array}第一行代表了定子磁能，第二行代表气隙传输的能量，第三行代表的是定子铜损。那么气隙中的力矩（电磁力矩）应该通过气隙传输的能量（电磁功率）来进行计算，即： \\begin{aligned} T_{e} &=\\frac{3}{2}\\left(\\psi_{d} i_{q}-\\psi_{q} i_{d}\\right) \\frac{\\omega_{s}}{\\omega_{m e c h}} \\\\ &=\\frac{3}{2}\\left(\\psi_{d} i_{q}-\\psi_{q} i_{d}\\right) \\frac{p_{f}}{2} \\end{aligned}$\\omega_{m e c h}$是转子机械角速度，$p_{f}$是转子极数。 因为前述都是用有名值来表示的，其中的一些系数既不便于计算，也不便于理解，因此需要采用标幺化来去除系数，具体标幺过程可见kundur原书，如果没有特别说明，后续给出符号均为标幺值，这里只给出标幺后的标准方程： 电压方程： \\begin{array}{l} e_{d}=p \\psi_{d}-\\omega_{s} \\psi_{q}-R_{a} i_{d} \\\\ e_{q}=p \\psi_{q}+\\omega_{s} \\psi_{d}-R_{a} i_{q} \\\\ e_{0}=p \\psi_{0}-R_{a} i_{0} \\\\ e_{fd}=p \\psi_{fd}+r_{fd}i_{fd} \\\\ 0=p \\psi_{kd}+r_{kd} i_{kd} \\\\ 0=p \\psi_{kq}+r_{kq} i_{kq} \\end{array}磁链方程： \\begin{array}{l} \\psi_{d}=-L_{d} i_{d}+L_{a f d} i_{f d}+L_{a k d} i_{k d} \\\\ \\psi_{q}=-L_{q} i_{q}+L_{a k q} i_{kq} \\\\ \\psi_{0}=-L_{0} i_{0} \\\\ \\psi_{f d}=L_{ff d} i_{f d}+L_{f k d} i_{k d}-L_{f d a} i_{d} \\\\ \\psi_{k d}=L_{k d f} i_{f d}+L_{k k d} i_{k d}-L_{k d a} i_{d} \\\\ \\psi_{k q}=L_{k k q} i_{k q}-L_{k q a} i_{q} \\end{array}其中，$L_{d}$可以拆分为直轴漏电感$L_{l}$和直轴电枢电感$L_{ad}$，$L_{q}$可以拆分为交轴漏电感$L_{l}$和交轴电枢电感$L_{aq}$，具体表达式为： \\begin{array}{l} L_{d}=L_{l}+L_{a d} \\\\ L_{q}=L_{l}+L_{a q} \\end{array}之所以这么拆分，是因为$L_{d}$的公式为$L_{d}=L_{a a 0}+L_{a b 0}+\\frac{3}{2} L_{a a 2}$，包含了漏电感和主电感，因此即便经过d-q-0变换之后，也存在漏电感和主电感。$-L_{a d}i_{d}$表示合成磁势对应下的主磁通（链），$-L_{l}i_{d}$ 表示定子侧的漏磁通（链），可以用图10来进一步说明： 图10 假设图10中S-S’线圈是三相经过d-q-0变换而合成的定子虚拟线圈，它和d-q-0参考轴一样是保持同步转速转动，因此它俩相对静止。这里只考虑稳态情况以及只看定子虚拟线圈的d轴磁通分量（q轴类似分析方式），那么D线圈中电流为0（没有电源），只有虚拟合成线圈和励磁线圈f具有电流，在稳态下，对于每个线圈d轴方向来说，都有两个磁路：一个是磁阻很小的铁芯磁路（大红圈的路径），另一个是每个线圈附近也有磁阻很大的空气回路（小红圈的路径）。那么从定子侧来看，磁通包含两部分:虚拟合成线圈电流和励磁线圈f电流综合起来的合成磁势所产生的主磁通$\\Phi_{ad}$（大红圈）穿越气隙之后很自然地走磁导大的地方，也有一小部分磁通$\\Phi_{al}$走空气回路。用公式表示则是： \\begin{array}{l} \\Phi_{ad} =F_{ad}P_{ad} \\\\ \\Phi_{al} =F_{ad}P_{al} \\\\ \\Phi_{ad}+\\Phi_{al} = F_{ad}(P_{ad}+P_{al} )=F_{ad}P_{d} \\end{array}其中，$P_{ad}$是铁芯磁路的磁导，$P_{al}$是虚拟合成线圈经过空气回路的磁导，那么它们磁导和为$P_{d}$。而磁导$P$和电感$L$是成正比的，具体公式为： L=N^{2}P其中，$N$为线圈匝数。因此很容易得到，$L_{d}=L_{l}+L_{a d}$，其它线圈也有相同性质，全部写在一起就是： \\begin{array}{l} L_{d}=L_{l}+L_{a d} \\\\ L_{q}=L_{l}+L_{a q} \\\\ L_{ff d} =L_{fl}+L_{a d} \\\\ L_{kd f} =L_{kdl}+L_{a d} \\\\ L_{kq f} =L_{kql}+L_{a q} \\\\ \\end{array}那么，励磁线圈在计算通过自己磁链，考虑定子电流对它的影响时，电感就应该是$L_{a d}$，定子电流交链励磁绕组的磁通就是$L_{ad} i_{d}$，这部分磁通不是图10所画的大红线，因为大红线是励磁电流和虚拟合成线圈电流最终合成磁场的d轴方向。从这里可以推知： L_{f d a}=L_{a d}同样的， \\begin{array}{l} L_{f d a}=L_{a d} \\\\ L_{k d a}=L_{a d} \\\\ L_{k q a}=L_{a q} \\end{array}综上所述，最后的标准方程可以写成： 电压方程： \\begin{array}{l} e_{d}=p \\psi_{d}-\\omega_{s} \\psi_{q}-R_{a} i_{d} \\\\ e_{q}=p \\psi_{q}+\\omega_{s} \\psi_{d}-R_{a} i_{q} \\\\ e_{0}=p \\psi_{0}-R_{a} i_{0} \\\\ e_{fd}=p \\psi_{fd}+r_{fd}i_{fd} \\\\ 0=p \\psi_{kd}+r_{kd} i_{kd} \\\\ 0=p \\psi_{kq}+r_{kq} i_{kq} \\end{array}磁链方程： \\begin{array}{l}\\psi_{d}=-L_{d} i_{d}+L_{a d} i_{f d}+L_{a d} i_{k d} \\\\ \\psi_{q}=-L_{q} i_{q}+L_{a q} i_{kq} \\\\ \\psi_{0}=-L_{0} i_{0} \\\\ \\psi_{f d}=L_{ff d} i_{f d}+L_{f k d} i_{k d}-L_{ad} i_{d} \\\\ \\psi_{k d}=L_{k d f} i_{f d}+L_{k k d} i_{k d}-L_{ad} i_{d} \\\\ \\psi_{k q}=L_{k k q} i_{k q}-L_{aq} i_{q} \\end{array}而输出功率和电磁转矩分别为： P_{t}=e_{d} i_{d}+e_{q} i_{q}+2 e_{0} i_{0} T_{e}=\\psi_{d} i_{q}-\\psi_{q} i_{d}同步电机的稳态模型分析前面建立的是同步电机的通用模型，为了更加清晰地分析同步电机的物理规律，可以分成稳态模型和动态模型来分析，这小节介绍的就是稳态模型。在这里，我们考虑凸极机的稳态模型，更具有通用性，如果是隐极机，把d轴和q轴方向的阻抗看成相等代入计算即可。 建立稳态模型时，我们希望用一个包含电源、电阻、阻抗的单端口电路来表征同步电机稳态特性，因此只需要将电源电势、电阻、阻抗等效出来即可。首先求电源电势，那么就需要列出三相的电势方程： \\begin{array}{l} e_{a}=E_{m} \\cos \\left(\\omega_{s} t+\\alpha\\right) \\\\ e_{b}=E_{m} \\cos \\left(\\omega_{s} t-\\frac{2 \\pi}{3}+\\alpha\\right) \\\\ e_{c}=E_{m} \\cos \\left(\\omega_{s} t+\\frac{2 \\pi}{3}+\\alpha\\right) \\end{array}其中，$E_{m}$是电势幅值，$\\alpha$是A相电势相角。对上述方程进行帕克变换得到： \\begin{array}{l} e_{d}=E_{t} \\cos \\left(\\omega_{s} t+\\alpha-\\theta\\right) \\\\ e_{q}=E_{t} \\sin \\left(\\omega_{s} t+\\alpha-\\theta\\right) \\end{array}而其中，$\\theta=\\omega_{s} t+\\theta_{0}$，$\\theta_{0}$是初始空间位置，$E_{t}$是经过变换之后的电势幅值。所以进一步简化得到： \\begin{array}{l} e_{d}=E_{t} \\cos \\left(\\alpha-\\theta_{0}\\right)=E_{t} \\cos \\delta_{i} \\\\ e_{q}=E_{t} \\sin \\left(\\alpha-\\theta_{0}\\right)=E_{t} \\cos \\delta_{i} \\end{array}那么端口电压的复数形式$\\tilde{E}_{t}$为: \\tilde{E}_{t}=e_{d}+j e_{q}假设端口电流$I_{t}$和端口电压的夹角为$\\phi$，那么端口电流的表达式可以写成： \\begin{array}{l} i_{d}=I_{t} \\sin \\left(\\delta_{i}+\\phi\\right) \\\\ i_{q}=I_{t} \\cos \\left(\\delta_{i}+\\phi\\right) \\end{array}同样地，端口电流复数形式$\\tilde{E}_{t}$为: \\tilde{I}_{t}=i_{d}+j i_{q}上述过程更明确的理解可以参考图11： 图11 为了用端口电流表示端口电压，可以利用$\\tilde{E}_{t}=e_{d}+j e_{q}$和之前建立的标准电压方程来一起推导，由于稳态下没有变压器电势和等值绕组Q和D的电流，因此电压方程可以写成： \\begin{array}{l} e_{d}=-\\omega_{s} \\psi_{q}-R_{a} i_{d}=\\omega_{s}L_{q}i_{q}-R_{a} i_{d}=X_{q}i_{q}-R_{a} i_{d} \\\\ e_{q}=\\omega_{s} \\psi_{d}-R_{a} i_{q}=-\\omega_{s}L_{d}i_{d}+\\omega_{s}L_{ad}i_{fd}-R_{a} i_{d}=-X_{d}i_{d}+X_{ad}i_{fd}-R_{a} i_{q} \\end{array}那么， \\begin{aligned} \\tilde{E}_{t} &=e_{d}+j e_{q} \\\\ &= X_{q}i_{q}-R_{a} i_{d}+j(-X_{d}i_{d}+X_{ad}i_{fd}-R_{a} i_{q} ) \\end{aligned}为了加入端口电流，而且能使方程更加简化，可以在左侧加上一个电抗项$jX_{q}\\tilde{I}_{t}$： \\tilde{E}_{t}+jX_{q}\\tilde{I}_{t}=X_{q}i_{q}-R_{a} i_{d}+j(-X_{d}i_{d}+X_{ad}i_{fd}-R_{a} i_{q} )+jX_{q}\\tilde{I}_{t}进一步将右边整理得到： \\tilde{E}_{t}+(R_{a}+jX_{q})\\tilde{I}_{t}=j(-(X_{d}-X_{q})i_{d}+X_{ad}i_{fd})再虚拟一个电源电势$\\tilde{E}_{q}=j(-(X_{d}-X_{q})i_{d}+X_{ad}i_{fd})$，那么有： \\tilde{E}_{q}=\\tilde{E}_{t}+(R_{a}+jX_{q})\\tilde{I}_{t}电源电势里面包含的$jX_{ad}i_{fd}$项是空载电势，如果用这个来表示同步电机稳态模型，只能用两个电路分别表征d轴和q轴模型，虚拟电源电势则很好解决了这个问题，这个包含虚拟电源电势的电路图可以画成图12： 图12 而相量图可以画成： 图13 其中，$\\delta_{i}$是熟知的功角，为虚拟电源电势和端口电压的夹角，而虚拟电源电势的方向和空载电势方向是一样的，所以直观来看就是空载电势和端口电压的夹角，转子拖着负载在转，负载越大，功角越大。 同步电机动态条件下的建模分析这小节并不打算讨论同步电机基于微分代数方程的动态行为，而是通过简化，了解发生故障后同步电机的发展过程，侧重分析瞬间短路电流的大小程度。 在发生短路之后，同步发电机的磁链不会发生突变，为了抵消定子侧因巨大而产生巨大的去磁短路电流，励磁绕组和等值绕组D、Q都会产生额外的电流，以保持各自线圈通过的磁链不变。感性一点来看，在短路瞬间，转子励磁线圈产生的磁场在定子三相达到某个磁链值，从定子侧来看，各相必然要产生直流电流来维持这个初始值，而转子的磁场会继续同步旋转，因此各相还会有交流电流。这样一来，转子侧的磁场又要发生改变，所以转子各线圈电流也会相应包含交流电流和直流电流。因此可以推知的是，在短路条件下，同步电机内包含了两部分力矩：转子侧直流和定子侧交流、转子侧交流和定子侧直流产生的同步制动转矩；转子侧直流和定子侧直流产生的交变转矩，其方向每半个周期变化一次。 各个线圈电流的突变量所包含的能量最后都会消耗在各自包含的电阻中，根据线圈电阻和电感参数的不同，等值绕组突变量最先消失，它消失前的阶段称为次暂态过程；接着是励磁线圈突变量的消耗，这个过程称为暂态过程。因此接下来，分别介绍这两个过程突变瞬间的等效电路。注：下面分析与kundur的书略有不同，因为kundur的书中转子有两个等值绕组D和两个等值绕组Q，而本文中转子只有一个等值绕组D和一个等值绕组Q，不过分析思路是一样的。 衰减图如图14所示： 图14 次暂态过程模型根据磁链方程： \\begin{array}{l} \\psi_{d}=-L_{d} i_{d}+L_{a d} i_{f d}+L_{a d} i_{k d} \\\\ \\psi_{q}=-L_{q} i_{q}+L_{a q} i_{kq} \\\\ \\psi_{0}=-L_{0} i_{0} \\\\ \\psi_{f d}=L_{ff d} i_{f d}+L_{f k d} i_{k d}-L_{ad} i_{d} \\\\ \\psi_{k d}=L_{k d f} i_{f d}+L_{k k d} i_{k d}-L_{ad} i_{d} \\\\ \\psi_{k q}=L_{k k q} i_{k q}-L_{aq} i_{q} \\end{array}可以先建立各轴等效电路图： 图15 d轴等效电路图 图16 q轴等效电路图 这里之所以要画出这两个等效电路图是因为根据标准电压方程： \\begin{array}{l} e_{d}=p \\psi_{d}-\\omega_{s} \\psi_{q}-R_{a} i_{d} \\\\ e_{q}=p \\psi_{q}+\\omega_{s} \\psi_{d}-R_{a} i_{q} \\end{array}在短路瞬间，假设没有变压器电势，而且电角速度不会突变（状态变量不突变），则$\\omega_{s}=1$，那么标准电压方程可以写成： \\begin{array}{l} e_{d}=-\\psi_{q}-R_{a} i_{d} \\\\ e_{q}=\\psi_{d}-R_{a} i_{q} \\end{array}也就是说，只要知道$\\psi_{q}$、$\\psi_{d}$就可以求得次暂态模型等效电路图的端口电压$\\tilde{E}_{t} =e_{d}+j e_{q}$。对图15、图16分别进行戴维南等值可以得到等效电源电势： \\begin{aligned} E_{q}^{\\prime \\prime}&=\\frac{\\frac{\\psi_{fd}}{L_{fl}}+\\frac{\\psi_{kd}}{L_{fdl}}}{\\frac{1}{L_{ad}}+\\frac{1}{L_{fl}}+\\frac{1}{L_{kdl}}} \\\\ &= \\frac{1}{\\frac{1}{L_{ad}}+\\frac{1}{L_{fl}}+\\frac{1}{L_{kdl}}}\\left(\\frac{\\psi_{fd}}{L_{fl}}+\\frac{\\psi_{kd}}{L_{kdl}}\\right) ) \\\\ &= L_{ad}^{\\prime \\prime}\\left(\\frac{\\psi_{fd}}{L_{fl}}+\\frac{\\psi_{kd}}{L_{kdl}}\\right) \\end{aligned}因为$\\omega_{s}=1$，上式可以写成电抗形式： \\begin{aligned} E_{q}^{\\prime \\prime}&=\\frac{\\frac{\\psi_{fd}}{X_{fl}}+\\frac{\\psi_{kd}}{X_{fdl}}}{\\frac{1}{X_{ad}}+\\frac{1}{X_{fl}}+\\frac{1}{X_{kdl}}} \\\\ &= \\frac{1}{\\frac{1}{X_{ad}}+\\frac{1}{X_{fl}}+\\frac{1}{X_{kdl}}}\\left(\\frac{\\psi_{fd}}{X_{fl}}+\\frac{\\psi_{kd}}{X_{kdl}}\\right) ) \\\\ &= X_{ad}^{\\prime \\prime}\\left(\\frac{\\psi_{fd}}{X_{fl}}+\\frac{\\psi_{kd}}{X_{kdl}}\\right) \\end{aligned}而d轴等效电抗（也称为次暂态d轴电抗）则为： \\begin{aligned} X_{d}^{\\prime \\prime}&=X_{l}+\\frac{1}{\\frac{1}{X_{ad}}+\\frac{1}{X_{fl}}+\\frac{1}{X_{kdl}}} \\\\ &= X_{l}+X_{ad}^{\\prime \\prime} \\end{aligned}那么d轴等效电路图的戴维南形式为图17： 图17 d轴戴维南等效电路图 采用同样的方式，q轴等效电源电势和等效电抗为： \\begin{aligned} -E_{d}^{\\prime \\prime}&=\\frac{\\frac{\\psi_{kq}}{X_{fql}}}{\\frac{1}{X_{aq}}+\\frac{1}{L_{kql}}} \\\\ &= \\frac{1}{\\frac{1}{X_{aq}}+\\frac{1}{X_{kql}}}\\frac{\\psi_{kq}}{X_{kql}}\\\\ &= X_{aq}^{\\prime \\prime}\\frac{\\psi_{kq}}{X_{kql}} \\end{aligned}这里左侧加了符号纯粹是为了后面简化，而q轴等效电抗（也称为次暂态q轴电抗）则为： \\begin{aligned} X_{q}^{\\prime \\prime}&=X_{l}+\\frac{1}{\\frac{1}{X_{aq}}+\\frac{1}{X_{kql}}} \\\\ &= X_{l}+X_{aq}^{\\prime \\prime} \\end{aligned}那么q轴等效电路图的戴维南形式为图18： 图18 q轴戴维南等效电路图 那么标准电压方程可以进一步改写成： \\begin{array}{l} e_{d}=E_{d}^{\\prime \\prime}+X_{q}^{\\prime \\prime} i_{q}-R_{a} i_{d} \\\\ e_{q}=E_{q}^{\\prime \\prime}-X_{d}^{\\prime \\prime} i_{d}-R_{a} i_{q} \\end{array}那么，次暂态模型等效电路端口电压$\\tilde{E}_{t}$为： \\begin{aligned} \\tilde{E}_{t} &=e_{d}+j e_{q} \\\\ &= E_{d}^{\\prime \\prime}+X_{q}^{\\prime \\prime} i_{q}-R_{a} i_{d} +j(E_{q}^{\\prime \\prime}-X_{d}^{\\prime \\prime} i_{d}-R_{a} i_{q} ) \\\\ &=E_{d}^{\\prime \\prime}+jE_{q}^{\\prime \\prime}-R_{a} \\tilde{I}_{t}+X_{q}^{\\prime \\prime} i_{q}-jX_{d}^{\\prime \\prime} i_{d} \\\\ &=E^{\\prime \\prime}-R_{a} \\tilde{I''}_{t}+X_{q}^{\\prime \\prime} i_{q}-jX_{d}^{\\prime \\prime} i_{d} \\end{aligned}其中，$E^{\\prime \\prime}$称之为次暂态电源电势，$\\tilde{I’’}_{t}$为次暂态模型等效电路端口电流，可以在左侧加上一个电抗项$jX’’_{d}\\tilde{I}_{t}$： \\tilde{E}_{t}+jX''_{d}\\tilde{I}_{t}=E^{\\prime \\prime}-R_{a} \\tilde{I''}_{t}+X_{q}^{\\prime \\prime} i_{q}-jX_{d}^{\\prime \\prime} i_{d}+jX''_{d}\\tilde{I}_{t}整理得到： \\tilde{E}_{t}+(R_{a} +jX''_{d})\\tilde{I}_{t}=E^{\\prime \\prime}+(X_{q}^{\\prime \\prime}-X_{d}^{\\prime \\prime} ) i_{q}一般在次暂态过程中，$X_{q}^{\\prime \\prime}\\approx X_{d}^{\\prime \\prime}$，$X_{q}-X_{d}^{\\prime}$可以忽略，所以次暂态模型等效电路可以简化为： \\tilde{E}_{t}=E^{\\prime \\prime}-(R_{a} +jX''_{d})\\tilde{I}_{t}所以次暂态模型等效电路为图19： 图19 次暂态模型等效电路 在次暂态过程中造成的电流最大，因为$X_{d}&gt;X’’_{d}$，但是相比暂态过程，其衰减也是最快的。 暂态过程模型暂态模型推导过程和次暂态模型推导过程类似，只不过等值绕组D和Q的电流此时已经衰减到0了，即$i_{k d}=i_{k q}=0$只有励磁线圈还有电流突变量。那么根据磁链方程，可以先建立暂态模型各轴等效电路图： 图20 d轴等效电路图 图21 q轴等效电路图 对图20、图21分别进行戴维南等值可以得到等效电源电势： \\begin{aligned} E_{q}^{\\prime}&=\\frac{\\frac{\\psi_{fd}}{L_{fl}}}{\\frac{1}{L_{ad}}+\\frac{1}{L_{fl}}} \\\\ &= \\frac{1}{\\frac{1}{L_{ad}}+\\frac{1}{L_{fl}}}\\frac{\\psi_{fd}}{L_{fl}} \\\\ &= L_{ad}^{\\prime}\\frac{\\psi_{fd}}{L_{fl}} \\end{aligned}同样假设没有变压器电势，而且电角速度不会突变（状态变量不突变），那么$\\omega_{s}=1$，上式可以写成电抗形式： \\begin{aligned} E_{q}^{\\prime}&=\\frac{\\frac{\\psi_{fd}}{X_{fl}}}{\\frac{1}{X_{ad}}+\\frac{1}{X_{fl}}} \\\\ &= \\frac{1}{\\frac{1}{X_{ad}}+\\frac{1}{X_{fl}}}\\frac{\\psi_{fd}}{X_{fl}} \\\\ &= X_{ad}^{\\prime}\\frac{\\psi_{fd}}{L_{fl}} \\end{aligned}而d轴等效电抗（也称为次暂态d轴电抗）则为： \\begin{aligned} X_{d}^{ \\prime}&=X_{l}+\\frac{1}{\\frac{1}{X_{ad}}+\\frac{1}{X_{fl}}} \\\\ &= X_{l}+X_{ad}^{\\prime} \\end{aligned}那么d轴等效电路图的戴维南形式为图22： 图22 d轴戴维南等效电路图 q轴因为没有等值绕组而不存在相应的等效电路。 那么标准电压方程可以进一步改写成： \\begin{array}{l} e_{d}=X_{q} i_{q}-R_{a} i_{d} \\\\ e_{q}=E_{q}^{\\prime}-X_{d}^{\\prime} i_{d}-R_{a} i_{q} \\end{array}那么，暂态模型等效电路端口电压$\\tilde{E}_{t}$为： \\begin{aligned} \\tilde{E}_{t} &=e_{d}+j e_{q} \\\\ &= X_{q} i_{q}-R_{a} i_{d}+j(E_{q}^{\\prime}-X_{d}^{\\prime} i_{d}-R_{a} i_{q} )\\\\ &= X_{q} i_{q}+j(E_{q}^{\\prime}-X_{d}^{\\prime} i_{d})-R_{a} \\tilde{I'}_{t} \\end{aligned}其中，$\\tilde{I’}_{t}$为暂态模型等效电路端口电流，可以在左侧加上一个电抗项$jX’_{d}\\tilde{I}_{t}$： \\tilde{E}_{t}+jX'_{d}\\tilde{I}_{t}=jE^{\\prime}_{q}-R_{a} \\tilde{I}_{t}+X_{q} i_{q}-jX_{d}^{\\prime} i_{d}+jX'_{d}\\tilde{I}_{t}整理得到： \\tilde{E}_{t}+(R_{a} +jX'_{d})\\tilde{I}_{t}=jE^{\\prime}_{q}+(X_{q}-X_{d}^{\\prime} ) i_{q}一般在暂态过程中，$X_{q}&gt; X_{d}^{\\prime}$，$X_{q}-X_{d}^{\\prime}$不能忽略，所以次暂态模型等效电路可以简化为： \\tilde{E}_{t}=E^{\\prime}-(R_{a} +jX'_{d})\\tilde{I}_{t}其中，$E^{\\prime}=jE^{\\prime}_{q}+(X_{q}-X_{d}^{\\prime} ) i_{q}$ 所以暂态模型等效电路为图23： 图23 暂态模型等效电路 在暂态过程中造成的电流比次暂态模型小，但比稳态模型大，因为$X_{d}&gt;X’_{d}&gt;X’’_{d}$，当暂态过程也衰减完之后，就过渡到稳态模型了。","link":"/2020/05/21/Power%20System%20Stability%20and%20Control%20(Kundur)----%E5%90%8C%E6%AD%A5%E7%94%B5%E6%9C%BA/"},{"title":"《临江仙》临摹作品","text":"首页摘要： 第一幅临摹作品。 《临江仙》临摹作品","link":"/2020/09/12/%E4%B8%B4%E6%B1%9F%E4%BB%99%E4%B8%B4%E6%91%B9/"},{"title":"Power System Stability and Control (Kundur)----第二章","text":"首页摘要： 本章主要介绍电力系统稳定问题的定义和分类，目的在于给出对电力系统稳定问题一个大概的了解，数学上具体的分析会在后续章节中给出。 电力系统稳定是指在正常运行状态下保持运行平衡点或者在遭受故障后重新到达可接受的状态平衡点，这是电力系统安全运行最基本的要求。从物理特性上，电力系统稳定问题可以分为功角稳定和电压稳定问题，前者表现为发电机转子之间的功角是否发生偏离，后者则表现为电压是否能够维持在一定范围内。但是，一旦电力系统发生稳定问题，两者总是交织在一起，例如，发生短路故障，可能既出现功角分离，也出现电压崩溃。然而，分别对它们的特性、影响因素进行分析理解并给出相应的反制措施对电力系统运行预控制而言是非常有必要的。 此外，在时间尺度上也可以将电力系统分为短期、中期、长期稳定问题，但是它们并没有绝对的区分界限，因此在本文中只做简要的介绍，并没有从机理上对其详细分析。 功角稳定问题功角稳定指的是发电机转子之间达到同步旋转的状态，而这本质上是发电机在相反的作用力下达到的一个平衡点。书中用一个例子来描述了这种稳定现象。假设多辆汽车在环形跑道上驾驶，两两之间互相用橡皮筋连接。这里的汽车类比电网中的发电机转子，橡皮筋类比电网中的输电线。当在某辆汽车上加上一个反作用力，那么前面的车会在橡皮筋的作用力下减速，后面的车则会加速，最后所有的车达到一个相对静止的状态，外部作用力的能量全部损耗在与地面的摩擦力当中。但是，如果橡皮筋承受不住汽车之间的拉力则有可能断裂，这时一部分车会相对另一部分车加速奔驰。 在电力系统中，当遭受扰动后一台同步发电机转子转矩上的变化包含了同步转矩变化（相当于汽车例子中的汽车之间的作用力，用于拉回同步）和抑制转矩变化（相当于汽车例子中地面的阻尼，阻尼用于抑制震荡），因此功角稳定问题的表现形式主要由这两种转矩决定。下面从功角问题中的小干扰稳定问题和暂态稳定问题来分别阐述。 （1）小干扰稳定问题小干扰问题，顾名思义，是电力系统在遭受小干扰下保持电网发电机同步的能力。如果发生小扰动后，发电机转子的转矩变化缺少同步转矩成分，那么失稳表现为发电机转子功角的稳步增加，一般是因为缺少励磁控制的作用；如果缺少抑制转矩成分，失稳表现为幅值在不断的震荡中增加的过程。下图（a）是发生小干扰后缺少同步转矩下稳定和失稳的表现；图（b）是发生小干扰后缺少抑制转矩下稳定和失稳的表现。 在现代电力系统中，小干扰稳定的转矩变化主要是缺少抑制转矩成分，因此一旦失稳就出现震荡行为，根据震荡行为的不同又可以分为几种模式：1）Local modes，发生在一台发电机或者电网一小部分区域发电机的震荡；2）Interarea modea，发生在两个区域之间的发电机的震荡摇摆，一般是通过不够坚强的联络线相连的互联系统容易造成这种情况；3）Control modes，一般由未能整定成合适参数的控制设备造成；4）Torsional modes，一般和涡轮机发电机旋转设备有关。 （2）暂态稳定问题暂态稳定是指在遭受大干扰后到达新的平衡点的能力。可以分为三种情况：稳定（case 1）、单摆失稳（case 2）、多摆失稳（case 3）。值得一提的是多摆失稳前期表现稳定，后期表现为interarea modes 震荡失稳。单摆失稳下，其时间尺度在3到5s左右；多摆失稳时间尺度则在10s左右。 电压稳定问题电压稳定定义为在电网任意一个节点注入无功时，该节点电压是增加的，否则为电压失稳。这类稳定问题主要和负荷有关，以一个简单电路来说明，如下图所示，可以看出，当恒定阻抗负荷$Z_{LD}$减小时，负荷有功不断增大，但是在$Z_{LD}&gt;Z_{LN}$时，负荷功率就不断下降了，而这个区域就是失稳区域，对应下面第三张图的虚线左半部分，此时无功越高，电压越低。 电压稳定稳定问题可以根据扰动大小来分类：1）大干扰电压稳定：在遭受大干扰后电压恢复到一定的电压水平。它由负荷特性以及保护控制特性有关，时间尺度在秒级到10分钟左右；2）小干扰电压稳定，在遭受小干扰，例如逐渐少量增加负荷时维持住电压水平的能力。它由在给定时间内的负荷特性以及连续、离散控制有关。 中长期电力系统稳定根据时间尺度也可以对电力系统稳定分类：短期稳定：0到10s；中期稳定：10s到若干分钟；长期稳定：若干分钟到几十分钟。但是其中的时间界限并不是绝对的，一般来说是根据设备响应的不充分性、保护与控制设备的协调性、有功无功备用的丰富性来决定的。短期稳定问题一般指的是暂态过程，例如单摆失稳。中期稳定侧重于同步发电机之间的功率震荡，包括暂态稳定中没有考虑到的慢过程影响因素、电压和频率的大幅跌落。长期稳定侧重于发生扰动后可能涉及到的连锁反应以及系统解列造成的各个孤岛继续能够保持稳定的能力，因此在这种情况下往往评估的是每个孤岛的平均频率，而不是评估每台发电机的相对功角。目前随着慢动态以及快动态仿真分析技术的成熟，中期稳定与长期稳定的界限并不是那么的重要了。 电力系统稳定最终分类下图是对稳定问题的总体分类。考虑到功角稳定、电压稳定和中长期稳定并不是具有很明显的分类界限，因此它们总是交织在一起。但是各类稳定问题的控制方式又有所区别，因此在控制的时候不能以牺牲一种稳定来满足另一种稳定。需要从各个稳定问题的角度来看待电力系统，所以发展针对不同稳定的分析工具以及识别各种稳定重叠程度的分析方法是很有必要的。","link":"/2020/03/19/Power%20System%20Stability%20and%20Control%20(Kundur)----%E7%AC%AC%E4%BA%8C%E7%AB%A0/"},{"title":"《Intelligent Time-Adaptive Transient Stability Assessment System》论文的复现及结论分析","text":"首页摘要： 在和导师讨论最近写完的论文《A Deep Imbalanced Learning Framework for Transient Stability Assessment of Power Systems》时提及选择电力系统暂态稳定非自适应评估模型和自适应评估模型的出发点的问题，因此再一次复现了IEEE on Power System 上的论文《Intelligent Time-Adaptive Transient Stability Assessment System》，将复现的结果和原论文进行对比，发现了一些不一样的结论，对目前正在写的应对电力系统暂态稳定评估数据缺失的问题有所启发，聊以记录。 以下为主要实现代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155# ----------------------------------------------------# Description: Class for DynamicLSTM Network# Created by: Bendong Tan# Created time: Friday, Jan 25, 2019# Last Modified: Monday, Jan 30, 2019# Wuhan University# ----------------------------------------------------import osos.environ['KERAS_BACKEND']='tensorflow'import timeimport numpy as npfrom keras.models import Sequentialfrom keras.layers import Dense,Masking,Flatten,Dropout,LSTMfrom keras.preprocessing.sequence import pad_sequencesfrom keras.utils import to_categoricalfrom keras.callbacks import ModelCheckpointfrom keras import backend as Kfrom keras import regularizersclass DynamicLSTM: ''' 初始化 ''' def __init__(self, X_train, y_train, X_test, y_test): n_trainsample, n_timesteps, n_features = np.shape(X_train) # 训练数据 self.X_train = X_train # 测试文件 self.X_test = X_test # 训练数据 self.y_train = y_train # 测试文件 self.y_test = y_test # 最后输出 self.n_outputs = 1 # 每个时刻的输入特征数量 self.n_features = n_features # 时序持续长度为 self.n_timesteps = n_timesteps # 层数 self.layer_num = 1 # 隐含层神经元数目 self.hidden_size=100 # 每代训练模型步数 self.batch_size=n_trainsample # 学习率 self.learningRate = 1e-3 # 训练代数 self.epochs=200 # 保存模型数据目录 self.storePath = None ''' 搭建LSTM网络 ''' def build(self): # 开始搭建浒关模型 model = Sequential() # 针对自适应评估模式设计补零操作以保持模型输入长度 model.add(Masking(mask_value=0, input_shape=(self.n_timesteps, self.n_features))) # LSTM层 model.add(LSTM(self.hidden_size,return_sequences=True)) # 设置dropout防止过拟合 model.add(Dropout(0.05)) model.add(LSTM(self.hidden_size, return_sequences=True)) model.add(Dropout(0.05)) model.add(LSTM(self.hidden_size)) # sigmoid层 model.add(Dense(self.n_outputs, activation='sigmoid')) # 编译模型 model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) return model ''' 训练模型 ''' def fit(self,model): # 记录最好模型 filepath = r&quot;.\\model\\model_best.h5&quot; checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max') callbacks_list = [checkpoint] # 训练模型 model.fit(self.X_train, self.y_train, epochs=self.epochs, batch_size=self.batch_size, validation_data=(self.X_test, self.y_test), callbacks=callbacks_list, verbose=1) return model ''' 标准评估模型 ''' def evaluation(self,model,X_test, y_test): _, accuracy = model.evaluate(X_test, y_test,batch_size=len(X_test), verbose=1) # 标准评估准确率 return accuracy ''' 自适应评估模型 ''' def Adaptive_TSA(self,model,X_test, y_test,delta): miss = 0 # 记录分类错误分数 right = np.zeros((len(y_test), 20)) # 记录每个样本在每个时刻的评估情况，做了评估记为1 y_pred = np.zeros((len(y_test), 1)) # 最终评估分类结果 # 自适应评估过程 for i in range(len(y_test)): for t in range(20): # 最大评估时刻数 # 如果在时间窗口内采取按照时刻逐步增加采样点的方式进行评估 if t&lt;self.n_timesteps: Input=pad_sequences(np.reshape(X_test[i,0:t+1,:], (-1,t+1,self.n_features)), maxlen=self.n_timesteps, padding='post') predictions = model.predict(Input) if predictions &gt;= delta and predictions &lt;= 1: right[i, 0:t + 1] = 1 y_pred[i] = 1 break if predictions &gt;=0 and predictions &lt; 1-delta: right[i, 0:t + 1] = 1 y_pred[i] = 0 break # 如果评估时刻超出时间窗口，则采取滑动时间窗口的方式评估 if t &gt;= self.n_timesteps: Input = np.reshape(X_test[i, t-self.n_timesteps+1:t + 1, :], (-1, self.n_timesteps, self.n_features)) predictions = model.predict(Input) if predictions &gt;= delta and predictions &lt;= 1: right[i, 0:t + 1] = 1 break if predictions &gt;= 0 and predictions &lt; 1 - delta: right[i, 0:t + 1] = 1 y_pred[i] = 0 break # 超出最大时刻的均视为失稳处理 if t + 1 == 20: if predictions&gt;=0.5: y_pred[i] = 1 if predictions&lt;0.5: y_pred[i] = 0 right[i, 0:t + 1] = np.ones((1, t+1)) break # 计算自适应评估准确率 for i in range(len(y_test)): if y_pred[i]!=y_test[i]: miss = miss + 1 # 记录平均评估时间 ART = sum(sum(right)) / len(y_test) # 记录自适应评估准确率 Accuracy=(len(y_test)-miss)/len(y_test)*100 return ART , Accuracy","link":"/2019/02/01/%E3%80%8AIntelligent%20Time-Adaptive%20Transient%20Stability%20Assessment%20System%E3%80%8B%E8%AE%BA%E6%96%87%E7%9A%84%E5%A4%8D%E7%8E%B0%E5%8F%8A%E7%BB%93%E8%AE%BA%E5%88%86%E6%9E%90/"},{"title":"《Spatial-temporal Adaptive Transient Stability Assessment for Power System under Missing Data》论文撰写过程总结","text":"首页摘要： 在《Spatial-temporal Adaptive Transient Stability Assessment for Power System under Missing Data》论文撰写过程中发现很多问题，趁着现在刚写完总结一下写这篇论文时编程遇到的问题以及相应的解决方法。 1.如何解决python数据读取时间过长的问题利用数据挖掘来做相关研究往往伴随着大数据，在此以基于机器学习的暂态稳定评估为例。在撰写这篇论文的过程中，在新英格兰10机39节点上生成的暂态故障数据集是5775个具有228个特征、时间长度为20的高维多变量时间序列。如果以CSV格式存储，那么将占据大约1GB的存储空间，利用python中的pandas库读写一次需要60-80s左右，对于需要多次调节超参数的机器学习模型来说浪费时间甚巨。 但是我发现python的科学计算库scipy可以读写mat文件，而且前述数据以mat格式保存只需要0.5GB左右的空间。利用这种读写方式只需要1s左右。因此对于需要大量数据交互的python运行过程中，scipy库在压缩数据、读写时间上都有巨大的优势。值得一提的是，mat文件可以利用matlab矩阵操作的优点进行构造。 总而言之，将数据保存成mat格式，最后利用scipy进行读写。 2.如何解决多次载入深度学习模型时间过长的问题在时间自适应的暂态稳定稳定评估中，由于最大时间窗口长达20，那么有可能需要在特定的参数下评估20次，而深度学习模型为训练过程中保存下来的最好模型，也就需要载入20次。而载入一次约30s，特别是要寻找合适的稳定阈值以及时间窗口长度大概需要10 50 30=15000s=40h=2days。为了避免每一次寻找最优参数时都载入深度学习模型，可以先将所有样本预测值输出并保存，基于这些输出来寻找最优稳定阈值以及时间窗口长度，最后仿真发现这样做时间不超过5min。同样地，在该论文中还需要自适应集成模型，也不需要每次载入模型，采取同样的手段可以节约大量时间。 3.如何解决python和matlab的交互问题在做仿真的时候发现，有的算法在python中已经实现好了，而有些算法只有matlab相关实现，如果重新在其中一个变成语言中变成将费时费力。为了解决这个问题，可以采用文本交互的方式解决，因为matlab和python都可以相互调用函数且都能读取mat文件，如果把函数输入输出参数都通过mat文件进行传递，可以解决数据类型不一致的问题，python和matlab交互的问题迎刃而解。","link":"/2019/03/10/%E3%80%8ASpatial-temporal%20Adaptive%20Transient%20Stability%20Assessment%20for%20Power%20System%20under%20Missing%20Data%E3%80%8B%E8%AE%BA%E6%96%87%E6%92%B0%E5%86%99%E8%BF%87%E7%A8%8B%E6%80%BB%E7%BB%93/"},{"title":"信息熵的理解","text":"首页摘要： 记录对信息熵的理解 第一，假设存在一个随机变量，可以问一下自己当我们观测到该随机变量的一个样本时，我们可以接受到多少信息量呢？毫无疑问，当我们被告知一个极不可能发生的事情发生了，那我们就接收到了更多的信息；而当我们观测到一个非常常见的事情发生了，那么我们就接收到了相对较少的信息量。因此信息的量度应该依赖于概率分布p(x)，所以说熵h(x)的定义应该是概率的单调函数。 第二，假设两个随机变量和是相互独立的，那么分别观测两个变量得到的信息量应该和同时观测两个变量的信息量是相同的，即：h(x+y)=h(x)+h(y)。而从概率上来讲，两个独立随机变量就意味着p(x,y)=p(x)*p(y)，所以此处可以得出结论熵的定义应该是概率的函数。因此一个随机变量的熵可以使用如下定义： ​ h(x)=-log2(p(x)) 此处的负号仅仅是用来保证熵（即信息量）是正数或者为零。而函数基的选择是任意的（信息论中基常常选择为2，因此信息的单位为比特bits；而机器学习中基常常选择为自然常数，因此单位常常被称为nats）。最后，我们用熵来评价整个随机变量平均的信息量，而平均最好的量度就是随机变量的期望，即熵的定义如下： ​ h(x)=-sum(p(x)*log2(p(x))) 再说一个对信息熵的理解。信息熵还可以作为一个系统复杂程度的度量，如果系统越复杂，出现不同情况的种类越多，那么他的信息熵是比较大的。如果一个系统越简单，出现情况种类很少（极端情况为1种情况，那么对应概率为1，那么对应的信息熵为0），此时的信息熵较小。","link":"/2018/06/13/%E4%BF%A1%E6%81%AF%E7%86%B5%E7%9A%84%E7%90%86%E8%A7%A3/"},{"title":"凸优化函数的定义、凸优化问题的概念及分类","text":"首页摘要： 凸优化系列文章旨在对记录自己这方面的学习心得，本篇文章主要介绍凸优化函数的定义、凸优化问题的概念及分类。 凸优化函数的定义从凸函数的名字也可以看出来，函数表示的区域形状是凸出来的，再具体点就是函数表示的区域任意两点连成的直线上的任意一点都落在该函数表示的区域内部，图中（A）曲线就是一个典型的凸函数，而（B）曲线由于有一部分凹进去而不满足定义。 现在开始用数理化定义凸函数。设函数$f: R_{n} \\rightarrow R $ 是凸的，如果 $f$ 的定义域是凸集（即定义域的形状是凸出来的），且对于$\\theta \\in [0,1] $ ，$f$ 上任意两点$ x$ 、$y$ 均满足： f(y)\\geq \\theta f(x)+(1-\\theta)f(y)那么我们称函数$f$ 是凸的，其充要条件是：$f(y) \\geq f(x)+\\nabla f(x)(x-y)$ ，这个条件很好理解，这里的微分项表示斜率，这个公式说明的就是函数两点之间任意一点大于两点连成直线上任意一点。 凸优化问题凸优化问题指的是在定义域内具有全局最优解的问题，其数理化定义为： \\begin{matrix} minimize & f(x) \\hfill \\\\ subject to & h_{i}(x)=0,i=1,2,...m\\\\ & g_{j}(x)\\leq 0,j=1,2,...p\\\\ \\end{matrix}如果目标函数$f(x)$、不等式约束$g_{j}(x)&lt;=0$全为凸函数以及等式约束$h_{i}(x)$是仿射的（即为线性函数），那么这个优化模型就是凸的。其最优解是$x$ 的充要条件是满足：$\\nabla f(x)(x-y)\\geq 0 ,\\forall y \\in X$ ，其中$X$ 是所有可行解。从$f$ 是凸函数的充要条件$f(y) \\geq f(x)+\\nabla f(x)(x-y)\\geq 0$ 可以看出，只要满足$\\nabla f(x)(x-y)\\geq 0 ,\\forall y \\in X$ ，$f(x)$ 在定义域内就是最小的。 凸优化模型的主要分类在处理优化问题时，我们总是尝试将面对的问题模型转化或者松弛成凸优化模型，常见的凸优化模型如下（但不限于）： 线性规划问题 线性规划问题的数理化定义为： \\begin{matrix} minimize & c^{T}x+d \\hfill\\\\ subject to & Gx\\leq e \\\\ & Ax=b\\\\ \\end{matrix} 二次优化问题 二次优化问题的数理化定义为： \\begin{matrix} minimize & \\frac{1}{2}x^{T}Px+q^{T}x+r \\hfill\\\\ subject to & Gx\\leq e \\\\ & Ax=b\\\\ \\end{matrix}其中，$P$ 为正定阵。 二阶锥模型 二阶锥问题的数理化定义为： \\begin{matrix} minimize & q^{T}x \\hfill\\\\ subject to & \\begin{Vmatrix} A_{i}x+b_{i} \\end{Vmatrix}\\leq c^{T}x+d,i=1,2,...,m \\\\ & Bx=l\\hfill\\\\ \\end{matrix}结语至此，凸优化问题的基本概念已经介绍完了，虽然看起来内容不多，在Boyd的凸优化书中却花了100多页来介绍，这篇文章提取其中的精华并省却了大量证明过程，这将为之后的介绍打下坚实的基础。","link":"/2020/02/04/%E5%87%B8%E4%BC%98%E5%8C%96%E5%87%BD%E6%95%B0%E7%9A%84%E5%AE%9A%E4%B9%89%E3%80%81%E5%87%B8%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%E7%9A%84%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%88%86%E7%B1%BB/"},{"title":"风中的纸屑","text":"首页摘要： 我天性不宜交际。在多数场合，我不是觉得对方乏味，就是害怕对方觉得我乏味。可是我既不愿忍受对方的乏味，也不愿费劲使自己显得有趣，那都太累了。我独处时最轻松，因为我不觉得自己乏味，即使乏味，也自己承受，不累及他人，无需感到不安。 对于这段话，我认为不善于交际的人并无任何地方比善于交际的人差，正是多元的性格造就了这个丰富的世界。其实人与人之间的交往无非尊重与理解，每个人都有自己的生活方式，不存在孰优孰劣。不赞同的生活方式多一些包容与理解，现在我总觉得言多必失，何不多一些与自己的对话，经常反思自己的行为。遇到理解自己的人则可以多交流，所谓求同存异不外如是。","link":"/2018/07/05/%E5%91%A8%E5%9B%BD%E5%B9%B3%E7%BB%8F%E5%85%B8%E8%AF%AD%E5%BD%95/"},{"title":"凸优化求解方法","text":"首页摘要： 在推导出KKT条件后，如何利用它对不同的凸优化模型求解是本篇文章的主要介绍内容，本文从无约束优化、等式约束优化、不等式约束优化三个凸优化模型来进行介绍。 无约束优化问题无约束优化问题求解思路非常简单，一般是对目标函数进行梯度计算的方法进行寻优，各类寻优的方法不同之处在于确定梯度方向和大小。 现在考虑无约束优化问题： minimize\\ \\ f(x)其最优解$x^{\\star}$一定满足： \\nabla f(x^{\\star})=0也就是说，只要求解这个具有$n$个变量$x=\\{x_{1},x_{2},…,x_{n}\\}$的等式方程组就可以得到最优解，然而，这个方程组一般没有解析解，需要进行数值迭代寻优求解，不论何种寻优方法，其最后迭代（第$k$次迭代）均满足： |f(x^{k})-f(x^{\\star})|","link":"/2020/02/06/%E5%87%B8%E4%BC%98%E5%8C%96%E6%B1%82%E8%A7%A3%E6%96%B9%E6%B3%95/"},{"title":"基于AI技术的大电网安全稳定分析","text":"首页摘要： 现在是2018年7月6日凌晨1:09，昨天晚上喝了一杯咖啡，果然失眠了，想想还是下床写一下博客吧！前几天总结了一下利用广域测量系统进行稳定评估现状的PPT，基于人工智能技术目前需要攻克的问题都总结在这份PPT中了，还有更加深刻的问题自感无法解决就没有贴出来。希望在接下来的一年中可以找到解决的办法！","link":"/2018/07/06/%E5%9F%BA%E4%BA%8EAI%E6%8A%80%E6%9C%AF%E7%9A%84%E5%A4%A7%E7%94%B5%E7%BD%91%E5%AE%89%E5%85%A8%E7%A8%B3%E5%AE%9A%E5%88%86%E6%9E%90/"},{"title":"强化学习之动态规划","text":"首页摘要： 动态规划算法主要包括策略评估、策略改进，其中策略评估是为了确定某个策略下对应的各个状态值函数或者是状态动作值函数，而策略改进则是根据确定的状态值函数或者状态动作函数找到最优策略。 最优值函数要解决强化学习问题就意味着智能体在与环境交互的过程中找到一个能够获得最大回报的策略，假设这个最优策略是 $ \\pi^{\\star} $，但是实际上是很难找到最优的策略的。一般而言，我们可以在多个策略中选择最好的那个策略，这个策略被当成最优策略，也就是说我们找到的是局部最优解。此时对应的状态价值函数也是最大的，即： v_{\\star}(s)=\\underset{\\pi}{max}\\, v(s)同样地，状态动作价值函数也可以被推出： q_{\\star}(s,a)=\\underset{\\pi}{max}\\, q(s,a)那么这个最优策略可以定义成： \\pi^{\\star}(a|s) =\\begin{cases} 1 & a= \\underset{a\\in A}{argmax}\\, q(s,a)\\\\ 0 & others \\end{cases}这句话的意思是只有在最大状态动作价值函数的时候对应的动作概率为1，其他动作概率为0，这是一种贪婪策略。也就是说状态价值函数在最优的贪婪策略下可以改写成： \\begin{equation} \\begin{split} v_{\\star}(s)&=\\sum_{a\\in A}\\pi ^{\\star}(a|s)q_{\\star}(s,a)\\\\ &=\\underset{a}{max}\\, q_{\\star}(s,a)\\\\ \\end{split} \\end{equation}进一步，状态动作价值函数的关系式也可以被推出： q_{\\star}(s,a)=r_{t+1}+\\gamma \\sum_{s'\\in S}P_{ss'}^{a}v_{\\star}(s')综上所述，最优状态价值函数和状态动作价值函数可以被总结成： v_{\\star}(s)=\\underset{a}{max}\\,（r_{t+1}+\\gamma \\sum_{s'\\in S}P_{ss'}^{a}v_{\\star}(s')）\\\\ q_{\\star}(s,a)=r_{t+1}+\\gamma \\sum_{s'\\in S}P_{ss'}^{a}\\underset{a}{max}\\, q_{\\star}(s',a)动态规划基本流程由于动态规划的模型是已知的，也就是说 $P_{ss’}^{a}$ 是已知的，因此可以直接采用贪婪寻优策略的方法来求解，这一点要和后面的蒙特卡洛模拟采取的 $\\epsilon -greedy$ 策略加以区别。因为markdown里面好像不支持latex的算法描述流程，直接用书中的图来介绍吧。最麻烦也是最先出现的就是策略迭代法，图片中公式略有区别，但是意思是一样的，其中 $p(s’,r|s,\\pi (s))$ 是 $\\pi (s)$ 执行不同的动作 $a$ 转到状态 $s’$ 具有不同的回报 $r$ 的概率，因此可以累积求和，如下所示： 大致过程是： （1）随机初始化策略； （2）估计在该策略下评估每个状态价值及状态动作价值； （3）估计完价值后，针对每个状态更新策略。 循环（2）-（3），直到策略稳定收敛。 但是值得注意的是，策略评估和策略改进解耦了，也就是所谓的离线策略( $offline-policy$ )这样做会导致计算量非常大，因此有人提出了改进算法，把这两部融合起来了，这就是值迭代过程，称之为在线策略( $online-policy$ )，具体流程如下： 虽然起初通过 $max$ 更新的最优策略下的估值是基于不完整的状态信息的，但每个状态总是有一个最优操作的。那么通过不断地迭代更新，总是有机会能先找到某个状态下的最优操作，保证其足够平稳（即该状态下的操作不会随着迭代经常变）。然后就能以点破面，找到更多周边的平稳的最优估值。久而久之，平稳的状态会越来越多，最后也就能找到最优策略了。","link":"/2019/03/28/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"title":"基于改进CGAN的电力系统暂态稳定样本增强方法","text":"首页摘要： 第一篇发表在期刊上的论文录用了，聊以纪念（虽然晚了两个月，太懒了），这篇论文针对的是电力系统中失稳数据极少的样本不平衡问题，通过条件生成对抗神经网络合成大量的失稳数据来提高对失稳样本的识别率。可视化效果不错，评估性能上表现也较为优异。论文具体内容见图片。","link":"/2018/12/18/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BCGAN%E7%9A%84%E7%94%B5%E5%8A%9B%E7%B3%BB%E7%BB%9F%E6%9A%82%E6%80%81%E7%A8%B3%E5%AE%9A%E6%A0%B7%E6%9C%AC%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95/"},{"title":"强化学习之基本概念","text":"首页摘要： 目前开始学习强化学习方面的内容，整体学习大纲为：基本概念、动态规划(基于模型的方法)、蒙特卡洛方法(不基于模型)、时间差分法(结合动态规划以及蒙特卡洛模拟的优点)。特别推荐的是一个博客，写得非常通俗易懂，mark一下：https://www.cnblogs.com/pinard/，本篇文章介绍强化学习的基本概念及基础方程。 强化学习是什么机器学习可以大致分为有监督学习、无监督学习以及强化学习，有监督学习经常用语分类及预测任务，无监督学习则适用于特征降维或者聚类任务，而强化学习擅长决策任务。严格来说它们之间的分类并不明显，是一种互相依存的关系。 用下围棋的例子来引出强化学习吧。当前时刻 $t$ 棋盘($environment$) 棋子的分布为状态 $S_{t}$ ，假设以持白子的棋手是主角，那么其下子的位置则是一个动作($action$) $A_{t}$，完成这个动作会有一个回报($reward$) $r_{t+1}$，这个过程称之为一个策略( $policy$ ) $\\pi(A_{t}|S_{t})$ 。在执行完策略之后，棋盘上的棋子分布发生了改变，这个时候状态为$S_{t+1}=s’$ ，这个过程一直持续到这局对弈结束，一局称之为一个 $episode$ 。 总结起来强化学习就是一个智能体和环境不断交互，针对当前环境的状态按照一定的策略来执行特定的动作，来获得尽可能大的回报的过程，而在这个交互过程中，这个智能体又不断学习进化，所采取的动作越来越合理。 强化学习基本概念其实在上一节的介绍中，对很多概念进行了简化，为了推出完整的强化学习数学模型，需要对上述概念进行补充，下面用四个步骤来推导强化学习的基本方程，这些方程是整个强化学习算法的基石。 策略 $\\pi(a|s)$ 是一个状态 $S_{t}=s$ 时执行动作 $A_{t}=a$ 的概率分布，可以理解成是一个具有 $softmax$ 层多输出的神经网络，每个动作的概率之和为1。具体而言： \\pi(a|s)=p(A_{t}=a|S_{t}=s) 当智能体在状态 $S_{t}=s$ 时执行策略 $\\pi(a|s)$ 时，需要先进行评估此策略价值，评估可以用状态价值函数$v_{\\pi}(s)$ 来l定量表示，这个价值函数一般是一个期望函数。此外，为了让智能体具有长远的目光，往往会考虑到未来可能的回报，但是又不能让未来的回报过于影响当前的决策，因此需要对未来的回报打个折扣。因此状态价值函数 $v_{\\pi}(s)$ 可以写成： \\begin{equation} \\begin{split} v_{\\pi}(s)&=E_{\\pi}(r_{t+1}+\\gamma r_{t+2}+ \\gamma^{2}r_{t+3}+...+\\gamma^{T-1}r_{t+T}|S_{t}=s )\\\\ &=E_{\\pi}(r_{t+1}+\\gamma v(S_{t+1}=s')|S_{t}=s )\\\\ \\end{split} \\end{equation}其中 $\\gamma$ 为回报衰减因子，执行策略 $\\pi(a|s)$ 也可评估其期望的回报，定义为动作价值函数 $q(s|a)$ : \\begin{equation} \\begin{split} q_{\\pi}(s,a)&= E_{\\pi}(r_{t+1}+\\gamma r_{t+2}+ \\gamma^{2}r_{t+3}+...+\\gamma^{T-1}r_{t+T}|S_{t}=s,A_{t}=a )\\\\ &=E_{\\pi}(r_{t+1}+\\gamma q_{\\pi}(S_{t+1}=s',A_{t+1}=a')|S_{t}=s ,A_{t}=a)\\\\ \\end{split} \\end{equation} 为了定义环境的概率转化模型，在状态 $s$ 下执行动作 $a$ 转到状态 $s’$ 的概率为 $P_{ss’}^{a}​$ ，那么状态价值函数的期望可以进一步显式表示为： \\begin{equation} \\begin{split} v_{\\pi}(s)&=\\sum_{a \\in A}\\pi(a|s)(r_{t+1}+\\gamma \\sum_{s'\\in S}P_{ss'}^{a}v_{\\pi}(s'))\\\\ & =\\sum_{a \\in A}\\pi(a|s)q_{\\pi}(s,a)\\\\ \\end{split} \\end{equation}动作价值函数也可从上式推出： \\begin{equation} \\begin{split} q_{\\pi}(s,a)&=r_{t+1}+\\gamma \\sum_{s'\\in S}P_{ss'}^{a}v_{\\pi}(s')\\\\ & =r_{t+1}+\\gamma \\sum_{s'\\in S}P_{ss'}^{a}(\\sum_{a' \\in A}\\pi(a'|s')q_{\\pi}(s',a'))\\\\ \\end{split} \\end{equation} 综上所述，状态价值函数 $v_{\\pi}(s)$ 和动作价值函数 $q_{\\pi}(s,a)$ 在策略 $\\pi$ 下的表达式可以写成： v_{\\pi}(s)=\\sum_{a \\in A}\\pi(a|s)(r_{t+1}+\\gamma \\sum_{s\\in S}P_{ss'}^{a}v_{\\pi}(s'))\\\\ q_{\\pi}(s,a)=r_{t+1}+\\gamma \\sum_{s\\in S}P_{ss'}^{a}(\\sum_{a' \\in A}\\pi(a'|s')q_{\\pi}(s',a')) 强化学习求解基本思路最后两个公式也被称之为贝尔曼方程，可见其表达式存在递归的形式(同一状态存在若干时刻)，直观上来讲非常符合动态规划的思路，这也是求解这两个公式最先出现的方法，并基于此产生了大量的衍生算法。因此下一篇文章我将重点介绍动态规划求解强化学习贝尔曼方程的方法。","link":"/2019/03/27/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"},{"title":"君主论","text":"首页摘要： 《君主论》一书的读后感。虽然这本书阐述的是君主治国平天下的方法论，但在世故之人的眼里可以是一本厚黑学，对我而言，它让我初识社会的复杂。 正文《君主论》这本书的目标读者其实是君主一类的掌权者，告诉他们要怎么征服别的国家、怎么稳定自己的国家，但它却阴差阳错地被人们用成了厚黑学。原因在于这本书假设人性本恶，在君主看来，如何不带感情、不择手段地去利用好各类工具人（贵族、人民、敌人、盟友等等）才是巩固自己地位的好办法。而这里面着重指出的是，一要有自己信得过的武装（和教员的枪杆子里出政权异曲同工），二要取得人民的支持（虽然只有几个字，但是对于君主而言却是非常难的一件事，因为涉及到对人民心理和物质上各方面的拉拢），在这两个基础上如何去平衡各方势力就是君主需要进一步发挥的地方了。后世很多人把这里面提到的各种策略用到自己身边的朋友，例如如何当一个成功的领导、如何让下属支持自己。 不过一个人当真用这种方式来对待身边的人，那也太累了，不但要想办法去别人身上获得好处，还要防止别人伤害自己。特别是这本书默认可以不择手段，一旦完全遵守这个思路，我想，真心想学习这本书套路的人下场不会特别好，即便成功了，也会觉得愧疚。知世故而不世故，这是我在这本书上能够坚定的信念，万幸到目前为止，我所遇之人都是善良的，有什么理由黑化呢？ 下面是读这本书看到的一些自觉经典的句子： （1） 统治者建立新的秩序而没有自己的武装作为后盾就不免于毁灭，军队和法律是立国的两大支柱 个人解读：枪杆子里出政权，教员很早就告诉我们了。军队是威慑和消灭敌人最直接有效的手段，而法律则可以约束人民什么能做、什么不能做。这样统治者便能更加顺利地开展经济建设、思想建设。而这些又能反过来支撑军队和法律的发展，具体而言，军队有更多的钱购买先进的武器、思想建设可以让他们更加忠心，人民因为有钱而减少违法活动、思想的提高也能减少作恶的行为。 （2） 对人们应当加以爱抚，要不然就应当把他们消灭掉；因为人们受到了轻微的侵害，能够进行报复，但是对于重大的损害，他们就无能为力进行报复了。所以，我们对一个人加以侵害，应当是我们无须害怕他们会报复的一种侵害。 个人解读：这句话可能比较腹黑。比如，对待一个人，即便这个人是老实人、比较隐忍、或是显得懦弱怕事，也不应该对其有任何主观上冒犯的行为，因为你永远不知道他是不是心里在想着怎么对付你，这个时候连嘲讽都不应该施予对方。如果选择得罪他，那么只能选择实施使得他对自己永远没有威胁能力的打击。所以在确认对方没有敌意的时候，最好的做法莫过于不要树敌。 （3） 然而一个明智的人总是应该追踪伟大人物所走过的道路的，并且效法那些已经成为最卓越的人们。这样一来，即使自己的能力达不到他们那样强，但是至少带有几分气派 个人解读：这个告诫我们不要重复造轮子，站在巨人的肩膀上会省去很多不必要的弯路，但是自己探索和思考的过程必不可少。从另一个角度来说，这也告诉我们要多读书，我们身边也许没法遇到可以参照的对象来学习，但是前人写的书就是经验的总结，书读多了，可以在一定程度上帮助我们增加经验，但是唯有实践出真知。 （4） 因为这些机会使得这些人走了运，同时由于他们具有卓越的能力，使他们能够洞察这种机会，从而利用这些机会给他们的祖国增光并为国造福 个人解读：核心是“越努力越幸运”。我们现在的努力也许短期没有明显的效果，但是在不经意的某一天，它会在不起眼的时间点给你带来惊喜，当然，前提是要有方法地努力，否则惊喜没你想象中的大。写这句话的时候，我觉得这是一碗浓浓的鸡汤，不过还好不毒。 （5） 因此，一个英明的君主应该考虑一个办法，使他的市民在无论哪一个时期对于国家和他个人都有需求，他们就会永远对他效忠了 个人解读：又是腹黑语录。如果是一个领导（虽然我没当过领导，这里权当沙盘模拟），要让属下为自己认真做事，要么给钱，要么给权，实在没办法就用威慑，核心在于对自己有所求，联想到现在的很多博士生导师，细思极恐。最终极的应该是以德服人，因为这本书的出发点就是人性本恶，用德行要感化这样的人，一旦无法逐利甚至有所损失，这类人会毫不迟疑地背叛，即便德行丰满如周总理，也不是所有人都对其爱戴，这样看来我想我这辈子是做不到以德服人了。 （6） 因为一个人如果在一切事情上都想发誓以善良自持，那么，他厕身于许多不善良的人当中定会遭到毁灭 个人解读：不违背善良之道是最后的底线，但并不意味着要任人宰割。换句话说，善良应当是施予善良的人而非恶人。在保护好自己的前提下，视不同的情况，去采取或者不采取一些不好的手段。古代的包拯、海瑞，官方认证是刚正不阿，实际上却非如此（至少不是墨守成规）。要想在恶人之中存活，必须采用恶人的手段去达到善良之目的。总结一下，在周星驰的九品芝麻官中有这么一句经典的话：要比贪官更狡猾，而对待身边善良的人，请不要吝惜自己的真心。 （7） 人们是那样的单纯，并且那样地受着当前地需要支配，因此进行欺骗的人总可以找到某些上当受骗的人们 个人解读：和（5）要表达的意思类似。","link":"/2020/08/22/%E5%90%9B%E4%B8%BB%E8%AE%BA/"},{"title":"家庭、私有制和国家的起源","text":"首页摘要： 在疫情的侵蚀下，人性的真善美与丑恶暴露得一览无余。很多正在发生的事情往往并不是那么简单，例如韩国邪教的“哈利路亚”、川普的各种政策、甚至于前不久发生的英国脱欧。隐隐觉得这些复杂的关系是以利为核心，但是它们的来源与发展却不明了。从理工科的角度来说，要想理解一个对象，首先要对相关的数学理论有所了解。而国与国之间的关系，则首先需要知道国家是怎么构成的，恩格斯的《家庭、私有制和国家的起源》不说能够绝对准确描述其中的利害关系，但也是了解国家这个对象的一个角度。 前言写这本书的初衷是恩格斯为了完成马克思的遗作——用唯物主义历史观来阐述史学家摩尔根的研究成果，主线是历史是如何发展的、导致历史发生变化的标志性生产力与社会制度变革。 根据唯物主义历史观，历史中的决定性因素，归根结蒂是直接生活的生产和再生产。生产可以理解成为了满足生存需要而制造产品的过程，再生产是保持生产规模或者扩大生产规模的行为（例如一个工厂赚的钱除去成本后刚好满足消费则只能保持生产规模，后者则是还有多余的钱扩大生产规模）。生产的过程中涉及到人，因此需要考虑到生产关系（社会制度，它主要规定人的行为），即生产资料的分配，也被称之为交换。这本书主要侧重点就是在描述社会制度的变化，其余内容都是社会制度的变化下的具体体现。 社会制度主要受到两个因素的制约：劳动的发展阶段（生产力）和家庭发展阶段。当生产力较低时，社会的财富不多，社会制度就主要受到血族关系的制约（氏族），当生产力提高时，例如在当今社会，生产资料的极大丰富容易造成私有制、交换和雇佣关系的出现，这时以血族关系为基础的社会制度慢慢和这些变化起了冲突。那么以地区团体（例如省市的划分）为基层单位的国家代替了以血族关系为基础的社会，主要为私有制等新生事物服务，那么久出现了阶级矛盾（剥削阶级和被剥削阶级），而这个特点一直持续到现在。 一言蔽之，经济基础决定上层建筑，人类社会的变迁很大程度上取决于生产力上的进步，私以为从这个角度去看，很多现象都或多或少可以得到解释。 人类社会各个时代的特点在这本书中，人类社会大致分为三个阶段：蒙昧时代、野蛮时代、文明时代，它直接体现了生产力的进步，也就是说它从本质上决定了人类社会制度的发展，为后续家庭、私有制和国家的形成提供生产力上面的例证。 蒙昧时代：以获得现成天然产物为主的时代，人工产品是获得天然产物的辅助工具，例如，这个时期开始制造弓箭来捕获猎物。这个时代的显著特征是母系氏族的形成，以具有血缘关系的家庭的形式聚居。这种方式和我们中国农村中常见的宗族类似，很多事情都由宗族统一处理，只不过现代的宗族更偏向父权主导。 野蛮时代：开始出现人类活动来增加天然产物的获得，例如畜牧、耕种的出现。由于各种天然产物的增加，开始出现私有制，可以想象到，消耗不完的产物可能集中到一些人的手中作为私有财产，而持有这批产物的人相应的就有了话语权。另一方面，由于男性在劳动体力上的优势，能够生产出更多的产品。因此母权开始衰落，开始走进父权时代。从此女性开始走上争取男女平等的道路，而这个目标依然没有完全实现。 文明时代：学会对天然产物加工的时期，例如榨油和酿酒。这个时代首先出现了奴隶社会，继之而来的是封建社会和现代社会。而这些都是以国家的形式存在，它的显著标志是出现了不从事劳动生产而只从事产品交换的一类人——商人，而这类人借助这个手段迅速集中大量财产，造成了阶级对立的出现（无产阶级、资产阶级），人类自此处心积虑解决阶级矛盾来维护稳定，而解决的手段则是借助国家这个工具来平衡双方的矛盾，实质上有时候容易成为资产阶级剥削无产阶级的的工具。 家庭是如何形成的家庭实质上是指具有血缘关系的人的集合，家庭的外在表现是伴随着婚姻形式发展的，婚姻形式变化的内在驱动力又是生产力的变化。在这个过程中，婚姻形式包含三种：群婚制、对偶制和专偶制，而这些分别对应人类的三个发展阶段：群婚制对应蒙昧时代、对偶婚制与野蛮时代相对应、以卖淫和通奸为补充的专偶制对应着文明时代。当然在野蛮时代到文明时代的过渡期还存在多妻制。下面分别介绍这三种婚姻形式： 群婚制：群婚制是指男女之间没有固定的性伴侣（同时有多个丈夫和多个妻子），“见一个爱一个”描述的就是这种婚姻形式，本质上和卖淫无异，但是仍然限制兄弟姐妹之间的通婚。这种制度的后果造成了儿女只知其母，不知其父。为了避免兄弟姐妹之间的通婚，开始有了血缘关系亲疏的区分，这时候就会形成以母亲为核心的氏族，即母系制社会。在这个社会中，母亲的兄弟姐妹和母亲的子女都属于一个氏族，这个母亲一旦去世，其遗产也只能由其兄弟姐妹和子女继承。而这些子女的父亲则属于另一个氏族，一旦去世，其子女并不能继承其遗产，而是留在这个父亲的氏族内。很明显，一旦男性的劳动优势压过母系制度，这种遗产继承制度必然要发生改变。 对偶制：在群婚制下，具有血缘关系的人越来越多，很自然地，社会会逐渐出现禁止具有血缘关系的人结婚，甚至影响到远姻关系，毕竟近亲结婚出现怪胎的概率很大，这很符合优胜劣汰的社会规律。这个现象的出现意味着人们结婚的可选对象越来越少，氏族组成的公社为了稳定人民，就会规定一个人在一段时间内只能有一个结婚对象，但是那时候仍然处于共产制（生产力不发达，获得食物均分，意味着每个人的话语权没有显著差别），所以夫妻两人都有离婚的权利。值得一提的是，由于在群婚时代，共夫使得女性感觉备受屈辱（毕竟男性在一定时期性欲更强，总有女性不存在交配欲望的时候），为了摆脱这种屈辱，女性不得不以委身于男性为代价来获得只同一个男性结婚的权利，这意味着女性婚内通奸从那时候开始成为一种违反社会规定的事情，严守贞操成了女性的枷锁。然而，男性不存在这种屈辱，他们反倒希望妻子越多越好，因此，多妻制在那时是合理的，虽然由于生产力的限制而养不起那么多妻子，限制了多妻制的大规模发生。另一方面，存在对偶制的野蛮时代开始出现畜牧、耕种，生产资料开始丰富起来，这时候家庭开始出现一定的私有。由于在那个时代，一个家庭内（这时候的家庭很接近我们现在的家了）的父亲因为体力的优势而存在获得食物及其对应劳动工具的责任，那么父亲就拥有劳动工具的所有权；母亲则是操持家务而拥有家庭工具的所有权。一旦离婚，父亲会带走劳动工具，母亲带走家庭用具。这就意味着，一旦有了新的劳动工具，父亲所拥有的财产将显著超过母亲，也就是父亲的家庭地位开始超过母亲，这时候就出现财产继承的问题，父亲自然希望他的子女获得他的财产，这个和母系制社会是矛盾的，母权制社会因此坍塌。恩格斯把这一变化称之为“乃是女性的具有世界历史意义的失败”。 专偶制：在财产出现贫富之分的时候，男性为了保证财产继承的对象是自己的亲生子女，从而诞生了具有牢固婚姻关系的专偶制，这种婚姻关系不能由双方任意解除，但是因为财产上的区别，一般潜规则是丈夫可以解除婚姻关系并赶走他的妻子，而妻子则必须保持贞操和忠诚。这种不公平婚姻制度本质上是由财富决定的，因此在结婚的时候，为了增加财富，人们既不愿意迎娶财富更少的家庭的女儿，又无法攀上财富更多的家庭的女儿，就只有和财富相当的家庭结下姻亲，从而维持或者增加自己的财产，这也是我们现在常说的“门当户对”。正是因为这种限制，使得爱情这种东西越来越难得，人们第一考虑永远是利益。反倒是无产阶级没有财富的羁绊，更容易获得不考虑利益的爱情。恩格斯说，当实现社会主义的时候，财富的差别不再明显，人们结婚的第一考虑将是情投意合。所以女性要获得在婚姻中的平等地位，第一步就是要有自己的事业，缩小和男性的财富差距。 综上所述，随着社会生产力的进步，至今为止，财富差距整体上都是在拉大的，造成婚姻制度的不合理。要破除这种不合理性，目前的手段恐怕只有不断努力获得财富以换取婚姻上的平等。所以说，即使在现代社会，女性地位仍然没有达到和男性同一水平线上。虽然社会上存在各种女性的傲娇行为，但这是少数现象，如果没有硬实力以支撑，恐怕将为此付出代价，大部分人还是不得不屈从于现有的婚姻不平等性。 私有制是如何形成的在野蛮时代低级阶段，氏族达到了全盛时期。这时候的财产是氏族的公社共同所有，只是因为性别的不同而造成了分工，即男性负责获取食物，女性负责操持家务，这种生活方式最接近共产主义。但是随着驯养牲畜、耕种以及冶炼技术的进步，人们开始出现农业、畜牧业的分工——第一次社会大分工，人们的劳动力已经可以生产出盈余于满足生活需求的产品了。由于男性主要负责耕种以及畜牧，理所当然地，多出的产品分配给生产它的男性，久而久之，就出现了生活资料相比其他人更丰富的情况，女性则因为不参与生活资料的生产造成话语权的逐渐丧失，母权制社会因此坍塌。而富裕的男性所在家庭则逐渐成长为对抗氏族的势力，以避免自己的财产被均分。当然由于生产分工的出现，交换产品的行为开始萌芽。 接着，人们开始掌握炼铁技术，他们从此拥有了更为强大的开垦工具。这也意味着各类生产方式的进步，“织布业、金属加工业及其他一切彼此日益分离的手工业，显示出生产的多样化和生产技术的日益改进；农业除了提供谷物、豆科植物和水果之外，也提供植物油和葡萄酒”，如此丰富的活动不可能一个人完成，于是手工业和农业开始分离——第二次社会大分工。而分工进一步的明确，意味着人们有了交换产品的需求，随之而来的就是贸易，这时开始出现以贵金属为主的货币商品。可以预见的是，人们生产产品的多少必然造成穷人和富人的出现，财富差距急剧拉大。另外，某些部落的因为生产丰富而比其它部落更加富裕，必然找来其它部落的掠夺，而这种掠夺的方式提高了原来军事民主制的军事首长的权力，出于人类与生俱来的私心，也是为了获得财务，这些军事首长希望也是直接让其后代继承他们的权力，世袭制开始出现。久而久之，军事机构在部落中从服从人民意志的角色转换成压迫和统治自己人民的工具。 最后，随着分工的进一步加强，特别是生产力进步造成的城市和农村的对立，出现了商人这个角色。可以想象这么一个场景，农民大部分时间都在劳作，在古代交通不发达的情况下，很难花费大量的时间去城市中交换产品，于是有人就充当交易中介的角色，从一个农村中收购产品，又卖给另外一个农村，为了使这个过程快速方便，铸币开始出现充当商品的商品的角色。人们发现只要拥有了铸币就可以购买一切商品，开始了对金钱的追逐，这是第三次社会大分工。很明显，商人至始至终没有参与劳动，但是可以从中获取利益。最后的结果就是因为财富进一步拉大而造成阶级的分裂——有的阶级即使不参与劳动也能快速增长财富，这谁能忍！社会因此出现阶级矛盾，而原来具有共产主义性质的氏族公社很明显无法用自己的方式来解决这个矛盾，凌驾于劳动阶级和商人阶级（分别对应现在无产阶级和资产阶级）的第三方力量——国家——随之出现，它使双方在不冲突的前提下缓和矛盾，以合法的形式来裁决，而国家也是两个阶级分别用实力共同推举而来，它以后会站在哪一边不言而喻。 国家是如何形成的在前面其实已经介绍了国家形成的原因，正是两个无法调和矛盾的阶级为了不在无谓的斗争毁灭自己和社会，需要一个凌驾于双方的机构来缓和这个矛盾，因此需要国家这个角色的介入。为了方便管理，国家的一个显著的特点就是按照地区来管理，因为之前的氏族一般聚居在一个地区，而现在因为贸易等原因人民开始不断流动，那么再按照氏族的关系网去管理会很困难，因此国家索性直接分割成地区来管理，只要取得在这个地区的户籍即可享有当地的权利，大大提高了行政管理效率。另一方面，出于避免财富被掠夺的需要（例如游牧民族国家对农耕国家的侵略），国家必须拥有公共权力来武装自己，包括地方内乱和外敌，而这种需要无论是哪个阶级都需要的，毕竟谁都希望能够安宁地赚钱。 在国家拥有这些治理人民的权力之后，很自然地，处于财富优势一方的资产阶级最后可以获得国家的治理权，即便表面上宣称国家是为所有人民服务的。很不幸地，在没有消灭财富差距之前，国家必然成为资产阶级剥削、压迫无产阶级的工具。 结论写这本书的目的在于揭示资本主义世界对无产阶级的压迫本质，特别是理解国家对于民众的意义，从这方面来说，离我们普通人实在太远。但是从其介绍的婚姻形式的发展来看，对我们的感情生活还是有一定指导意义的：两个人结婚，不论哪方，都要有对自己价值的清晰定位，最好能够“门当户对”（包括三观、性格、财富等因素），否则，从统计学的意义来说，很可能是一场注定失败的婚姻。如果要有更多的选择，那么提升自己的价值是较为稳妥的方式。","link":"/2020/05/14/%E5%AE%B6%E5%BA%AD%E3%80%81%E7%A7%81%E6%9C%89%E5%88%B6%E5%92%8C%E5%9B%BD%E5%AE%B6%E7%9A%84%E8%B5%B7%E6%BA%90/"},{"title":"强化学习之蒙特卡洛法","text":"首页摘要： 动态规划是基于模型的方法，一旦模型的状态转移概率 $P_{ss’}^{a}$ 无法获得时就无法求解。这个时候不基于模型的方法——蒙特卡洛法——可以利用采样来近似求得每个状态的价值期望，这种方法整体也可以分为策略评估(在特定的策略下每个状态价值的评估)和策略改进(确定每个状态价值后对策略进行提升)两部分。 为什么会出现蒙特卡洛法在基于动态规划的定义中，给定状态集 $S$ 、动作集 $A$ 、状态概率转移矩阵 $P$ 、回报衰减因子 $\\gamma$、以及策略集 $\\pi$ 就能够通过基于贪婪策略的动态规划找出最优策略（尽管是局部最优解）。当我们没有办法对环境建模时就无法得知状态概率转移矩阵 $P$ ，也就没有办法利用动态规划来进行求解。 从定义上来说，例如求解状态价值函数的期望，表达式是这样的： v_{\\pi}(s)=\\sum_{a \\in A}\\pi(a|s)(r_{t+1}+\\gamma \\sum_{s'\\in S}P_{ss'}^{a}v_{\\pi}(s'))其中，$\\pi(a|s)$ 是我们最后要得到的策略，$v_{\\pi}(s’)$ 是最后得到最优策略后要确定的状态价值函数，换句话说这个期望公式实质上是要知道状态概率转移矩阵 $P$ 才能进行求解的，如果不知道这个状态概率转移矩阵 $P$ ，怎么来求状态价值函数的期望呢？根据蒙特卡洛采样的性质，大量样本的平均可以近似变量的期望，用所有采样得到的完整 $episold$ 状态价值平均就可以近似得到它的期望值。 蒙特卡洛法策略评估对策略评估的手段是求出状态价值函数，首先假设在一个给定策略 $\\pi$ 下长度为 $T$ 的完整的 中序列为： S_{1},A_{1},r_{2},S_{2},A_{2},r_{3},...S_{t},A_{t},r_{t+1},...,S_{T},A_{T},r_{T+1}那么，状态价值函数可以表示为： \\begin{split} v_{\\pi}(s)&=E_{\\pi}(r_{t+1}+\\gamma r_{t+2}+ \\gamma^{2}r_{t+3}+...+\\gamma^{T-1}r_{t+T}|S_{t}=s )\\\\ &=E_{\\pi}(G_{t}|S_{t}=s )\\\\ \\end{split}在该$episold$ 下特定状态$s$ 的回报即： G_{t}=r_{t+1}+\\gamma r_{t+2}+ \\gamma^{2}r_{t+3}+...+\\gamma^{T-1}r_{t+T}那么在不同策略下每个$episold$ 可以得到出现特定状态的回报，蒙特卡洛对该状态下所有的回报取平均作为该状态价值的期望： v(s)=average(G_{t})在实际应用中，同样一个状态可能在一个完整的$episold$序列中重复出现，对于这种情况存在两种方法进行计算： （1）只计算状态$s$ 在某个$episold$ 第一次出现的回报，称之为 $first \\ visit$; （2）把所有出现状态 的回报用来计算平均值。 如果做了$N$ 次采样，那么需要保存 $N$ 个数据来做平均，为了解决存储空间，一般会采用递进累加平均值的方法来处理，状态价值计算平均值可以改写成： N(S_{t})=N(S_{t})+1\\\\ \\begin{equation} \\begin{split} v(S_{t})&=v(S_{t})+\\frac{1}{N(S_{t})}(G_{t}-v(S_{t}))\\\\ &=v(S_{t})+\\alpha (G_{t}-v(S_{t})) \\end{split} \\end{equation}类比状态价值函数的求法，动作价值函数也可以同样得到： q(S_{t},A_{t})=q(S_{t},A_{t})+\\alpha (G_{t}-q(S_{t},A_{t}))蒙特卡洛法策略改进蒙特卡罗法策略改进的方式和动态规划类似，都是先对策略评估其状态价值函数，再根据状态价值函数改进策略。但是存在不同的地方就是采用的策略略有区别，蒙特卡洛采用的是$\\epsilon -greedy$ 贪婪策略，而动态规划采用的是基本贪婪策略。具体而言，$\\epsilon -greedy$ 贪婪策略是： \\pi(a|s) =\\begin{cases} 1-\\epsilon & a= \\underset{a\\in A}{argmax}\\, q(s,a)\\\\ \\frac{\\epsilon}{m} & others \\end{cases}它表示的是使得动作价值最大的动作不一定会被选择，而是以较小的概率给其他$m$ 个动作留机会。这么做是因为蒙特卡洛法通过采样得到的状态进行最优求解不一定是实际最优解，需要留个机会给模型进行探索其它可能的方式。 蒙特卡洛法流程最后总结一下蒙特卡洛法进行强化学习的总流程，这里给出在线版(on-policy)本的过程，离线(off-policy)版本的在后续介绍。在线和离线的区别我们在后续的文章里面会讲。同时这里我们用的是every-visit,即个状态序列中每次出现的相同状态，都会计算对应的收获值。 输入:状态集$S$ 、动作集 $A$ 、即时回报$r$ 、衰减因子$\\gamma$ 、探索率$\\epsilon$ ； 输出:最优的动作价值函数 $q^{\\star}$ 、最优策略$\\pi^{\\star}$ ； 1.初始化所有的动作价值$q(s,a)=0$，状态次数$N(s,a)=0$ ，采样次数$k=0$，随机初始化一个策略$\\pi$ 2.$k=k+1$，基于策略$\\pi$ 产生完整的$episold$ 序列： S_{1},A_{1},r_{2},S_{2},A_{2},r_{3},...S_{t},A_{t},r_{t+1},...,S_{T},A_{T},r_{T+1}3.对于序列出现的每一对$q(S_{t},A_{t})$ ，计算其收获$G_{t}$ ，更新其计数$N(S_{t})$ 及动作价值函数： G_{t}=r_{t+1}+\\gamma r_{t+2}+ \\gamma^{2}r_{t+3}+...+\\gamma^{T-1}r_{t+T}\\\\ N(S_{t})=N(S_{t})+1\\\\ q(S_{t},A_{t})=q(S_{t},A_{t})+\\alpha (G_{t}-q(S_{t-1},A_{t-1}))\" alt=\"G_{t}=r_{t+1}+\\gamma r_{t+2}+ \\gamma^{2}r_{t+3}+...+\\gamma^{T-1}r_{t+T}4.基于新计算出的动作价值，更新当前的$\\epsilon -greedy$ 贪婪策略： \\pi(a|s) =\\begin{cases} 1-\\epsilon & a= \\underset{a\\in A}{argmax}\\, q(s,a)\\\\ \\frac{\\epsilon}{m} & others \\end{cases}5.如果所有的$q(S_{t},A_{t})$ 收敛，则对应的所有$q(S_{t},A_{t})$ 即为最优的动作价值函数 $q^{\\star}$ 。对应的策略 $\\pi(a|s)$ 即为最优策略 。否则转到第2步。 结语蒙特卡洛法解决了动态规划需要模型参数的问题，但是它存在的问题是需要完整的$episold$ 序列，实际应用中可能没有那么多的完整$episold$ 序列，时序差分方法就是为了解决这个方法而提出来的。","link":"/2019/03/29/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%B3%95/"},{"title":"强化学习之时序差分法","text":"首页摘要： 时序差分法和蒙特卡洛法都是不用基于模型的方法，但是蒙特卡洛需要完整的序列才能使用，而时序差分法正是用来克服这个不足的。时序差分法的在线（on-policy）版是SARSA算法、离线（off-policy）版是Q-learning算法，不同的策略改进方式产生了这个差别。 时间差分法从蒙特卡洛法我们知道，动作价值函数通过采样再取平均来更新： G_{t}=r_{t+1}+\\gamma r_{t+2}+ \\gamma^{2}r_{t+3}+...+\\gamma^{T-1}r_{t+T}\\\\ N(S_{t})=N(S_{t})+1\\\\ \\begin{equation} \\begin{split} v(S_{t})&=v(S_{t})+\\frac{1}{N(S_{t})}(G_{t}-V(S_{t}))\\\\ &=v(S_{t})+\\alpha (G_{t}-v(S_{t})) \\end{split} \\end{equation}\\\\ q(S_{t},A_{t})=q(S_{t},A_{t})+\\alpha (G_{t}-q(S_{t},A_{t}))根据回报的表达式可知： G_{t}=r_{t}+\\gamma v(S_{t+1})所以蒙特卡洛计算状态价值以及动作价值函数的公式可以改写成： G_{t}=r_{t+1}+\\gamma v(S_{t+1})\\\\ v(S_{t})=v(S_{t})+\\alpha (r_{t}+\\gamma v(S_{t+1})-v(S_{t}))\\\\ q(S_{t},A_{t})=q(S_{t},A_{t})+\\alpha (r_{t}+\\gamma q(S_{t+1},A_{t+1})-q(S_{t},A_{t}))其中的 $\\alpha$ 是设置的迭代超参数，因为时序差分法是在持续进行环境中学习，不会等到运行结束再采样完整的序列，最后一个公式之所以可以把$G_{t}=r_{t}+\\gamma v(S_{t+1})$改写成$G_{t}=r_{t}+\\gamma q(S_{t+1},A_{t+1})$，是因为动作价值函数是确定动作之后的价值函数，而价值函数是多个可能动作下的动作价值函数的期望。 前面所述回报是用向前一步来代替，但是也可以用 $n$ 步来代替： G_{t}=r_{t+1}+\\gamma r_{t+1}+\\gamma ^{2} r_{t+2}+...+\\gamma ^{n-1} r_{t+n}+\\gamma ^{n} v(S_{t+n})当 $n$ 趋于无穷时，时序差分法相当于蒙特卡洛法。因此确定这个步数是一个需要考虑的问题，但是为了从理解原理起见，这里只介绍一步前向回报。 在蒙特卡洛法中，我们用了在线（on-policy）策略来进行强化学习。对于时序差分法来说，在线版本是SARSA算法，离线版本是Q-learning。在线是指选择动作和更新动作值函数都是基于同一个$\\epsilon -greedy$ 贪婪策略，而离线是指选择动作采用$\\epsilon -greedy$贪婪策略，更新动作值函数使用$max$贪婪策略。算法具体细节见以下两节。 SARSASARSA算法迭代时，基于$\\epsilon -greedy$ 贪婪策略在状态 $s$ 时选择动作 $a$ ，获得实时回报 $r$ 并转到状态 $s’$，进一步根据$\\epsilon -greedy$ 贪婪策略采取动作 $a’$ ，这个时候就可以更新动作值函数： \\begin{equation} \\begin{split} q(s,a)&=q(s,a)+\\alpha (G_{t}-q(s,a))\\\\ &=q(s,a)+\\alpha (r+\\gamma q(s',a')-q(s,a)) \\end{split} \\end{equation}具体算法流程如下： 输入:迭代轮数 $T$、状态集 $S$ 、动作集 $A$ 、即时回报 $r$ 、衰减因子 $\\gamma$ 、探索率 $\\epsilon$ ； 输出:所有的状态和动作对应的价值 $q$ ； 1.随机初始化所有的状态和动作对应的价值 $q$ ； 2.for $i$ to $T$ ，进行迭代 （1）初始化 $s$ 为当前状态序列的第一个状态。设置 $a$ 为$\\epsilon -greedy$ 贪婪策略在状态 $s$ 下选择的动作 （2）在状态 $s$ 下执行动作 $a$ ，转到状态 $s’$ 并获得回报 $r$ （3）利用$\\epsilon -greedy$ 贪婪策略在状态 $s’$ 下得到选择的动作 $a’$ （4）更新动作价值函数： q(s,a)=q(s,a)+\\alpha (r+\\gamma q(s',a')-q(s,a))（5）$s=s’,a=a’$ （6）如果 $s$ 是终止状态，当前轮迭代完毕，否则转到步骤(2) 这里有一个要注意的是，步长 $\\alpha$ 一般需要随着迭代的进行逐渐变小，这样才能保证动作价值函数可以收敛。当动作价值函数收敛时，我们的 $\\epsilon -greedy$ 贪婪策略也就收敛了。 Q-learning.Q-learning算法迭代时，基于$\\epsilon -greedy$贪婪策略在状态 $s$ 时选择动作 $a$ ，获得实时回报 $r$ 并转到状态 $s’$，和SARSA算法不同的是进一步根据$max$贪婪策略采取动作 $ a’$ ，这个时候就可以更新动作值函数： \\begin{equation} \\begin{split} q(s,a)&=q(s,a)+\\alpha (G_{t}-q(s,a))\\\\ &=q(s,a)+\\alpha (r+\\gamma q(s',a')-q(s,a)) \\end{split} \\end{equation}具体算法流程如下： 输入:迭代轮数 $T$、状态集 $S$ 、动作集 $A$ 、即时回报 $r$ 、衰减因子 $\\gamma$ 、探索率 $\\epsilon$ ； 输出:所有的状态和动作对应的价值 $q$ ； 1.随机初始化所有的状态和动作对应的价值 $q$ ； 2.for $i$ to $T$ ，进行迭代 （1）初始化 $s$ 为当前状态序列的第一个状态。对于终止状态其 $q$ 值初始化为0。设置 $a$ 为$\\epsilon -greedy$ 贪婪策略在状态 $s$ 下选择的动作 （2）在状态 $s$ 下根据 $\\epsilon -greedy$ 贪婪策略执行动作 $a$ ，转到状态 $s’$ 并获得回报 $r$ （3）利用$max$贪婪策略在状态 $s’$ 下得到选择的动作 $a’$ （4）更新动作价值函数： q(s,a)=q(s,a)+\\alpha (r+\\gamma q(s',a')-q(s,a))（5）$s=s’$ （6）如果 $s$ 是终止状态，当前轮迭代完毕，否则转到步骤(2) 这里有一个要注意的是，步长 $\\alpha$ 一般需要随着迭代的进行逐渐变小，这样才能保证动作价值函数可以收敛。当动作价值函数收敛时，我们的 $\\epsilon -greedy$ 贪婪策略也就收敛了。 结语在实际应用中两种方法各有优劣，具体来说，存在以下几个区别： Q-learning在更新动作价值时采用的是贪婪策略，而SARSA采用的是 $\\epsilon -greedy$ 贪婪策略，导致前者收敛速度更快，但是这也导致前者更加激进，容易掉入“最优陷阱”（实际上或许最优性还不如后者）； 一个就是Q-Learning直接学习最优策略，但是最优策略会依赖于训练中产生的一系列数据，所以受样本数据的影响较大，因此受到训练数据方差的影响很大，甚至会影响Q函数的收敛。Q-learning的深度强化学习版Deep Q-Learning也有这个问题。 因此，在模拟环境中一般使用Q-learning（试错机会多），实际生产环境用SARSA（保守操作更好）。但是这两种方法只适合状态和动作都比较少的环境，因为如果状态和动作很多的话，会导致Q值表非常大以至于内存不足，此外还容易造成维数灾。针对这个问题，近几年兴起的深度学习在一定程度上解决了这个问题，在未来的学习中，我将结合深度学习来进行介绍。","link":"/2019/03/30/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%B6%E5%BA%8F%E5%B7%AE%E5%88%86%E6%B3%95/"},{"title":"改变","text":"首页摘要： 一个人最难改变的是自己，需要的是对过去的自己反思，对过去的遭遇深入研究、分析，不破不立！ 啊，昔日醉心于斗争的忧郁的灵魂， 希望曾以马刺来激起你的热情， 如今竟再也不想骑你：躺下吧，别再有什么羞耻心， 啊，老马，如今你遇到任何障碍都不得不停顿！ 听天由命吧，我的心：请睡得像死一样沉！ 啊，四处碰壁而疲乏不堪的灵魂！啊，老贼，爱情 对你来说不再有什么趣味，只是争吵而已； 别了，铜号的歌声和长笛的叹息！ 啊，欢乐，情别再诱惑一颗阴郁而无所追求的心！ 可爱的春天已经失去往日的芳馨！ 时间正一刻不停地吞没我， 犹如大雪吞没一具冻僵的尸首； 我从天上俯瞰这圆形的地球， 再也不从尘世寻求一个容我栖身的简陋的住所。 啊，雪崩，你可肯让我随着你的塌落而隐没？ ——波德莱尔，《恶之花.忧郁与理想.虚无的感受》","link":"/2018/05/21/%E6%94%B9%E5%8F%98/"},{"title":"日本上智大学“樱花计划”第一天——东京，我来了","text":"首页摘要： 樱花计划是日本政府为促进本国与国外学术交流并借此引进人才的一个项目，日本东京上智大学申铁龙教授邀请我实验室至日本进行学术交流。经过多日的准备，我、阳哥（彭刘阳）、城哥（周际城）完成了樱花计划的实验——设计燃油发动机的空燃比控制系统，此事暂且按下不表。8月16号是出发至东京的时间，本人是第一次坐飞机，想想还是有点小激动的。 第一次坐飞机的感受早上六点钟从武汉大学工学部出发，大家坐着大巴出发至天河机场。在出发之前我就担心因为行李超重引起不必要的麻烦，结果发现称重不到限额的一半，还是很轻松愉快的，就是没带早餐，结果发现机场的拉面88？好吧，随便买了一瓶矿泉水就等着飞机餐了。。。 九点半左右（中国时间）登机，起飞之前飞机在跑道上滑行了一段时间终于拉升了，感觉和坐电梯上升差不多。慢慢地，飞机平稳飞行，穿过云层浮至棉花糖般的云朵之上。一行人也渐渐入睡，睡了大概一个小时，饭终于来了，A、B两种款式，本着随机的原则选了牛肉套餐，味道不是特别好，毕竟我把面条料酒加到米饭里面了，沙拉肉泥什么的吃不习惯，在飞机上也根本不想享用哈根达斯，能填饱肚子就不错了。 两点半左右（日本时间）到达东京上空，从空中看，东京的绿化不错可以看到大片的绿地及农田。抵达机场的时候，飞机急速下降，有种坐跳楼机的既视感，回来还可以感受一次。。。 日本ANA机场总体来说，坐飞机比坐火车还是要舒服一些，就是起飞下降不太适应。 在东京第一次的夜生活一路上乘坐火车地铁终于到了酒店，大概七点左右安顿好之后，各自找地方吃饭。酒店的位置在赤坂见附，周边还是有很多吃饭的地方，从街景可以看出来夜市是非常发达的。唯一的缺点就是贵，对于我这种穷学生来说，普通1000日元的晚饭都是一种奢侈，最后挑了一家日式意大利面，算是比较便宜的地方了。 繁忙的夜市 日式意大利面晚上我们简单地在周围逛了一圈，便利店非常多，各种罗森、7eleven等便利店随处可见，还是一句老话——太贵了，泡面都得100日元，大概是贫穷限制了我的想象力，最后打开泡面发现连叉子都没有，资本主义社会真的太抠了。总的来说，东京还是一个非常吸引人的城市，有待我们进一步发掘。鉴于第二天还得听课，我们早早地休息了。","link":"/2018/08/16/%E6%97%A5%E6%9C%AC%E4%B8%8A%E6%99%BA%E5%A4%A7%E5%AD%A6%E2%80%9C%E6%A8%B1%E8%8A%B1%E8%AE%A1%E5%88%92%E2%80%9D%E7%AC%AC%E4%B8%80%E5%A4%A9%E2%80%94%E2%80%94%E4%B8%9C%E4%BA%AC%EF%BC%8C%E6%88%91%E6%9D%A5%E4%BA%86/"},{"title":"拉格朗日对偶","text":"首页摘要： 优化问题原问题求解起来往往非常复杂，这个时候需要构建对偶问题来进行求解，如果原问题是凸模型，那么对偶问题的最优解就是原问题的最优解。这篇文章主要介绍拉格朗日对偶方法的来龙去脉。 拉格朗日对偶函数的定义 定义 考虑标准优化问题（原问题）： \\begin{matrix} minimize & f(x) \\hfill \\\\ subject\\ to & h_{i}(x)=0,i=1,2,...m\\\\ & g_{j}(x)\\leq 0,j=1,2,...p\\\\ \\end{matrix}其中，函数$f: R_{n} \\rightarrow R $ ，$x \\in R^{n}$。那么可以定义拉格朗日函数： L(x,\\lambda ,\\nu )=f(x)+\\sum_{j=1}^{p}\\lambda _{j}g_{j}+\\sum_{i=1}^{m}\\nu _{i}h_{i}进一步，拉格朗日对偶函数可以被定义为： \\begin{align*} l(\\lambda ,\\nu)&= \\underset{x \\in D}{inf}\\; L(x,\\lambda ,\\nu ) \\\\ &= \\underset{x \\in D}{inf}\\;f(x)+\\sum_{j=1}^{p}\\lambda _{j}g_{j}+\\sum_{i=1}^{m}\\nu _{i}h_{i}\\end{align*}这里$inf$ 表示下确界，$D$表示定义域，可以看出$l(\\lambda ,\\nu)$ 是关于$\\lambda ,\\nu$ 的仿射函数，也是关于$x$的逐点下确界。既然$l(\\lambda ,\\nu)$ 是仿射函数，说明无论原问题是否为凸，对偶问题一定为凸。 性质 对偶函数构成了原问题最优解$x^{\\star}$的下界，这是因为对于任何$\\lambda\\geqslant 0$ 、$x \\in D$有： \\begin{align*} L(x,\\lambda ,\\nu )&= f(x)+\\sum_{j=1}^{p}\\lambda _{j}g_{j}+\\sum_{i=1}^{m}\\nu _{i}h_{i} \\\\ &\\leq f(x)\\end{align*}上式成立是因为：$\\sum_{j=1}^{p}\\lambda _{j}g_{j} \\leq 0$、$\\sum_{i=1}^{m}\\nu _{i}h_{i}=0$。所以， l(\\lambda ,\\nu)= \\underset{x \\in D}{inf}\\; L(x^{\\star},\\lambda ,\\nu ) \\leq L(x^{\\star},\\lambda ,\\nu ) \\leq f(x^{\\star}) 弱对偶与强对偶 定义 上一节我们得到一个结论就是：$l(\\lambda ,\\nu) \\leq f(x^{\\star})$，也就是说，$\\underset{\\lambda ,\\nu}{max}\\ l(\\lambda ,\\nu) \\leq f(x^{\\star})$ ，这个也称之为对偶问题的最好下界，可以表述成如下优化问题： \\begin{matrix}maximize & l(\\lambda ,\\nu) \\hfill\\\\ subject\\ to & \\lambda_{j} \\geq 0, j=1,2,...,p\\end{matrix}这就是原问题的拉格朗日对偶问题，它的最优目标值是$d^{\\star}$，且根据前面的结论可以得到$d^{\\star} \\leq f(x^{\\star})$ ，$ f(x^{\\star})- d^{\\star}$ 称之为对偶间隙。 这里有个有意思的现象是，对偶问题等价于: \\underset{\\lambda \\geq 0 ,\\nu}{max}\\ \\underset{x\\in D}{min}\\ L(x,\\lambda ,\\nu )= f(x)+\\sum_{j=1}^{p}\\lambda _{j}g_{j}+\\sum_{i=1}^{m}\\nu _{i}h_{i}而原问题可以转化为： f(x^{\\star})=\\underset{x\\in D}{min}\\ \\underset{\\lambda \\geq 0 ,\\nu}{max}\\ L(x,\\lambda,\\nu )= f(x)+\\sum_{j=1}^{p}\\lambda _{j}g_{j}+\\sum_{i=1}^{m}\\nu _{i}h_{i}从上面两个式子可以清楚地看到，其实公式形式上原问题和对偶问题就是对偶的，而正是$min$和$max$两个求优算子的调换造成了对偶间隙，如果原问题是凸的话，这两个求优算子调换之后，原问题和对偶问题的最优值也是相同的。 很自然的想法是，既然对偶问题是凸问题，而且求解也更简单，我们能否根据这个对偶问题的最优目标值来逼近原问题的最优目标值呢？甚至对偶问题的最优目标值就是原问题的最优目标值呢？答案是肯定的。这两种情况分别称之为弱对偶（对偶间隙大于0）和强对偶（对偶间隙等于0）。 弱对偶的几何解释 本节我们用一个特殊的几何例子来解释出现弱对偶的原因，强对偶会在下一节进一步用公式来解释。首先构建集合$\\Omega =\\begin{Bmatrix}(h_{1}(x),…,h_{m}(x),g_{1}(x)…,g_{p}(x),f(x)) \\in R^{m}\\times R^{p}\\times R | x \\in D\\end{Bmatrix}$ ，原问题的最优解可以表示成 f(x^{\\star})=\\begin{Bmatrix}(t|(u,v,t) \\in \\Omega,u_{j} \\leq 0, v_{i}=0\\end{Bmatrix}其中，$u$、$v$、$t$分别是不等式约束、等式约束、目标函数的简写符号。拉格朗日函数则可以据此表示成： (\\lambda ,\\nu,1 )^{T}(u,v,t)= \\sum_{j=1}^{p}\\lambda _{j}u_{j}+\\sum_{i=1}^{m}\\nu _{i}v_{i}+t故拉格朗日对偶函数为： l(\\lambda ,\\nu)=inf\\begin{Bmatrix}(\\lambda ,\\nu,1 )^{T}(u,v,t)|(u,v,t) \\in \\Omega\\end{Bmatrix}即： (\\lambda ,\\nu,1 )^{T}(u,v,t) \\geq l(\\lambda ,\\nu)这个不等式定义了一个非垂直支撑超平面，之所以称之为非垂直支撑超平面，是因为左项法向量最后一个分量为1. 本节铺垫到此结束，现在基于上述内容用几何解释来说明强对偶。 图1用只有一个不等式约束的优化问题来说明，可以将集合$\\Omega = \\{ (h_{1}(x),f(x)|x \\in D\\}$画在二维平面上，如图1所示，给定$\\lambda$，在集合$\\Omega$中极小化$(\\lambda ,1 )^{T}(u,t)$，得到斜率为$-\\lambda$的非垂直支撑超平面。注意只有$u\\leq 0$部分（即黄线区域）才是可行域，而$\\lambda$必须大于零，所以在$u=0$处取得$l(\\lambda ,\\nu)=l(\\lambda)$的最大值（因为$(\\lambda ,\\nu,1 )^{T}(u,v,t) \\geq l(\\lambda ,\\nu)$）。橘色直线是不同$\\lambda$下$\\Omega$的支撑超平面，它们与$t$轴的截距最大值表示拉格朗日对偶函数的最优值，因为$d^{\\star}&lt;p^{\\star}$，所以是弱对偶。如果原问题是凸函数，一般最优的非垂直超平面都能穿过$p^{\\star}$点。 KKT条件从前面我们可以知道，只要优化问题满足了强对偶要求，那么就找到了优化问题的全局最优解，那么如何公式化表达这个特点呢？基于强对偶的KKT条件可以帮助我们找到和判断全局最优解。 KKT条件是非凸优化问题取得全局最优解的必要条件，而是凸优化问题取得全局最优解的充要条件，换言之，KKT条件可以用来检验非凸优化问题是否取得全局最优解，凸优化问题可以利用KKT条件求解全局最优解。无论在非凸优化问题还是在凸优化问题中，KKT条件都是一样的形式。从前面的介绍可以知道，优化问题如果有全局最优解$x^{\\star}$，对于原问题来说，必须满足约束条件： \\begin{matrix} & h_{i}(x^{\\star})=0,i=1,2,...m\\\\ & g_{j}(x^{\\star})\\leq 0,j=1,2,...p\\\\ \\end{matrix}对于拉格朗日对偶函数来说，必须满足： \\lambda _{j} \\geq 0,j=1,2,...p在全局最优解处，拉格朗日对偶函数的微分为0，这样保证了这是一个极值，公式如下： \\nabla f(x^{\\star})+\\sum_{j=1}^{p}\\lambda _{j}\\nabla g_{j}(x^{\\star})+\\sum_{i=1}^{m}\\nu _{i}\\nabla h_{i}(x^{\\star})=0还一个条件是当解是全局最优解时，满足强对偶要求，即原问题最优解和拉格朗日对偶问题最优解相等，两者目标函数要相等，必须满足： \\sum_{j=1}^{p}\\lambda _{j}g_{j}(x^{\\star})=0综上所述，KKT条件为： \\left\\{\\begin{matrix} & h_{i}(x^{\\star})=0,i=1,2,...m \\hfill& \\\\ & g_{j}(x^{\\star})\\leq 0,j=1,2,...p \\hfill& \\\\ & \\lambda _{j} \\geq 0,j=1,2,...p \\hfill& \\\\ & \\nabla f(x^{\\star})+\\sum_{j=1}^{p}\\lambda _{j}\\nabla g_{j}(x^{\\star})+\\sum_{i=1}^{m}\\nu _{i}\\nabla h_{i}(x^{\\star})=0\\hfill & \\\\ & \\sum_{j=1}^{p}\\lambda _{j}g_{j}(x^{\\star})=0 \\hfill& \\end{matrix}\\right.结语至此，凸优化的对偶问题已经介绍完了，这部分是我认为最难理解的内容，特别是弱对偶的几何解释，但是这部分内容是之后如何求解凸优化问题以及取得全局最优解的利器，KKT条件则是其中的核心方法，后续我将介绍如何用KKT条件大杀四方。","link":"/2020/02/05/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%AF%B9%E5%81%B6/"},{"title":"日本上智大学“樱花计划”第七天——硬件在环实验演示","text":"首页摘要： 本来计划在今天把之前各组搭建的模型代码烧录至dipace进行发动机控制实验，但是我们搭的模型没有给出完美的控制效果以及不适合硬件实验，最重要的是万一我们把实验室的发动机玩坏了那就不大好了，于是老师师兄们决定做演示实验给我们看看=_=。当然了，演示实验只是饱饱眼福，今天我要介绍的是日本赫赫有名的章鱼小丸子！——来给大家饱饱口福..。 硬件在环实验其实这个实验平台在第二天的博客就已经介绍过了，这次只不过是各位师兄实操了一遍给我们看，我就不再介绍了。只不过既然是学术项目，标题还得取这个以表敬意。放几张在这个平台做过实验的文章意思意思。 不知道为什么，markdown没法竖着显示233 先进车辆控制 实验平台示意图章鱼小丸子先百度一波这玩意儿：章鱼烧，又名章鱼小丸子，在日本已有70多年的历史，是日本民间一种流传很久的风味小吃，据说章鱼烧最早出于大阪的章鱼烧丸专营店会津屋的创始人远藤留吉之手。远藤留吉起初将肉、魔芋等加入调开的小麦粉面糊里煎烧后放在食摊上卖。后来，1935年时，远藤留吉开始使用章鱼作为原材料，并在面糊里调入味道，煎烧出的章鱼烧丸大受人们的欢迎。因每颗章鱼丸里都有鲜章鱼肉，其味鲜而香，营养成分十分丰富，广受消费者的青睐，故得其名为章鱼小丸子，又名为章鱼烧，很快，章鱼烧从大阪被推广到日本全国。 我们一行三人找了一家酒屋喝酒，看到章鱼小丸子而且还是自制，那必然点一份哪。这家酒屋还有一个好玩的项目就是可以通过摇色子免去酒的费用（当然没摇到就得买一杯双倍费用的酒），今晚我们运气爆棚每个人都免单了点的酒，哈哈哈。 田中烧酒、日本清酒，虽然我非爱酒之人，但是常常也无不可，喝起来没有中国烧酒那么烈，自然度数也比较低 章鱼小丸子的制作，把面糊糊倒进去自己烤就好了 章鱼小丸子要趁热吃。。 免单的三杯威士忌，运气咋那么好呢最后我想说的是，酒别混着喝，这晚我回去就晕了。。。","link":"/2018/08/22/%E6%97%A5%E6%9C%AC%E4%B8%8A%E6%99%BA%E5%A4%A7%E5%AD%A6%E2%80%9C%E6%A8%B1%E8%8A%B1%E8%AE%A1%E5%88%92%E2%80%9D%E7%AC%AC%E4%B8%83%E5%A4%A9%E2%80%94%E2%80%94%E7%A1%AC%E4%BB%B6%E5%9C%A8%E7%8E%AF%E5%AE%9E%E9%AA%8C%E6%BC%94%E7%A4%BA/"},{"title":"整数规划约束处理技巧","text":"首页摘要： 这篇博文是在构建最优特征子集方法是发现的处理整数规划中约束条件（包括一些经典的逻辑约束条件）的处理方法，以两只小熊风趣幽默的对话把这些技巧告诉读者，记录下来以后还能翻翻。","link":"/2018/12/20/%E6%95%B4%E6%95%B0%E8%A7%84%E5%88%92%E7%BA%A6%E6%9D%9F%E5%A4%84%E7%90%86%E6%8A%80%E5%B7%A7/"},{"title":"日本上智大学“樱花计划”第三天——参观日本松下","text":"首页摘要： 今天的日程为参观日本松下，但是要遵守日方的保密条例就没有拍照片了。参观的内容为介绍日本的文化、2020年东京奥运会，类似一个博物馆，日本的文化有一些地方还是很有意思的。 日本文化没有图我就不知道怎么往下写了，虽然有图写出来的东西也惨不忍睹（反正我自己看），写着写着就想起了日本的和服，男款女款看起来都很漂亮啊，在大街上看得比较多得是穿着和服的小姐姐，太美了好吧。实在不知道写什么了，就随便放一张在上智大学门口出发的照片吧。。。 这才是上智大学最醒目的标志 日本松下在松下主要参观松下的未来生活展区，体现了日本人未来的生活理念，就是目前的科技还没有让我感受到未来生活有多美妙，不过理念包含的高科技很多。讲解包括了厨房、客厅、卧室，我都会简单地一一介绍。 为了体现科技夏令营的“科技”，给我们讲解的是一位和蔼可亲的阿姨，为了表示尊重，暂且称之为小姐姐。首先介绍的是厨房，厨房中的食物水果都有专门的储物柜进行存储，一旦想吃什么就可以呼唤小机器人帮你做，小机器人会很贴心地递上菜单，想吃什么点什么，这就是后勤自动化；在客厅有一个投影仪和一个桌子，这个桌子的用处在于解读物品，比如你的平板放上去，投影仪可以把平板的屏幕投影上去并可以直接隔空控制投影仪屏幕，感觉很棒；卧室就更玄了，晚上熄灯天花板可以显示星空等等，洗漱间的镜子可以为你的脸定制化妆品，还有为你选择要穿的衣服，这个对我不会整自己的人可能非常有用（一键磨皮）。 玩耍才是正题像什么优衣库、松本清都不说了，毕竟这些地方非我擅长，给姐姐带的化妆瓶已经蒙了我一逼。今天要说的地方是《你的名字》取景的一个地点，当然了，这些都是城哥他们告诉我的，原谅我连一部动漫都没看完，第一次听说《你的地方》，不过看到实景对比动漫还是有点激动的，假装我也曾在动漫里出现过（路人也好）。 主角回眸一笑两脸懵逼的地方今天的文笔貌似不佳233，就这样吧！","link":"/2018/08/18/%E6%97%A5%E6%9C%AC%E4%B8%8A%E6%99%BA%E5%A4%A7%E5%AD%A6%E2%80%9C%E6%A8%B1%E8%8A%B1%E8%AE%A1%E5%88%92%E2%80%9D%E7%AC%AC%E4%B8%89%E5%A4%A9%E2%80%94%E2%80%94%E5%8F%82%E8%A7%82%E6%97%A5%E6%9C%AC%E6%9D%BE%E4%B8%8B/"},{"title":"日本上智大学“樱花计划”第二天——参观实验室","text":"首页摘要： 今日行程安排主要是参观上智大学以及申教授的发动机控制研究实验室，下午第一堂课就是申老师给我们讲述控制理论，感受到了老一辈人的数学功底以及严谨，给我最大的感受就是我们现在很多人在追求工具而忽略了科学的本质内涵，最后得到的成果自然只是皮毛。当然了，最重要的还是晚上的happy time——上东京塔俯瞰整个东京！ 参观上智大学日本的大学并不像中国大学“地大物博”，往往是小巧玲珑，而且现代感十足（除了东京大学、京都大学这些老牌帝国大学外），图1即为上智大学正门，可以感受到它的低调，但是走进实验室才发现它的肚子里都是货啊。 上智大学正门，申老师不小心入镜了，但是最自然的pose才是最帅的pose接着我们参观了上智大学的博物馆（或者称之为校史馆），看了上智大学的历史变迁感觉日本有名的大学一般历史底蕴还是很深厚的，不过也有中国大学强行增加校史的嫌疑。。。不管怎么说，上智大学总体上还是一所有内涵有颜值的大学。 （ 上智大学博物馆 一号楼走廊 七夕在7号楼前合影 上智大学前的小河，加滤镜就体现我的拍照技术了印象最深刻的莫过于校内的活动宣传栏，宣传海报都是手绘，上智大学的学生让我想起了上个世纪的中国大学生，总觉得这样的活力更加有一种青春的气息。 最后一站到申老师的实验室参观，这个实验室研究属于典型的校企联合研发的模式。由于大部分项目都是和汽车公司合作，因此研究方向主要为发动机的控制。实验室内主要为硬件在环控制平台：一台实体发动机由dispace控制，可以通过烧录代码写入控制算法，而发动机的路况信息则由测控机模拟（如风速、阻力等），发动机的能量补偿可以直接利用逆变器与电网交互。所以说，这个实验室最大的特点就是接地气，根据实际需求来进行研究，可能这就是国内外比较大的区别吧。 总的来说，上智大学是一所充满活力、朝气蓬勃的大学，不失为在日留学的好大学。 申老师的第一堂课进了上智大学总归要稍稍接受申老师的指导的，第一堂课就由申老师执牛耳。内容主要是关于控制系统稳定性判别的方法——李普雅诺夫定律，但是今天我不介绍这个定律的内容。我想说的是申老师想要让我们学会的——道与器的关系，控制理论包含了很多定理公式：劳斯判据、波特图。。。。不一而足，这些都是控制领域的器，在工程师的手里都是利器。可是如果科学要向前发展必须掌握控制的道，何谓“道”，是一种分析的思维，而这种思维数学功底必不可少，通过数学符号把现象表达出来，再一步步向前推导。 我自己目前做科研依赖器太过严重，以为算法是万能的，却不知天下没有免费的午餐，一个东西既然有益于一方面那么必然存在有害于另一方面的地方。做研究大概是仔细分析对象的特性，根据其不足提出解决方案，其实做什么不都是这样呢？怎么可能一招鲜走遍天呢？感谢申教授这次的教导，获益良多。 东京塔和中国明珠塔、广州塔一样，作为东京的标志性建筑，从东京塔上可以俯瞰东京全城，只不过越往上走门票越贵，只能说贫穷限制了我的眼界，最后我们选择了第一层（门票只要900日元！我怎么会说东京塔塔有三层呢）。但是也就这一层就已经美不胜收了，东京的夜景大部分尽收眼底，川流不息的车辆构成了一条条光流，别具一番风情，特别是东京塔内的小灯，一抹一抹的“流星”不断划过东京夜景的上空，这就是天人合一吧。东京塔内贩卖着各式纪念品，本来打算从日本寄几张明信片回国的，却发现没有可以寄的人，还是作罢，不过还是买了几张以备不时之需=_=。 东京塔 东京塔外夜景 东京塔内的流星 我觉得我越来越骚了=_=","link":"/2018/08/17/%E6%97%A5%E6%9C%AC%E4%B8%8A%E6%99%BA%E5%A4%A7%E5%AD%A6%E2%80%9C%E6%A8%B1%E8%8A%B1%E8%AE%A1%E5%88%92%E2%80%9D%E7%AC%AC%E4%BA%8C%E5%A4%A9%E2%80%94%E2%80%94%E5%8F%82%E8%A7%82%E5%AE%9E%E9%AA%8C%E5%AE%A4/"},{"title":"日本上智大学“樱花计划”第九天——参观丰田公司","text":"首页摘要： 这一天是在日本的最后一天学习了，行程是参观丰田公司，可惜当地天气不大好，没办法看到富士山，只能说去不逢时了。除了感叹丰田的财大气粗、技术先进之外，还有当晚的日本榻榻米让我印象深刻，让我感觉是真来旅游的。。。 日本丰田公司从东京出发坐新干线大概40分钟到静冈县富士山也就是丰田公司坐在地，到了公司所在地才让我震惊，丰田公司总部占了富士山估摸着有中国一个乡镇的面积，自己修建了各式建筑以及他们所需的测试跑道，他们所谓跑道是真公路，不得不感叹真有钱。上午我们参观了丰田公司的发动机模拟实验室以及硬件在环控制实验室，由于进去就不能带手机，因此没有拍照片，这个过程大致明白了发动机的工作原理，好像也没其他收获了。。。下午听新加坡南洋理工大学黄广斌教授的讲座《极限学习机》，讲座讲得比较宽泛，介绍了这种算法的优点以及未来的发展趋势，不过黄教授是一个很有趣的老师=_=。 日本榻榻米听完讲座我们就抓紧时间赶到酒店入住，今晚注定不会平静，还不知道日本人的晚会是怎么样的，也不知道酒店的温泉怎么样，听说还要和申老师、黄老师喝酒。希望今晚不会像前天那样喝得不省人事。 一进房间，看到没有床的地面，榻榻米别具风味啊，茶道、书画一应俱全，配备的和服穿起来感觉也不一样了，终于体验了一把日本人穿和服的感觉。 不骚誓不为人 照片又反了？ 日本欢送酒会，生鱼片、龙虾什么的，基本是生食，吃起来很不习惯，但是味道还可以，申老师告诉我在日本敬酒时给对方倒酒然后把杯子伸过去让对方倒酒，起初还有点懵。。。后来慢慢适应了，只是我那蹩脚的英文和日本友人交流起来极其困难，我偏又话多。。。没救了。在把酒言欢的时候，申老师上去唱了一首《小薇》，一发不可收拾，大家纷纷点歌，我反正不会唱歌，略显寂寞。 记住图片上面另外两位在今晚中喝得烂醉如泥，不过没在这边醉一次也是一种遗憾吧~这次的日本学术交流活动到此为止，写的这几篇博客也就是记一些流水账，给自己以后留点回忆。在日本遇到了很多让我敬佩的人，玩的也很开心，学到的东西也很多。总之，此次不虚此行，未来日子且行且珍惜，尽力而为！","link":"/2018/08/24/%E6%97%A5%E6%9C%AC%E4%B8%8A%E6%99%BA%E5%A4%A7%E5%AD%A6%E2%80%9C%E6%A8%B1%E8%8A%B1%E8%AE%A1%E5%88%92%E2%80%9D%E7%AC%AC%E4%B9%9D%E5%A4%A9%E2%80%94%E2%80%94%E5%8F%82%E8%A7%82%E4%B8%B0%E7%94%B0%E5%85%AC%E5%8F%B8/"},{"title":"日本上智大学“樱花计划”第八天——实验汇报","text":"首页摘要： 这一天的主要内容是向申铁龙教授汇报此次项目研究实验的成果，前几天由于讲座占用了大部分时间且剩下的时间又都是到处玩，于是我们一致选择了在上午讲座上赶出汇报的PPT，结果可想而知，下午随即被申老师问得哑口无言。特别是此次我们这组控制部分由我介绍，讲演效果实在不忍直视，回国应该好好反思，努力提高表达能力。不过汇报完之后大家都放飞自我，剩下的时间抓紧时间玩=_= 实验内容为对发动机空燃比的控制，控制量为燃油注入量。辨识方法采用神经网络模型，控制手段我们尝试了PID、神经网络自适应PID、神经网络逆模型，从实验结果发现还是PID效果最好。最大的收获是对控制领域大致的研究过程有了了解，Simulink也有了一定的掌握，总算没有划水。。。报告PPT内容如下：","link":"/2018/08/23/%E6%97%A5%E6%9C%AC%E4%B8%8A%E6%99%BA%E5%A4%A7%E5%AD%A6%E2%80%9C%E6%A8%B1%E8%8A%B1%E8%AE%A1%E5%88%92%E2%80%9D%E7%AC%AC%E5%85%AB%E5%A4%A9%E2%80%94%E2%80%94%E5%AE%9E%E9%AA%8C%E6%B1%87%E6%8A%A5/"},{"title":"日本上智大学“樱花计划”第六天——Lecture2","text":"首页摘要： 这一天的主要内容是向申铁龙教授汇报此次项目研究实验的成果，前几天由于讲座占用了大部分时间且剩下的时间又都是到处玩，于是我们一致选择了在上午讲座上赶出汇报的PPT，结果可想而知，下午随即被申老师问得哑口无言。特别是此次我们这组控制部分由我介绍，讲演效果实在不忍直视，回国应该好好反思，努力提高表达能力。不过汇报完之后大家都放飞自我，剩下的时间抓紧时间玩=_= 实验内容为对发动机空燃比的控制，控制量为燃油注入量。辨识方法采用神经网络模型，控制手段我们尝试了PID、神经网络自适应PID、神经网络逆模型，从实验结果发现还是PID效果最好。最大的收获是对控制领域大致的研究过程有了了解，Simulink也有了一定的掌握，总算没有划水。。。报告PPT内容如下：","link":"/2018/08/21/%E6%97%A5%E6%9C%AC%E4%B8%8A%E6%99%BA%E5%A4%A7%E5%AD%A6%E2%80%9C%E6%A8%B1%E8%8A%B1%E8%AE%A1%E5%88%92%E2%80%9D%E7%AC%AC%E5%85%AD%E5%A4%A9%E2%80%94%E2%80%94lecture2/"},{"title":"日本上智大学“樱花计划”第五天——lecture1","text":"首页摘要： 从八月20号开始听来自瑞典、东京大学等大学的教授的讲座，今天的内容主要包括基于机器学习的模型辨识以及最优控制问题，在各位教授的详细介绍下，学到的东西使我获益匪浅。 EM算法优化问题逻辑约束条件的处理一直没明白涉及到判断语句约束条件在优化问题中的处理办法，本小节简单介绍处理过程的思路：增加0-1变量，同时增加约束条件进行等价转换，这是无法避免的代价。 如遇到约束条件$if \\quad \\delta =1 \\quad then \\quad f(x)\\geq 0$ 那么我们可以转化为$\\left\\{\\begin{matrix} f(x)\\leq M(1-\\delta )\\\\ f(x)\\geq \\epsilon +(m-\\epsilon)\\delta \\end{matrix}\\right.$ 其中$M=max f(x)$ ，$m=min f(x)$ ，$\\delta$ 为0-1变量。 再举例，$z(t)=\\delta (t)x(t)$ 可以转化为$\\left\\{\\begin{matrix} z(t)\\leq M_{2}\\delta (t)\\\\ z(t)\\geq m_{2}\\delta (t)\\\\ z(t)\\leq x(t)-m_{2}(1-\\delta (t))\\delta (t)\\\\ z(t)\\geq x(t)-M_{2}(1-\\delta (t))\\delta (t)\\end{matrix}\\right.$ 下面用一个实际模型说明： 特别的晚会","link":"/2018/08/20/%E6%97%A5%E6%9C%AC%E4%B8%8A%E6%99%BA%E5%A4%A7%E5%AD%A6%E2%80%9C%E6%A8%B1%E8%8A%B1%E8%AE%A1%E5%88%92%E2%80%9D%E7%AC%AC%E4%BA%94%E5%A4%A9%E2%80%94%E2%80%94lecture1/"},{"title":"日本上智大学“樱花计划”第四天——参观日本未来科学馆","text":"首页摘要： 今天主要是参观日本未来科学馆，略显无聊。另外一个地方就是东京大学了，如果去了东京而没有去东大，那未免太遗憾了。值得一提的是，日本的无人驾驶地铁台场段的风景真心不错，这次我就不说话，用图说话。 日本未来科学馆图片的位置基本上就是这一天的路线图了，让我带各位导游一波。 从上智大学出发路过的一座天桥，下面就是地铁道 日本未来科学馆的绿色地球展览点 台场“变形金刚” 未来科学馆日本女性和服照 台场海鸥线，霸气，站在前排的我对前方一览无余 台场海鸥线 台场海鸥线 台场海鸥线 台场海鸥线某个拐弯处 台场海鸥线 台场海鸥线不得不说，这条线路是我在日本坐过的地铁线路中最漂亮的，海岸线的风景一览无余，此行无憾！ 东京大学今天的主角是东京大学，作为日本最好的大学（京都大学也很厉害，但是比东大要差一丢丢），就像中国的清华北大，从感情上来讲我更喜欢清华。不过清华和东大两者很像，内部建筑都是红砖搭建，其中绿荫随处可见，不论求学或是游玩都是一处绝佳的地方。 东京大学医学部门口，怎么我瞅着比正门还霸气 时间紧迫，象征性地参观了东大的电气工程学院，门牌不仔细看都找不到，日本人果然很低调谦逊 东大一处路口 东大一处比较壮观的建筑 东大正门，低调低调，日本大学特色有生之年如果能够在东大求学一段时间，何其幸也！东大、清华都是令我神往的地方，以后梦里见~~~","link":"/2018/08/19/%E6%97%A5%E6%9C%AC%E4%B8%8A%E6%99%BA%E5%A4%A7%E5%AD%A6%E2%80%9C%E6%A8%B1%E8%8A%B1%E8%AE%A1%E5%88%92%E2%80%9D%E7%AC%AC%E5%9B%9B%E5%A4%A9%E2%80%94%E2%80%94%E5%8F%82%E8%A7%82%E6%97%A5%E6%9C%AC%E6%9C%AA%E6%9D%A5%E7%A7%91%E5%AD%A6%E9%A6%86/"},{"title":"智能电网与人工智能","text":"首页摘要： 人工智能目前进展如火如荼，而智能电网也处于建设时期，如何找到两者的结合点是一个众多学者关注的问题。为了探讨这个问题，参考鞠平教授的论文，对人工智能和智能电网的概念、发展、需求分别作了阐述，对未来两者可能取得突破的地方作了展望（以下人工智能简称AI，智能电网简称SG）。 人工智能概念及发展情况人工智能（Artificial Intelligence）的缩写是AI，它是模拟、拓展人的智能的一种理论、方法及系统。从学科分类上来说，它属于计算机科学与技术，目的是了解智能的实质，试图生产出能以类似人类智能反应方式的一种系统。 诞生 1950年，”人工智能之父”马文·明斯基和他的大四同学邓恩·埃德蒙 一起建造了世界第一台神经网络计算机；同年“计算机之父”的阿兰·图灵提出了人工智能的原始概念：如果在人不知道对方是机器的情况下与其对话而无法发现对方是机器，那么这台机器就具有智能。这个测试的方法也被称之为图灵测试。1956年，计算机专家约翰·麦卡锡在达特茅斯学院举办的一次会议上正式提出了“人工智能 ”一词，就在这次会议后不久，麦卡锡从达特茅斯搬到了MIT。同年，明斯基也搬到了这里，之后两人共同创建了世界上第一座人工智能实验室——MIT AI LAB实验室。 第一次高潮（1956-1974） 1956年之后，人工智能开始了第一次热潮，其取得的成功主要集中利用计算机在数学定理及代数证明上面。A. Newell和H. Simon研发的“逻辑理论家（Logic Theorist）”证明了《数学原理》中全部52条定理，其中某些证明比原著更加巧妙。人们几乎无法相信机器原来可以如此智能。这些成果让研究者对未来充满信心，认为完全智能的机器人二十年内就能出现。这些成就在现在看来自然是小儿科，但在当时确实巨大的突破，毕竟做到了基于机器的数学证明。正因为如此，很多研究机构投入巨额资金进行人工智能的研究。 第一次低谷（1974-1980） 从70年代开始，人工智能迎来了寒冬期。因为它停留于证明简单数学定理等比较容易的问题，而又限制于计算能力，因此存在它能够解决的问题对象不多，一旦维度上升就会克服；另外一个原因是缺乏大量的数据用于研究，无法有效对人工智能进行分析。基于上述原因，政府所投资的项目大部分失败并终止，人工智能的热度慢慢降了下来。 第二次高潮（1980-1987） 最先让人工智能再度火起来的是卡耐基梅隆大学为DEC公司设计的一个名为XCON的专家系统，每年为公司节省四千万美元，取得巨大成功。许多公司纷纷效仿，开始研发和应用专家系统。专家系统依赖的知识工程因而也成为AI研究的焦点。于是，日本推出第五代计算机计划，其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。其他国家也纷纷作出响应。与此同时，John Hopfield发明Hopfield网络，解决了著名的旅行商（TSP）问题。David Rumelhart提出反向传播（Back Propagation，BP）算法，解决了多层神经网络的学习问题。神经网络被广泛的应用于模式识别、故障诊断、预测和智能控制等多个领域。AI迎来了又一轮高潮。 第二次低谷（1987-1993） 但是，人们很快发现专家系统所依赖的知识非常难以获取，因此其应用的范围很窄；同时，关于AI的一些项目也遇到了财政困难；此外，苹果和 IBM 生产的台式机性能都超过了 Symbolics 等厂商生产的通用型计算机，专家系统自然风光不再。 第三次高潮（1993-至今） 随着计算机性能的不断提升、海量数据的收集以及人工智能研究者的不断努力，AI迎来了第三次高潮。具有里程碑意义的事件包括：1997年，IBM的国际象棋机器人深蓝战胜国际象棋世界冠军卡斯帕罗夫 ；2006年，Geoffrey Hinton提出深度学习。在接下来的若干年，借助深度学习技术，包括语音识别、计算机视觉在内的诸多领域都取得了突破性的进展 ；2016年，Google的围棋人工智能系统AlphaGo与围棋世界冠军、职业九段选手李世石进行人机大战，并以4:1的总比分获胜 。 人工智能为什么会取得这些成功？相比传统的浅层学习算法，如支持向量机、多层感知机等均没有足够的能力处理海量数据，因为模型的简化造成对复杂问题的表达能力不足；当然，它们在少样本学习上有着非常优秀的泛化能力。而深度学习是一种多层非线性的网络结构，理论上可以逼近任意函数，换句话说，在一定程度上深度学习的结构越复杂其参数越多那么其表达能力越强，但这不是绝对的，因为数据即便再多其蕴含的信息也可能是一定的，这就意味着优化的参数也是有限的，所以我们需要根据实际情况搭建网络。 在另一方面，深度学习不但在性能上超越了传统浅层学习算法，其还具有自动提取特征的作用，这个功能相比传统算法手工设计特征来说是个巨大的进步。它将特征和分类器结合到一个框架中，具体而言是利用了无监督的学习方式将无标注的数据特征提取，这就是所谓的预训练（每次单独训练一层，将训练结果输入更高一层，最后对整个网络微调的方式）。 目前人工智能的代表是深度学习，但深度学习也不是万能的，其最成功的的领域是图像处理，在很多领域依然由传统机器学习算法主导。其不足具体体现为：（1）需要先验知识和其他模型结合才能取得state of art的效果；（2）深度学习模型为黑箱模型，可解释性不强，可以说是牺牲的解释性来提高准确性；（3）训练困难，包括训练速度和调节参数。 智能电网概念及发展情况智能电网是通过传感器把各种设备、 资产连接到一起，形成一个客户服务总线，从而对信息进行整合分析，以此来降低成本，提高效率， 提高整个电网的可靠性，使运行和管理达到最优化的一种高度信息化的电力系统。其特点可以描述为：数字化、信息化、自动化、互动化，主要体现在灵活性、可观性和可控性、互操作性3各方面。要实现这些功能需要依靠先进的传感器技术、网络通讯技术以及自动化技术。 灵活性：灵活性是指在电力系统发电功率或者负荷出现较大的快速波动而造成的功率不平衡能够通过调整功率或者负荷保持稳定运行的能力。在智能电网中，高渗透率新能源的接入造成了系统功率的不平衡性，降低了灵活性；而大规模电动汽车的接入作为可控负荷又提高了灵活性，需要很好地利用两者的能力； 可观性和可控性：可观性是指能够完整地获得电网中的信息，例如目前广泛安装的PMU可以对电网中的状态进行检测；而可控性是指具备有效的手段对电网进行控制，例如大规模装备的FACT元件可以帮助智能电网完成这个工作； 互操作性：互操作性是指保证多个网络、系统、设备、应用或元件之间相互通信以及在不需要过多人工介入即可有效、安全、协调运行的能力。例如发生故障，能够正确启动继电保护装置就是一种互操作性。 智能电网的发展简介 美国：从2000年开始提出intelligent grid的概念，2003年美国能源部发布了“Grid 2030”计划并启动了相应的研究工作，美国主要关注信息化基础架构技术的发展升级以实现最大化对信息的利用，目前实施项目有美国能源部和电网智能化联盟主导的 GridWise 项目和 EPRI 发起的 Intelligrid 项目 ； 欧盟：欧洲则重点关注可再生能源和分布式能源的发展，并带动整个行业发展模式的转变。2005年智能电网欧洲技术论坛成立。 欧盟第 5 次框架计划 (FP5) (1998—2002)中的“欧洲电网中的可再生能源 和分布式发电整合”专题下包含了50多个项目， 分为分布式发电、输电、储能、高温超导体和其他 整合项目5大类，其中多数项目于2001年开始实施并达到了预期目的，被认为是发展互动电网第一 代构成元件和新结构的起点； 中国：国内从2005年开始智能电网建设。近年来，我国在智能电网的建设上取得了长足的发展。 所投资的数百项智能电网项目涵盖了发电、输电、配电、用电和调度5大领域以及信息平台建设。归纳起来可以总结为：1）一批智能输配电技术得到应用#提升了电网的可控性和灵活性从而提升了电网输送能力和安全稳定水平；2）智能调度支持系统D5000应用，提升了电力系统安全运行水平；3）智能变电站和配电自动化的加速应用，增强了电网的互操作性；4）开展了电网大数据平台的建设及应用探索$在国家电网范围内建设并推广了调度系统D5000、WAMS、大规模的用电信息采集AMI系统等数据采集系统，积累了海量的电网大数据。 目前我国在硬件设施如输配电设备、D5000等调度平台建设得较为完善，但是在电网数据分析上依然远远不够，例如现代电网每隔15分钟保存一次安全稳定数据，一天的数据就可达到以T计算，因此电网数据库中所存储的数据是海量的，尚未得到有效利用，而人工智能的发展为分析这些数据提供了有效的手段。 AI和SG的结合发展展望当前随着高渗透率新能源的接入、电力电子化电力系统的发展以及多种能源融合的背景下，结合人工智能保证电网的安全稳定运行尤为重要。总结《“智能电网+”研究综述》，未来发展趋势总结如下： 对象 发展要点 电力大数据 EMS/DMS、WAMS、故障录波、智能电表等基础数据结合气象信息以及设备振动信息等进行分析，建立大数据分析平台，实现大数据管理一体化 发电侧 主要针对不确定性实现可再生能源的电源功率预测，随机场景生成等，其次是同步发电机、风力发电机的故障诊断及预警 输电侧 暂态稳定、电压稳定、小干扰稳定等安全稳定问题的模式识别，紧急控制措施的学习、故障定位、故障诊断等经典问题 配电侧 分布式电源接入以及敏感型负荷接入造成的短期负荷预测、非法用电分析、负荷建模等问题 虽然人工智能技术目前如火如荼，但是它并不是万能的，在我看来最根本的还是传统方法对电力系统物理本质的分析，只有对其本质足够了解才能有效结合人工智能技术解决问题。例如我目前所研究的暂态稳定评估领域，过去大家所做的无非是怎样选取特征、如何换算法、如何确定评估目标，除了在快速性上较传统方法具备一定优势外，在传统问题诸如稳定裕度、关键影响因素都没有很好地解决，甚至是连自身如何构造数据集都无法很好解释，根本上还是传统方法未能取得突破，所以我现在很期待看到众多学者是如何解决这个问题的。《“智能电网+”研究综述》曾提到小样本学习这个问题，我觉得如果能够从物理本质出发再结合小样本学习或许是一种思路，反正在研三年我是无法解决了=o=。 参考 [1]http://mini.eastday.com/mobile/161203062329556.html [2]http://www.360doc.com/content/17/1207/13/1609415_710797958.shtml [3]“智能电网+”研究综述","link":"/2018/05/16/%E6%99%BA%E8%83%BD%E7%94%B5%E7%BD%91%E4%B8%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"title":"李普亚诺夫指数概念及其在电网中的应用","text":"首页摘要： 待补充。","link":"/2019/04/18/%E6%9D%8E%E6%99%AE%E4%BA%9A%E8%AF%BA%E5%A4%AB%E6%8C%87%E6%95%B0%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%94%B5%E7%BD%91%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/"},{"title":"梦回珞珈山","text":"首页摘要： 很久没有更新博客了，就把回武大拍的照片发上来吧！ 正文刚好这段时间是樱花节，也想着顺道回去看望导师（不巧杨老师去参加乒乓球比赛了，sad~），那就和师兄弟们一块儿赏花好了，直接上图。 一进来就是樱花城堡，灰蒙蒙的天还真是不太配城堡的气质呢！ 在回武大之前就心心念念到樱顶拍楼顶的一角，虽然是阴天，还是很好看。 樱顶一枝花的特写，可惜花没有茂盛时那么饱满，还是来晚了。 吴教授樱花摄影教学专场，看阿姨仰慕的表情就知道了。 阴天樱花也黯淡了许多，夜樱是真的很美呢！。 樱花大道和百步梯的留念~ 在武大七年最常去的就是工学部图书馆，单独留张影，不知道什么时候能再回来=_= 。 时隔半年再回武大，还是以前一样熟悉，在我心底，它就是我的第二个家。","link":"/2021/03/23/%E6%A2%A6%E5%9B%9E%E7%8F%9E%E7%8F%88%E5%B1%B1/"},{"title":"浅谈文化","text":"首页摘要： 在岳麓山下，我开始思考文化的意义…… 正文来长沙半个月还没去岳麓山和橘子洲怕是不敢和别人说我到长沙玩过的，难得在科研上有点小的突破，总算积攒了爬山的心情，也正好可以避免国庆节恐怖的人流。不过结局并未如我所计划，在刚走到岳麓寺的时候，远在德国的国栋兄来了一通微信电话，这也成就了我的奇葩之行——爬山只花了一个多小时，在山下打电话却花了三个多小时。 虽然没能领略到长沙的独有风光，但和国栋兄的一席讨论却让我有了新的收获，旅行于我而言就是在不同的环境中去获得新的感悟，这么一想倒也没觉得遗憾。其实通话内容无非是一些学术问题的探讨、对于身边和世界发生事情的看法。但是其中我当时没有想清楚、现在也未必理解到皮毛的问题是关于文化的话题 在百度百科关于文化的定义是：文化是人类社会相对于经济、政治而言的精神活动及其产物，分为物质文化和非物质文化。在知乎上一条高赞的定义却是：文化本质上就是一群人对于决策机制的群体共识。百度百科中的定义对我来说过于抽象了，简直到了无法理解的地步。知乎这个定义显然更适合我去认识文化，在这个基础上，我个人对文化的定义是：一个群体的三观即可认为是文化。知乎的定义更接近三观中的价值观——即遇到问题的时候是如何决策的，也即认为怎么决策是合理正确的。 如果认为一个群体的三观是文化，那么世界观就是我们口头上经常说的“有文化”，这是对这个客观世界的认识，即知识，这个对于不同的群体在理论上应该是一样的（假设各个群体的科技水平一样）。我更关心的是三观中的人生观和价值观是如何在群体文化中表现的，这是在主观意识的方面。一个群体的人生观大体是一致的，比如让自己的国家民族越来越富足、强大，这个我觉得无需再讨论。关键在于价值观，也就是说实现人生观的决策机制，这个在国家之间区别非常明显。在2020年这次疫情中，从中国和欧美国家的表现对比来看，中国人更加偏好集体主义，笃信听国家指挥可以战胜疫情；而欧美国家的人民则更加倾向自由主义，主张自己的人身自由不能被侵犯，这使得在国家针对疫情的隔离措施无法有效实施。这其中的人生观可以看成是战胜疫情，不同国家的人民抗疫的做法却截然不同，我无心评判价值观之间的优劣，以上只为说明文化对于国家决策的影响。作为中国人，我自然更加熟悉中国文化，例如勤俭节约、爱国主义都是自古以来中国人受到的文化熏陶，我觉得这是用来理解文化很好的例子。 在这次疫情之后，我明显感觉周围朋友对于中西方在态度或者说认识上的一些转变。在以前很多人会觉得欧美是天堂，不论是在生活环境还是个人价值实现上都具有优越性。现在看来，西方国家存在其局限性，中国也不是我们以前所认为的那么不堪，特别是美国今年开始明目张胆打压中国的政策，让我觉得人性的本质大体是一致的，都是为利而行，这个世界哪有真正的天堂——只要生活富足，人人都有机会成为天使。或许2020年是中国人民对民族文化的自信心转折的一年，中华民族很多文化值得我们去传承，用一句话来说明文化的作用就是提高了民族凝聚力，越来越多的人开始认同我们自己民族的价值观，这是一件值得庆祝也值得铭记的事情。","link":"/2020/10/03/%E6%B5%85%E8%B0%88%E6%96%87%E5%8C%96/"},{"title":"深度强化学习之基于策略梯度的方法","text":"首页摘要： 基于值函数近似的方法，例如Deep Q-learning，存在无法处理连续动作的缺点。因此，策略梯度方法被提出来解决这个问题。本文主要从策略梯度的推导、策略梯度算法框架两个方面来进行介绍。 策略梯度的计算Deep learning方法主要存在如下几点不足： （1）无法处理连续动作。因为其样本目标$q$值的计算涉及到求取最大$q$值的动作，如果动作是连续的，则无法求取。 （2）无法处理随机策略问题，从而可能错过最优解。同样地，其样本目标$q$值的计算涉及到贪婪法$max$，无法应用$\\epsilon -greedy$随机策略。 因此我们试图对策略求取梯度，找到最优策略，同时这样也能处理连续状态和连续动作。大概做法是采用神经网络（我们称这个网络为actor网络，表示选择动作的策略网络），输入为状态$S$，输出为策略$\\pi$。假设该神经网络参数为$\\theta$，那么策略可以表示成$\\pi_{\\theta}$。很自然的是，我们希望策略$\\pi_{\\theta}$下得到的回报（reward）越大越好，因此目标为： maxmize\\ \\ \\ \\ \\bar{r}_{\\theta}=E_{\\tau\\sim \\pi_{\\theta}}[r(\\tau)]对于上式的解释，可以用下图来进行解释。在策略$\\pi_{\\theta}$下（注意因为这是随机策略）一个可能的包含动作和状态的序列$\\tau$中，所有时刻的奖励之和为：$r(\\tau)=r_{1}+r_{2}+…+r_{T}$，其中$T$为序列长度，假设$p_{\\theta}(a_{t}|s_{t})$为时刻t时在状态$s_{t}$采取动作$a_{t}$的概率，因此该序列的概率$\\tau$是$p_{\\theta}(\\pi_{\\tau})=p_{\\theta}(s_{1})\\prod_{t=1}^{T}p_{\\theta}(a_{i}|s_{i})p_{\\theta}(s_{i+1}|a_{i}s_{i})$。 那么，$\\bar{r}_{\\theta}$可以表示成： \\bar{r}_{\\theta}=\\sum_{\\tau \\sim \\pi_{\\theta}}[r(\\tau)p_{\\theta}(\\tau)]为了使其最大化，可以利用梯度上升的方法进行优化，取其梯度得到： \\nabla \\bar{r}_{\\theta}=\\sum_{\\tau \\sim \\pi_{\\theta}}[r(\\tau) \\nabla p_{\\theta}(\\tau)]根据公式$\\nabla f(x)=f(x)\\nabla log(f(x))$，上式可以转换为： \\nabla \\bar{r}_{\\theta}=\\sum_{\\tau \\sim \\pi_{\\theta}}[r(\\tau) p_{\\theta}(\\tau) \\nabla log \\ p_{\\theta}(\\tau)]上式等价于： \\nabla \\bar{r}_{\\theta}=E_{\\tau \\sim p_{\\theta}}[r(\\tau) \\nabla log \\ p_{\\theta}(\\tau)]在实际应用中，我们通过大量抽取$N$个样本来近似上式： \\nabla \\bar{r}_{\\theta}=\\frac{1}{N}\\sum_{n=1}^{N}r(\\tau^{n}) \\nabla log \\ p_{\\theta}(\\tau^{n})对状态动作序列$\\tau$中每一步奖励求和得到： \\nabla \\bar{r}_{\\theta}=\\frac{1}{N}\\sum_{n=1}^{N}\\sum_{t=1}^{T}r(\\tau^{n}) \\nabla log\\ p_{\\theta}(a_{t}^{n}|s_{t}^{n})在这个公式下我们知道，我们希望奖励越大的动作其概率的增加$\\nabla log\\ p_{\\theta}(a_{t}^{n}|s_{t}^{n})$越大，但是当奖励都为正的情况下，如果一直没有采样到奖励最大的动作，那么其他动作的概率都上升了之后，由于所有动作之和为1，那么奖励最大的动作必然下降。因此，我们考虑对奖励项$r(\\tau^{n})$减去一个基准（baseline），这个baseline取$r(\\tau^{n})$的期望$E[r(\\tau)]$，这样做的好处是使得奖励最小的动作概率会下降（因为算法总是希望$\\bar{r}_{\\theta}$大于0），也就是说，这样可以尽量避免采取奖励小的动作。那么，公式可以改写成： \\nabla \\bar{r}_{\\theta}=\\frac{1}{N}\\sum_{n=1}^{N}\\sum_{t=1}^{T}(r(\\tau^{n})-b) \\nabla log\\ p_{\\theta}(a_{t}^{n}|s_{t}^{n}),\\ b=E[r(\\tau)]进一步，对于每个样本而言，想象它是在线运行，当采取一个动作时，它的回报$r(\\tau^{n})$和前面时刻动作无关，而后续时刻的奖励则应该打个折扣，因此$r(\\tau^{n})$可以写成$G(\\tau^{n})=\\sum_{t^{\\prime}=t}^{T_{n}} \\gamma^{t^{\\prime}-t} r_{t^{\\prime}}^{n}$的形式，其实这个就是动作价值函数$Q^{\\pi_{\\theta}}\\left(s_{t}^{n}, a_{t}^{n}\\right)$，综上所述，回报的梯度可以表示成： \\begin{equation} \\begin{split} \\nabla \\bar{r}_{\\theta}&=\\frac{1}{N}\\sum_{n=1}^{N}\\sum_{t=1}^{T}(\\sum_{t^{\\prime}=t}^{T_{n}} \\gamma^{t^{\\prime}-t} r_{t^{\\prime}}-b) \\nabla log\\ p_{\\theta}(a_{t}^{n}|s_{t}^{n}),\\ b=E[\\gamma^{t^{\\prime}-t} r_{t^{\\prime}}^{n}]\\\\ &=\\frac{1}{N}\\sum_{n=1}^{N}\\sum_{t=1}^{T}(Q^{\\pi_{\\theta}}\\left(s_{t}^{n}, a_{t}^{n}\\right)-b) \\nabla log\\ p_{\\theta}(a_{t}^{n}|s_{t}^{n}),\\ b=E[Q^{\\pi }\\left(s_{t}, a_{t}\\right)] \\end{split} \\end{equation}策略函数的设计（1）考虑离散动作，可以将策略$p_{\\theta}(a|s)=\\pi_{\\theta}(s,a)$设计为： \\pi_{\\theta}(s, a)=\\frac{e^{\\phi(s, a)^{T} \\theta}}{\\sum_{b\\in A} e^{\\phi(s, b)^{T} \\theta}}其中，$\\phi(\\cdot )$是神经网络表征的函数。那么可以求其梯度： \\nabla_{\\theta} \\log \\pi_{\\theta}(s, a)=\\phi(s, a)-\\mathbb{E}_{\\tau \\sim \\pi_{\\theta}}[\\phi(s, .)]（2）考虑连续动作，可以将动作的概率分布视为高斯分布$\\mathbb{N}\\left(\\phi(\\mathrm{s})^{\\mathrm{T}} \\theta, \\sigma^{2}\\right)$那么策略概率的微分为： \\nabla_{\\theta} \\log \\pi_{\\theta}(s, a)=\\frac{\\left(a-\\phi(s)^{T} \\theta\\right) \\phi(s)}{\\sigma^{2}}蒙特卡洛方法下的策略梯度算法本节为了理解策略梯度，利用最简单的蒙特卡洛方法来说明策略梯度算法是如何应用的。在这里，我们采用价值函数$V(s_{t}^{n})$来代替策略梯度公式中的动作价值函数$Q^{\\pi_{\\theta}}\\left(s_{t}^{n}, a_{t}^{n}\\right)$，详细流程如下： 输入：N个蒙特卡罗完整序列,训练步长$\\alpha$ 输出：策略函数的参数$\\theta$ （1）用蒙特卡罗法计算每个序列每个时间位置$t$的状态价值$V(s_{t}^{n})$ （2）对每个序列每个时间位置$t$ ，使用梯度上升法，更新策略函数的参数$\\theta$： \\begin{equation} \\begin{split} \\theta&=\\theta+\\alpha\\\\ &=\\frac{1}{N}\\sum_{n=1}^{N}\\sum_{t=1}^{T}(V(s_{t}^{n})-b) \\nabla log\\ p_{\\theta}(a_{t}^{n}|s_{t}^{n}),\\ b=E[V(s_{t}^{n})] \\end{split} \\end{equation}（3）返回策略函数的参数θ 结语至此，我们介绍完了策略梯度方法。从它的算法流程可以看出，除了可以对连续状态、连续动作操作之外，完美地继承了蒙特卡洛方法的缺点——需要等序列采样结束才能进行计算。因此下一篇文章着重介绍如何融合基于值函数近似和策略梯度的方法来解决这个问题。","link":"/2020/02/11/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E4%BA%8E%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%E7%9A%84%E6%96%B9%E6%B3%95/"},{"title":"深度强化学习之基于值函数近似的方法","text":"首页摘要： 2019年3月学习完强化学习基础之后，迟迟未能进一步了解深度强化学习方面的内容。虽然2020年开局就是如此严重的疫情，但对我而言，它也给了自我学习的时间。深度强化学习系列文章会从基于值函数近似的方法、基于策略梯度的方法、两者相结合的方法三个方面来进行介绍。本文介绍基于值函数近似的方法，包括Deep Q-learning及其各种改进体。 Deep Q-learning从名字就可以看出来，Deep Q-learning是将深度学习应用在Q-learning中的方法。我们知道，Q-learning的值函数是通过将”动作-价值“对以表格的形式进行存储，因此其状态和值函数是离散的。这个特点造成了Q-learning使用的局限性——我们大多数场景的状态都是连续的，要应用Q-learning就必须进行离散化，而这很容易造成维数灾问题。为了解决这个问题，Deep Q-learning对Q-learning中的值函数用神经网络（也可以是其他机器学习方法，如决策树）进行近似表示，即输入为状态$S_{t}$、输出为”状态-动作“价值函数$q(S_{t},A_{t})$，其它步骤不变。这样，Deep Q-learning就可以对连续状态输出价值。 假设神经网络（后面也称Q网络）的参数为$w$，那么”状态-动作“价值函数$q(S_{t},A_{t})$可以表示成： Q(S_{t},A_{t},w)但是神经网络最大的问题是需要大量的数据来进行训练，为了解决这个问题，Deep Q-learning在部署之前必须与环境进行交互来产生大量训练数据，即五元组$\\{\\phi(s),a,r,\\phi(s’),{isend_{j}} \\}$ 集合$D$，其中$s’$是状态$s$下采取动作$a$ 后转到的下一状态，$\\phi(\\cdot)$是特征抽取或者特征选择函数，Deep Q-learning选择在与环境交互过程中同时对神经网络进行训练，因此使用了经验回放方式，即设置集合$D$的元素个数上限，如果与环境交互过程中$D$的元素还没充满，就添加新产生的五元组$\\{\\phi(s),a,r,\\phi(s’),{isend_{j}} \\}$ 进去，如果$D$的元素已经充满，新产生的五元组$\\{\\phi(s),a,r,\\phi(s’),{isend_{j}} \\}$ 就替换最老的五元组（类似队列弹出）。 下面给出Deep Q-learning的具体算法流程： 输入:迭代轮数 $T$、状态特征维度$n$、即时回报 $r$ 、衰减因子 $\\gamma$ 、探索率 $\\epsilon$ 、Q网络结构、批量梯度下降的样本数$m$； 输出:Q网络参数； 1.随机初始化Q网络的所有参数$w$，基于$w$初始化所有的状态和动作对应的价值$q$，清空经验回放的集合$D$； 2.for $i$ to $T$ ，进行迭代 （1）初始化$s$为当前状态序列的第一个状态, 拿到其特征向量$\\phi(s)$ （2）在Q网络中使用$\\phi(s)$作为输入，得到Q网络的所有动作对应的$q$值输出。用$\\epsilon-greedy $贪婪法在当前$q$值输出中选择对应的动作$a$ （3） 在状态$s$执行当前动作$a$,得到新状态$s’$对应的特征向量$\\phi(s’)$和奖励$r$,是否终止状态$is_end$ （4）将五元组$\\{\\phi(s),a,r,\\phi(s’),isend \\}$ 放入经验回放集合$D$ （5）$s=s’$ （6）从经验回放集合$D$中采样$m$个样本$\\{ \\phi(s_{j}),a_{j},r_{j},\\phi(s’_{j}),isend_{j}\\},j=1,2,…,m$ ，计算这些样本的目标$q_{j}$值： q_{j}=\\left\\{\\begin{array}{ll} {r_{j}} & {isend_{j} \\text { is true }} \\\\ {r_{j}+\\gamma \\max _{a_{j}^{\\prime}} Q\\left(\\phi\\left(s_{j}^{\\prime}\\right), a_{j}^{\\prime}, w\\right)} & {isend_{j} \\text { is false }} \\end{array}\\right.（7）使用均方差公式$\\frac{1}{m} \\sum_{j=1}^{m}\\left(q_{j}-Q\\left(\\phi\\left(s_{j}\\right), a_{j}, w\\right)\\right)^{2}$作为损失函数来更新Q网络的参数$w$ （8）如果 $s$ 是终止状态，当前轮迭代完毕，否则转到步骤(2) 这里有一个要注意的是， $\\epsilon$ 一般需要随着迭代的进行逐渐变小，这样才能保证Q网络可以收敛。然而，即使这样，Deep Q-learning的主要问题仍然是收敛问题，其主要解决办法包括Nature DQN、Double DQN (DDQN)、Prioritized Replay DQN、Dueling DQN。下面几节通过一步步改进来分别介绍。 Nature DQN原始的Deep Q-learning经验回放中样本的目标$q_{j}$值计算公式为： q_{j}=\\left\\{\\begin{array}{ll}{r_{j}} & {isend_{j} \\text { is true }} \\\\{r_{j}+\\gamma \\max _{a^{\\prime}} Q\\left(\\phi\\left(s_{j}^{\\prime}\\right), a_{j}^{\\prime}, w\\right)} & {isend_{j} \\text { is false }}\\end{array}\\right.可以看出，用来更新Q网络参数的目标$q_{j}$值是通过Q网络自身来进行计算的，这样造成的相关性会使得算法整体收敛性变慢。为了解决这个问题，Nature DQN增加了一个新的目标Q‘网络来计算目标$q_{j}$值，而这个网络参数$w’$和Q网络在若干时刻之前的参数一模一样，每隔一段时间，就将Q网络的参数覆盖Q’网络的参数。其它计算步骤和Deep Q-learning一致，具体算法流程如下： 输入:迭代轮数 $T$、状态特征维度$n$、即时回报 $r$ 、衰减因子 $\\gamma$ 、探索率 $\\epsilon$ 、Q网络结构、目标Q’网络结构（其实和Q网络一样，之所以叫这个名字是因为用来计算目标$q$值）、批量梯度下降的样本数$m$、更新目标Q’网络的频率$C$； 输出:Q网络参数； 1.随机初始化Q网络的所有参数$w$，目标Q’网络参数$w’=w$，基于$w$初始化所有的状态和动作对应的价值$q$，清空经验回放的集合$D$； 2.for $i$ to $T$ ，进行迭代 （1）初始化$s$为当前状态序列的第一个状态, 拿到其特征向量$\\phi(s)$ （2）在Q网络中使用$\\phi(s)$作为输入，得到Q网络的所有动作对应的$q$值输出。用$\\epsilon-greedy $贪婪法在当前$q$值输出中选择对应的动作$a$ （3） 在状态$s$执行当前动作$a$,得到新状态$s’$对应的特征向量$\\phi(s’)$和奖励$r$,是否终止状态$is_end$ （4）将五元组$\\{\\phi(s),a,r,\\phi(s’),isend \\}$ 放入经验回放集合$D$ （5）$s=s’$ （6）从经验回放集合$D$中采样$m$个样本$\\{ \\phi(s_{j}),a_{j},r_{j},\\phi(s’_{j}),isend_{j}\\},j=1,2,…,m$ ，计算这些样本的目标$q_{j}$值： q_{j}=\\left\\{\\begin{array}{ll}{r_{j}} & {isend_{j} \\text { is true }} \\\\{r_{j}+\\gamma \\max _{a_{j}^{\\prime}} Q'\\left(\\phi\\left(s_{j}^{\\prime}\\right), a_{j}^{\\prime}, w'\\right)} & {isend_{j} \\text { is false }}\\end{array}\\right.（7）使用均方差公式$\\frac{1}{m} \\sum_{j=1}^{m}\\left(q_{j}-Q\\left(\\phi\\left(s_{j}\\right), a_{j}, w\\right)\\right)^{2}$作为损失函数来更新Q网络的参数$w$ （8）如果$T\\%C==1$，$w’=w$ （9）如果 $s$ 是终止状态，当前轮迭代完毕，否则转到步骤(2) Double DQN (DDQN)和Nature DQN相同的是，DDQN也创造了一个目标Q’网络。但是DDQN认为Nature DQN存在过度估计的问题，具体体现在计算目标$q$值中： q_{j}=\\left\\{\\begin{array}{ll}{r_{j}} & {isend_{j} \\text { is true }} \\\\{r_{j}+\\gamma \\max _{a_{j}^{\\prime}} Q'\\left(\\phi\\left(s_{j}^{\\prime}\\right), a_{j}^{\\prime}, w'\\right)} & {isend_{j} \\text { is false }}\\end{array}\\right.为什么说它存在过度估计呢？从上面的公式可以看出，计算每个样本的目标$q$值时采用了贪婪法 ，即选取动作价值最大的动作。这样做的缺点是，它总是倾向选择过度估计的动作，这里理解起来可能会有一些绕口，用一张图来说明： 从上图可以看到，蓝色表示四个工作的真实$q$值，橙色部分为高估的值（算法不可能绝对准确得到某动作的$q$，因此存在高估或者低估的部分）。如果是Nature DQN算法，它会选择动作$a_{1}$，因为它的真实$q$值加上估计值最大，然而动作$a_{3}$的真实$q$值才是最大的。这样的后果是会使得最后选到动作$a_{3}$需要更多的算法迭代，因此不利于算法收敛。 DDQN的做法是使用通过贪婪法选择使得Q网络的$q$值最大的动作来作为Q’网络计算目标$q$值的动作，如下式所示： q_{j}=r_{j}+\\gamma \\max _{a_{j}^{\\prime}} Q'\\left(\\phi\\left(s_{j}^{\\prime}\\right), \\arg \\max _{a_{j}^{\\prime}} Q\\left(\\phi\\left(s_{j}^{\\prime}\\right), a_{j}, w\\right), w'\\right),isend_{j} \\text { is false }DDQN其它步骤和Nature DQN一致，具体算法流程如下： 输入:迭代轮数 $T$、状态特征维度$n$、即时回报 $r$ 、衰减因子 $\\gamma$ 、探索率 $\\epsilon$ 、Q网络结构、目标Q’网络结构（其实和Q网络一样，之所以叫这个名字是因为用来计算目标$q$值）、批量梯度下降的样本数$m$、更新目标Q’网络的频率$C$； 输出:Q网络参数； 1.随机初始化Q网络的所有参数$w$，目标Q’网络参数$w’=w$，基于$w$初始化所有的状态和动作对应的价值$q$，清空经验回放的集合$D$； 2.for $i$ to $T$ ，进行迭代 （1）初始化$s$为当前状态序列的第一个状态, 拿到其特征向量$\\phi(s)$ （2）在Q网络中使用$\\phi(s)$作为输入，得到Q网络的所有动作对应的$q$值输出。用$\\epsilon-greedy $贪婪法在当前$q$值输出中选择对应的动作$a$ （3） 在状态$s$执行当前动作$a$,得到新状态$s’$对应的特征向量$\\phi(s’)$和奖励$r$,是否终止状态$is_end$ （4）将五元组$\\{\\phi(s),a,r,\\phi(s’),isend \\}$ 放入经验回放集合$D$ （5）$s=s’$ （6）从经验回放集合$D$中采样$m$个样本$\\{ \\phi(s_{j}),a_{j},r_{j},\\phi(s’_{j}),isend_{j}\\},j=1,2,…,m$ ，计算这些样本的目标$q_{j}$值： q_{j}=\\left\\{\\begin{array}{ll}{r_{j}} & {isend_{j} \\text { is true }} \\\\{r_{j}+\\gamma Q'\\left(\\phi\\left(s_{j}^{\\prime}\\right), \\arg \\max _{a_{j}} Q\\left(\\phi\\left(s_{j}^{\\prime}\\right), a_{j}, w\\right), w'\\right)} & {isend_{j} \\text { is false }}\\end{array}\\right.（7）使用均方差公式$\\frac{1}{m} \\sum_{j=1}^{m}\\left(q_{j}-Q\\left(\\phi\\left(s_{j}\\right), a_{j}, w\\right)\\right)^{2}$作为损失函数来更新Q网络的参数$w$ （8）如果$T\\%C==1$，$w’=w$ （9）如果 $s$ 是终止状态，当前轮迭代完毕，否则转到步骤(2) Prioritized Replay DQNDDQN中经验回放采样是采取随机的方式，通过改进采样方式也能加快算法收敛。怎么做呢？从Q网络损失函数我们知道，如果目标Q’网络计算的目标$q_{j}$值和Q网络计算的Q值的差越大，那么Q网络反向更新的梯度越大，收敛速度越快，这个也被称之为TD误差，因此Prioritized Replay DQN就利用对TD误差绝对值大的样本赋予优先级（表现形式是权重），这样它被采样的概率就大，优先级的赋予方式采取的是SumTree（不知道这个可以查资料了解）。同时损失函数也改进为： \\frac{1}{m} \\sum_{j=1}^{m} w_{j}\\left(q_{j}-Q\\left(\\phi\\left(S_{j}\\right), a_{j}, w\\right)\\right)^{2}$w_{j}$就是优先级权重。Prioritized Replay DQN的其它步骤和DDQN一致，具体算法如下： 输入:迭代轮数 $T$、状态特征维度$n$、即时回报 $r$ 、衰减因子 $\\gamma$ 、探索率 $\\epsilon$ 、Q网络结构、目标Q’网络结构（其实和Q网络一样，之所以叫这个名字是因为用来计算目标$q$值）、批量梯度下降的样本数$m$、更新目标Q’网络的频率$C$、SumTree的叶子节点数$N$； 输出:Q网络参数； 1.随机初始化Q网络的所有参数$w$，目标Q’网络参数$w’=w$，基于$w$初始化所有的状态和动作对应的价值$q$，清空经验回放的集合$D$，初始化经验回放SumTree的默认数据结构，所有SumTree的$N$个叶子节点的优先级$p_{j}$为1； 2.for $i$ to $T$ ，进行迭代 （1）初始化$s$为当前状态序列的第一个状态, 拿到其特征向量$\\phi(s)$ （2）在Q网络中使用$\\phi(s)$作为输入，得到Q网络的所有动作对应的$q$值输出。用$\\epsilon-greedy $贪婪法在当前$q$值输出中选择对应的动作$a$ （3） 在状态$s$执行当前动作$a$,得到新状态$s’$对应的特征向量$\\phi(s’)$和奖励$r$,是否终止状态$is_end$ （4）将五元组$\\{\\phi(s),a,r,\\phi(s’),isend \\}$ 放入经验回放集合$D$ （5）$s=s’$ （6）从SumTree中采样$m$个样本$\\{ \\phi(s_{j}),a_{j},r_{j},\\phi(s’_{j}),isend_{j}\\},j=1,2,…,m$ ，每个样本被采样的概率基于是$P(j)=\\frac{p_{j}}{\\sum_{i}\\left(p_{i}\\right)}$，损失函数权重是$w_{j}=(N * P(j))^{-\\beta} / \\max _{i}\\left(w_{i}\\right)$，计算这些样本的目标$q_{j}$值： q_{j}=\\left\\{\\begin{array}{ll}{r_{j}} & {isend_{j} \\text { is true }} \\\\{r_{j}+\\gamma Q'\\left(\\phi\\left(s_{j}^{\\prime}\\right), \\arg \\max _{a_{j}} Q\\left(\\phi\\left(s_{j}^{\\prime}\\right), a_{j}, w\\right), w'\\right)} & {isend_{j} \\text { is false }}\\end{array}\\right.（7）使用均方差公式$\\frac{1}{m} \\sum_{j=1}^{m} w_{j}\\left(q_{j}-Q\\left(\\phi\\left(S_{j}\\right), a_{j}, w\\right)\\right)^{2}$作为损失函数来更新Q网络的参数$w$ （8）如果$T\\%C==1$，$w’=w$ （9）如果 $s$ 是终止状态，当前轮迭代完毕，否则转到步骤(2) Dueling DQNDueling DQN在Prioritized Replay DQN的基础上改进了Q的网络，将其输出变成了价值$V(s)$和优势函数$H(s,a)$（reward减去其期望值，表明某个动作的优势），具体变化如图所示： 这样可以加快算法收敛速度，至于为什么，我也还没理解……其它步骤和Prioritized Replay DQN是一样的，区别在于Q网络的不同，具体算法如下： 输入:迭代轮数 $T$、状态特征维度$n$、即时回报 $r$ 、衰减因子 $\\gamma$ 、探索率 $\\epsilon$ 、Q网络结构、目标Q’网络结构（其实和Q网络一样，之所以叫这个名字是因为用来计算目标$q$值）、批量梯度下降的样本数$m$、更新目标Q’网络的频率$C$、SumTree的叶子节点数$N$； 输出:Q网络参数； 1.随机初始化Q网络的所有参数$w$，目标Q’网络参数$w’=w$，基于$w$初始化所有的状态和动作对应的价值$q$，清空经验回放的集合$D$，初始化经验回放SumTree的默认数据结构，所有SumTree的$N$个叶子节点的优先级$p_{j}$为1； 2.for $i$ to $T$ ，进行迭代 （1）初始化$s$为当前状态序列的第一个状态, 拿到其特征向量$\\phi(s)$ （2）在Q网络中使用$\\phi(s)$作为输入，得到Q网络的所有动作对应的$q$值输出。用$\\epsilon-greedy $贪婪法在当前$q$值输出中选择对应的动作$a$ （3） 在状态$s$执行当前动作$a$,得到新状态$s’$对应的特征向量$\\phi(s’)$和奖励$r$,是否终止状态$is_end$ （4）将五元组$\\{\\phi(s),a,r,\\phi(s’),isend \\}$ 放入经验回放集合$D$ （5）$s=s’$ （6）从SumTree中采样$m$个样本$\\{ \\phi(s_{j}),a_{j},r_{j},\\phi(s’_{j}),isend_{j}\\},j=1,2,…,m$ ，每个样本被采样的概率基于是$P(j)=\\frac{p_{j}}{\\sum_{i}\\left(p_{i}\\right)}$，损失函数权重是$w_{j}=(N * P(j))^{-\\beta} / \\max _{i}\\left(w_{i}\\right)$，计算这些样本的目标$q_{j}$值： q_{j}=\\left\\{\\begin{array}{ll}{r_{j}} & {isend_{j} \\text { is true }} \\\\{r_{j}+\\gamma Q'\\left(\\phi\\left(s_{j}^{\\prime}\\right), \\arg \\max _{a_{j}} Q\\left(\\phi\\left(s_{j}^{\\prime}\\right), a_{j}, w\\right), w'\\right)} & {isend_{j} \\text { is false }}\\end{array}\\right.（7）使用均方差公式$\\frac{1}{m} \\sum_{j=1}^{m} w_{j}\\left(q_{j}-Q\\left(\\phi\\left(S_{j}\\right), a_{j}, w\\right)\\right)^{2}$作为损失函数来更新Q网络的参数$w$ （8）如果$T\\%C==1$，$w’=w$ （9）如果 $s$ 是终止状态，当前轮迭代完毕，否则转到步骤(2) 结语至此，我们介绍完了Q-learning及其变体的过程。但是Deep Q-learning还存在无法处理连续动作的问题（当然也有相应的改进，但是效果并不如人意，因此就视若无吧），基于策略梯度的方法可以很好地解决这个问题，这个我们在下一篇文章中介绍。","link":"/2020/02/10/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E4%BA%8E%E5%80%BC%E5%87%BD%E6%95%B0%E8%BF%91%E4%BC%BC%E7%9A%84%E6%96%B9%E6%B3%95/"},{"title":"爱你就像爱生命","text":"首页摘要： 爱你就像爱生命，王小波也太会说情话了。 正文今年算来，李银河已经六十八岁了，她和王小波相识于她二十五岁那年，而那时王小波也刚好二十五岁。二十三年前，王小波没能在她臂弯里离去，或许成了李银河一生的遗憾，但是她不后悔的是接受了王小波像爱生命一样的爱。 其实生离死别，他俩都已经经历过了。在李银河和王小波相处的二十年里，他们去了无数地方、探讨了无数真理、更加尝试过那个年代所无法想象的非常人之举。王小波停留在了他精神的巅峰，他曾在一篇小说中说：人就像一本书，你要挑一本最好看的书来看。李银河是幸运的，她挑了王小波这本书来看，虽然到高潮就结束了，但李银河在她的回忆录中这样写道：虽然后面的篇章再也看不到了，但是我还会反反复复地看这二十年。 王小波这一辈子都想做自由和理性的人，他做到了。在青年时期，他下乡当过知青，这段时期的经历逐渐形成了他的价值观；恢复高考后，他又考入了中国人民大学，正是这段时间成就了他和李银河的结识与相恋，一切都源于那本王小波手写的《绿毛水怪》；在三十左右的时候，他开始专职写作，他只是觉得，生活太枯燥的话还不如死了好，而写作让他超越平淡乏味的现实生活。他一生都像个保持好奇心的孩子，这份童心他只给了李银河。 李银河和王小波生活过、探索过、更加爱过，他们都是自由的思想家，《爱你就像爱生命》这本书就是最好的诠释。有人说，既然这么相爱，李银河为什么还重新嫁做他人妇？我觉得李银河说得很好：为什么小波死了我就不能再喜欢别人了呢，哪怕小波活着，我也有可能喜欢别人的。在这个世界上，我们爱的是一类人，而不是一个人，但是失去独特的这个你之后，这份爱也不一样了。 在《爱你就像爱生命》这本书中，王小波的情话很动人，但真正打动我的是他和李银河那份纯粹而又深沉的爱。 王小波语录： 你不要觉得这话肉麻，真话不肉麻。 我们好像在池塘的水底，从一个月亮走到另一个月亮 如果说人再童年可以决定自己生命的前途，那么就是当孩子的时候最幸福，其实有一种我们不能左右的力量参加进来决定我们的命运，也就是说，我们被天真欺骗了。 总之，人们应当为自己的剩余精力建设美好的精神生活，这是物质所替代不了的。这样的文化不带一点点的肉感，只能用精神去感受，需要崇高的智慧，这一点我已经可以确定。 我真的不知怎么才能和你亲近起来，你好像一个可望不可即的目标，我捉磨不透，追也追不上，就坐下哭了起来。 总之，我认为人不应当忽视自己，生活就是自己啊。总要无愧于自己才好。比方说我要无愧于自己就要好好地爱你才对。 不过你也该知道，我也肯为别人牺牲，也接受一切人们的共同行动，也尽义务，只要是为大家好；却不肯为了 仪式去牺牲、共同行动、尽义务，顶多敷衍一下。 懒于思想劳动必然勤于体力劳动，懒于创造性的思想活动必然勤于死记硬背。 比方说中国孩子太多，生孩子极吃苦头，但是人们为什么非生不可呢？我猜是因为：一、大家都生；二、怕老了；三、现在不生以后生不了。 世界上没有比爱情更好的东西了，爱一回就够了，可以死了，什么也不需要了。 在大限到来之前，我们要把一切做好，包括爱。 我要用尽所有的生命之能画出一条自身存在的曲线。 告诉你，一想到你，我这张丑脸上就泛起微笑。 我起初怀疑，一对不美的人的恋爱能是美的吗？后来的事实证明，两颗相爱的心在一起可以是美的。 但愿我和你是一首唱不完的歌。 你要是愿意，我就永远爱你，你要不愿意，我就永远相思。 我把我整个的灵魂都给你，连同它的怪癖，耍小脾气，忽明忽暗，一千八百种毛病。他真讨厌，只有一点好，爱你。 不管我本人多么平庸，我总觉得对你的爱很美。 只希望你和我好，互不猜忌，也互不称誉，安如平日，你和我说话像对自己说话一样，我和你说话也像对自己说话一样。 你是非常可爱的人，真应该遇到最好的人，我也真希望我就是。 不一定要你爱我，但是我爱你，这是我的命运。 咱们应当在一起，否则就太伤天害理了。 我老把和你在一起的时间当成节日来度过，我看你也是。","link":"/2020/09/08/%E7%88%B1%E4%BD%A0%E5%B0%B1%E5%83%8F%E7%88%B1%E7%94%9F%E5%91%BD/"},{"title":"深度强化学习之基于融合值函数近似和策略梯度的方法","text":"首页摘要： 基于策略梯度的方法主要存在的问题是需要完整序列以及难以收敛的问题，能否引入基于值函数近似的方法来处理是我们所关心的因此Actor-Critic的方法被提出来解决这个问题，其中Actor是策略网络，而Critic是评论网络，也就是说Critic作用类似于Deep Q-learning中的Q网络，用来评估$q$值。本篇文章将简要介绍Actor-Critic方法的过程以及其改进形式——深度确定性策略梯度(DDPG)。 Actor-Critic因为求回报的梯度时是针对整个状态工作序列$\\tau$ 来计算的，所以策略梯度方法需要完整的序列，此外，收敛性也是策略梯度方法的一大问题。然而我们实际应用希望的是一边和环境交互一边更新自身参数，基于蒙特卡洛方法的策略梯度是无法完成这个目标的。所以Actor-Critic借鉴了Deep Q-learning的思想，Actor网络一边与环境交互用Critic网络一边对值函数逼近，不断迭代，逐渐达到较优的水平。 我们知道，策略梯度方法更新公式是： \\begin{equation}\\begin{split} \\theta&=\\theta+\\alpha\\\\&=\\frac{1}{N}\\sum_{n=1}^{N}\\sum_{t=1}^{T}(V(s_{t}^{n})-b) \\nabla log\\ p_{\\theta}(a_{t}^{n}|s_{t}^{n}),\\ b=E[V(s_{t}^{n})] \\end{split}\\end{equation}在Actor-Critic中，由于需要在线和环境交互，因此不涉及到策略的采样，Actor策略梯度方法更新公式改成： \\nabla \\bar{r}_{\\theta}=\\sum_{t=1}^{T}V(s_{t}) \\nabla log\\ p_{\\theta}(a_{t}|s_{t})当然$V(s_{t})$也可以换成动作价值、TD误差、优势函数、TD(λ)误差。而Critic网络则承担起估计$V(s_{t})$的任务，输入数状态向量，输出是$V(s_{t})$。将$V(s_{t})$换成TD误差的Actor-Critic算法流程如下： 输入：迭代轮数$T$，状态特征维度$n$, 动作集$A$, 步长$\\alpha、\\beta$，折扣因子$\\gamma$ , 探索率$\\epsilon$, Critic网络结构和Actor网络结构。 输出：Actor 网络参数$\\theta$，Critic网络参数$w$ 1.随机初始化所有的状态对应的价值$V$. 随机初始化Critic网络的所有参数$w$。随机初始化Actor网络的所有参数$\\theta$。 2.for i from 1 to T，进行迭代。 （1）初始化$s$为当前状态序列的第一个状态, 拿到其特征向量$\\phi(s)$ （2）在Actor网络中使用$\\phi(s)$作为输入，输出动作$a$，基于动作$a$得到新的状态$s’$,奖励$r$。 （3）在Critic网络中分别使用$\\phi(s)$、$\\phi(s’)$作为输入，得到价值输出$V(s)$、$V(s’)$ （4）计算TD误差$\\delta=r+\\gamma V\\left(s^{\\prime}\\right)-V(s)$ （5）使用均方差损失函数$\\sum\\left(r+\\gamma V\\left(s^{\\prime}\\right)-V(s)\\right)^{2}$作Critic网络参数$w$的梯度更新 （6）更新Actor网络参数$\\theta$: \\theta=\\theta+\\alpha \\nabla_{\\theta} \\log p_{\\theta}(a_{t}|s_{t})\\delta 从算法我们可以看出，Actor网络和Critic网络相互依赖，这样会使得收敛变慢，而下一节介绍的DDPG就是用来解决这个问题。 DDPG同DDQN解决网络耦合的思路一样，DDPG分别给Actor-Critic方法中的Actor网络安排了目标Actor网络、给Critic网络安排了目标Critic网络。同样的，目标Actor网络参数$\\theta’$是从Actor$\\theta$网络复制而来，目标Critic网络参数$w’$是从Critic网络$w$复制而来。具体而言，四种网络功能如下： （1）Actor网络：在状态$s$下选择最优动作$a$，得到奖励$r$环境转到状态$s’$; （2）目标Actor网络：根据经验回放池中采样的状态$s’$下选择动作$a’$; （3）Critic网络：计算当前时刻动作价值$Q(s,a,w)$; （4）目标Critic网络：根据经验回放池中采样的状态$s’$下计算下一时刻动作价值$Q(s’,a’,w’)$; 根据上述功能，可以将它们套入Actor-Critic框架中，但是Actor的损失函数以及更新方式有一些简化。为了避免高维动作空间造成的计算量，DDPG采用了确定性策略，这时候其策略梯度发生了一些改变。考虑到确定性策略下，算法希望动作价值越大越好，同时采用梯度下降法，结合经验回放的$m$个样本可以将策略损失函数写成： J(\\theta)=-\\frac{1}{m} \\sum_{j=1}^{m} Q(s_{i}, a_{i}, w)为了实现和$\\epsilon-greedy$贪婪策略类似的目标，DDPG对动作施加随机性噪声$\\mathcal{N}$： a=\\pi_{\\theta}(s)+\\mathcal{N}此外，和DDQN采取直接复制参数不一样的是，目标Actor网络和目标Critic网络更新参数采取软更新的方式： \\begin{array}{l} {w^{\\prime} \\leftarrow \\xi w+(1-\\xi ) w^{\\prime}} \\\\ {\\theta^{\\prime} \\leftarrow \\xi \\theta+(1-\\xi ) \\theta^{\\prime}} \\end{array}其中，更新系数$\\xi $为极小的数，如0.01。 最后，Critic网络的损失函数和DDQN一样，结合经验回放可以得到： J(w)=\\frac{1}{m} \\sum_{j=1}^{m}\\left(q_{j}-Q\\left(\\phi\\left(s_{j}\\right), a_{j}, w\\right)\\right)^{2}综上所述，DDPG算法可以写成如下流程： 输入：Actor当前网络，Actor目标网络，Critic当前网络，Critic目标网络,参数分别为$\\theta$、$\\theta’$、$w$、$w’$，衰减因子$\\gamma$，软更新系数$\\xi $,批量梯度下降的样本数$m$,目标网络参数更新频率$C$。最大迭代次数$T$，随机噪音函数$\\mathcal{N}$ 输出：最优Actor当前网络参数$\\theta$,Critic当前网络参数$w$ 1.随机初始化$\\theta$、$\\theta’=\\theta$、$w$、$w’=w$。清空经验回放的集合$D$ 2.for i from 1 to T，进行迭代。 （1）初始化$s$为当前状态序列的第一个状态，拿到其特征向量$\\phi(s)$ （2）在Actor当前网络基于状态$s$得到动作$a=\\pi_{\\theta}(s)+\\mathcal{N}$ （3）执行动作$a$，得到新状态$s’$，奖励$r$,是否终止状态$isend$ （4）将$\\{\\phi(s),a,r,\\phi(s’),isend \\}$这个五元组存入经验回放集合$D$ （5） $s=s’$ （6）从经验回放集合$D$中采样$m$个样本$\\{ \\phi(s_{j}),a_{j},r_{j},\\phi(s’_{j}),isend_{j}\\},j=1,2,…,m$ ，计算这些样本的目标$q_{j}$值： q_{j}=\\left\\{\\begin{array}{ll}{r_{j}} & {isend_{j} \\text { is true }} \\\\{r_{j}+\\gamma Q'\\left(\\phi\\left(s_{j}^{\\prime}\\right), a_{j}^{\\prime}, w'\\right)} & {isend_{j} \\text { is false }}\\end{array}\\right.（7）使用均方差损失函数$\\frac{1}{m} \\sum_{j=1}^{m}\\left(q_{j}-Q\\left(\\phi\\left(s_{j}\\right), a_{j}, w\\right)\\right)^{2}$，通过神经网络的梯度反向传播来更新Critic当前网络的所有参数$w$ （8）使用$J(\\theta)=-\\frac{1}{m} \\sum_{j=1}^{m} Q(s_{i}, a_{i}, w)$，通过神经网络的梯度反向传播来更新Actor当前网络的所有参数$\\theta$ （9）如果$T \\%C==1$,则更新Critic目标网络和Actor目标网络参数： \\begin{array}{l}{w^{\\prime} \\leftarrow \\xi w+(1-\\xi ) w^{\\prime}} \\\\{\\theta^{\\prime} \\leftarrow \\xi \\theta+(1-\\xi ) \\theta^{\\prime}}\\end{array}（10） 如果$s’$是终止状态，当前轮迭代完毕，否则转到步骤（2） 结语至此，深度强化学习介绍已经完结，更多的读书心得或许要在应用于工程学科之后才能分享了。","link":"/2020/02/12/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E4%BA%8E%E8%9E%8D%E5%90%88%E5%80%BC%E5%87%BD%E6%95%B0%E8%BF%91%E4%BC%BC%E5%92%8C%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%E7%9A%84%E6%96%B9%E6%B3%95/"},{"title":"灵飞经","text":"首页摘要： 学最抚媚的中国书法，品最惨淡的人生~","link":"/2018/06/14/%E7%81%B5%E9%A3%9E%E7%BB%8F/"},{"title":"生成对抗神经网络简介","text":"首页摘要： 最近投了一篇《基于改进CGAN的电力系统暂态稳定样本数据增强方法》，趁着和微软俱乐部小伙伴交流的机会简单做了一份PPT，记录学习心得。 生成对抗神经网络简介","link":"/2018/05/26/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E4%BB%8B/"},{"title":"电压稳定机理总结","text":"首页摘要： 在电力系统的研究中，通常认为功角稳定比电压稳定在机理的认识上更加成熟。出于对电压稳定机理的了解的目的，我查找了相关的资料并作了简单总结。 时期 研究特点 早期：70年代之前 电网规模小、无功充足，不容易造成电失稳，此时普遍利用$\\frac{dQ}{dU}$来进行判别 中期：70年代至80年代 此时开始出现电压失稳问题，但由于事故往往里初始故障的时间间隔较长，因此人们认为电压稳定属于静态范畴，主要的因素为无功不足。 目前 电压失稳和功角失稳是非线性动力学系统失稳的两种表现形式，两者是相互联系、相互影响的。在研究过程中要分析主要问题，于电压稳定现象中找到与其有关的影响因素。而电力系统是非线性动力系统，电压稳定本质上是动态过程，因此只有为电力系统保留动态特性才能真正解释电压失稳的发展机制。 目前在电压稳定研究领域仍然存在不足，主要体现在如下问题： （1）电压失稳的机理分析，包括辨析出影响电压稳定的关键因素以及回答电压失稳是如何发生的；（2）电压稳定的数学模型及方法；（3）电压稳定性指标；（4）电压稳定控制；（5）电压稳定和功角稳定的关系。 稳定性的定义及分类对比了IEEE和CIGRE两个工作组对稳定的分类后，我认为后者基于数学原理的分类更加容易接受，因此只在这篇博文中记录后者的分类情况：（1）静态稳定：指系统受到小扰动后不发生非周期性的功角稳定性，其物理特性是指与同步转矩相关的小扰动动态特性。我的理解是发生小干扰后能够回到稳定点。（2）小扰动动态稳定：指系统系统受到小扰动后不发生周期性失稳的功角稳定，其物理特性是指与阻尼转矩相关的小扰动动态稳定性。我的理解是静态稳定后不会发生周期性震荡。（3）暂态稳定：主要指系统受到大扰动后第一、二摇摆的稳定性，用于确定系统暂态稳定极限及稳定措施，其物理特性是指与同步转矩相关的暂态稳定性。我的理解是发生大干扰后能够到达新的平衡点（4）大扰动动态稳定：主要指系统受到大干扰后，在系统动态元件和控制转置的作用下，保持系统稳定性的能力，其物理特性是指与阻尼转矩相关的大扰动动态特性。我的理解是暂态稳定后，在平衡点附近不会发生周期性震荡。（5）频率稳定：是指电力系统发生突然的有功功率扰动后，系统频率能够保持或者恢复到允许的范围内，不发生频率崩溃的能力。（6）静态电压稳定：是指系统受到小干扰后，系统电压能够保持或恢复到允许的范围内，不发生电压崩溃的能力。（7）大扰动电压稳定：包括暂态电压稳定、动态电压稳定、中长期电压稳定，是指电力系统受到大干扰后，系统不发生电压崩溃的能力。暂态电压主要用于分析快速的崩溃问题，中长期电压稳定主要用于分析系统在响应较慢的动态元件和控制装置的作用下的电压稳定性，如有载调压器。 暂态电压失稳的影响因素在暂态电压是稳定的机理解释上，大部分是从电压稳定的定义出发，侧重于系统负荷及负荷元件的特性。事实上，除了一部分工业感应电动机负荷外，负荷并没有多少动态特性。很多解释很少涉及到系统法发电机侧和网络输电侧的状态，这样割裂了电力系统的整体性，甚至不能肯定符合节点电压的恶化是否与发电机功角趋于失稳有关，致使某些解释难以说明暂态电压稳定和暂态功角稳定的关系。具体而言，暂态电压稳定主要与输电网络输电能力极限、负荷动态特性（主要是感应电动机）以及首端系统电压支撑（发电机失磁或跳闸、并联电容器、HVDC）有关。 中长期电压失稳影响因素中长期电压失稳的情况不一样的是考虑到多次连续故障的影响，由于动态元件的特性造成前一次故障的冲击影响到后一次故障的发展过程，进而造成电压失稳。主要和它有关的因素为：发电机过励限制、有载调压变压器动作特性、负荷的功率恢复特性，这里研究的是电压失稳的慢过程中发生的一些变化。","link":"/2019/03/22/%E7%94%B5%E5%8E%8B%E7%A8%B3%E5%AE%9A%E6%9C%BA%E7%90%86%E6%80%BB%E7%BB%93/"},{"title":"电力系统暂态稳定评估最优特征子集求解方法","text":"首页摘要： 这篇博文单纯介绍考虑信息缺失的电力系统暂态稳定评估中的最优特征子集求解方法，也是其中最关键的方法。初衷是建立0-1整数非线性优模型来求解最优特征子集，在经历半个月的苦苦思索之后未能成功搭建考虑零注入节点的最优特征子集保证电网全局可观性求解方法，这个问题暂且搁置一边，留待日后解决。现在搭建的模型是基于遗传算法的最优特征子集求解模型（考虑了零注入节点）和0-1整数非线性优化模型（不考虑零注入节点）。具体内容见正文。","link":"/2018/12/19/%E7%94%B5%E5%8A%9B%E7%B3%BB%E7%BB%9F%E6%9A%82%E6%80%81%E7%A8%B3%E5%AE%9A%E8%AF%84%E4%BC%B0%E6%9C%80%E4%BC%98%E7%89%B9%E5%BE%81%E5%AD%90%E9%9B%86%E6%B1%82%E8%A7%A3%E6%96%B9%E6%B3%95/"},{"title":"电网调度监控大数据关联分析模块","text":"首页摘要： 项目马上接近尾声，现学现卖总算把软件写完了，总结一下在搭建软件过程中的一些心得。首先介绍电网调度监控大数据关联模块，然后介绍Pycharm+PyQt5的配置及使用过程，最后介绍在搭建软件过程中解决的问题。 电网调度监控大数据关联分析模块介绍大数据关联分析模块是采用Python在PYQT5上的软件平台上开发的，主要包括状态监测和大数据关联分析程序两大块内容，其中数据配置程序是整个模块的基础。数据配置程序最初的数据是在D5000平台中获取，其中包括变压器状态监测数据、变电站保护信号数据等，通过数据配置程序对所有的数据读取并保存在内存中供模块软件进行分析。在状态监测程序显示界面中，通过选择时间、设备、监测的物理量，确定在特定时刻需要监控的测量量曲线，进一步基于过去一年的数据（包括高压侧、低压侧电流）评估该变压器的运行状态及预测该变压器的剩余寿命。在大数据关联分析程序显示界面中，利用内存中提供的保护信息数据，以表格的形式展示保护信息在特定时间段的动作情况，进一步利用关联分析方法统计保护信号类型动作频率分布及保护信号动作时间分布。本模块是一套智能状态评估监控及关联分析软件，也是现有调度自动化系统的有益扩展。 软件框架 软件启动界面 变压器状态监测界面 保护动作信号关联分析界面Pycharm+PyQt5的配置及使用过程本来是按照我的电脑来说明，但是忘记带书在身边（这里安利一下《PyQt5快速开发与实践》这本书），所以就直接参考网上的博客来写，也可以直接借鉴https://blog.csdn.net/wangle_08/article/details/79235719。 在这里简单说一下，使用PyQt5的思路是利用QT designer设计窗体布局，其中一些控件实现的具体功能另外建立py文件进行设计，这也是它的一个优势。总的来说，PyQt5的使用方法和QT5几无二致。 第一步：打开cmd安装PyQt5 pip install pyqt5第二步：PyQt5不再提供Qt Designer等工具，所以需要再安装pyqt5-tools pip install pyqt5-tools第三步：打开Pycharm，进入设置，添加外部工具 第四步：添加QtDesigner，exe的路径在安装目录下C:\\Program Files\\Python35\\Lib\\site-packages\\pyqt5-tools\\designer.exe 第五步：设置“PyUIC” — 这个主要是用来将 Qt界面 转换成 py代码，在PyUIC的设置中，其他的都差不多，Program 写入Python的地址，Parameters写入： -m PyQt5.uic.pyuic $FileName$ -o $FileNameWithoutExtension$.py 第六步： 新建项目 第七步：使用designer，新建main window后，使用PyUIC将hello.ui文件转换为hello.py 第八步：添加main.py，因为ui文件命名为hello，所以import是hello 1234567891011import sysimport hellofrom PyQt5.QtWidgets import QApplication, QMainWindowif __name__ == '__main__': app = QApplication(sys.argv) MainWindow = QMainWindow() ui = hello.Ui_MainWindow() ui.setupUi(MainWindow) MainWindow.show() sys.exit(app.exec_()) 遇到的一些问题在打包所有的软件程序时，需要安装pyinstaller库，这个库使用起来存在一些问题，在这里记录下解决方法 1.Pyinstaller打包出现UnicodeDecodeError: ‘utf-8’ codec can’t decode byte 0xce in position 解决方案，这里主要是因为存在中文注释在打包的命令行中先输入chcp 65001 然后再输入打包命令：pyinstaller -F xxx.py 2.pyinstaller把Python打包成exe去掉黑窗doc窗口问题pyinstaller -F -w example.py 3.AttributeError: module ‘enum’ has no attribute ‘IntFlag’pip uninstall enum34","link":"/2018/10/24/%E7%94%B5%E7%BD%91%E8%B0%83%E5%BA%A6%E7%9B%91%E6%8E%A7%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90%E6%A8%A1%E5%9D%97%E8%BD%AF%E4%BB%B6%E4%BB%8B%E7%BB%8D/"},{"title":"谈谈未来的计划","text":"首页摘要： 当年明月写的《明朝那些事》最后一章是这么总结的：人一生最大的成功就是能够按照自己的方式去生活。有的人穷尽一生追名逐利，官至高位；有的人一生碌碌无为，毫无所成，最后都不免成为一堆尘土。我经常在想，如果生活毫无乐趣，就算再成功又有什么用呢？","link":"/2018/05/13/%E8%B0%88%E8%B0%88%E6%9C%AA%E6%9D%A5%E7%9A%84%E8%AE%A1%E5%88%92/"},{"title":"负荷热力图的绘制总结","text":"首页摘要： 最近接触的新项目是关于电力系统负荷特性分析的内容，本来觉得这些工作目前非常的成熟了，但是里面一个利用百度地图来画负荷热力图分布相关的内容比较感兴趣，查找网上相关资料发现百度的Echarts可以做相关的工作，为了灵活接口后续的工作，选择了pyecharts来编程实现。 相关库的安装配置安装pycharts库pip install pycharts pip install pyecharts_snapshot 安装地图包pip install echarts-countries-pypkgpip install echarts-china-provinces-pypkgpip install echarts-china-cities-pypkg pip install echarts-countries-pypkgpip install echarts-china-provinces-pypkgpip install echarts-china-cities-pypkg 实现代码12345678910111213141516171819202122232425262728293031# 加载pyechartsfrom pyecharts import Geo, Styleimport pandas as pd# 导入excel表举例df = pd.read_excel('220.xls')df.head()# 导入自定义的地点经纬度geo_cities_coords = {df.iloc[i]['变电站']: [df.iloc[i]['经度'], df.iloc[i]['纬度']] for i in range(len(df))} # 根据文件大小生成字典attr = list(df['变电站']) # 字典的每个键值value = list(df['负荷']) # 负荷值style = Style(title_color=&quot;#fff&quot;, title_pos=&quot;center&quot;, width=1000, height=800, background_color=&quot;#404a59&quot;)# 可视化geo = Geo('武汉负荷分布', **style.init_style)geo.add(&quot;&quot;, attr, value, visual_range=[min(value), max(value)], symbol_size=5, visual_text_color=&quot;#fff&quot;, is_piecewise=False, is_visualmap=False, maptype='武汉', geo_cities_coords=geo_cities_coords,border_color = '#fff')geo.add(&quot;&quot;, attr, value, visual_range=[min(value), max(value)], symbol_size=20,type = 'heatmap', visual_text_color=&quot;#fff&quot;, is_piecewise=False, is_visualmap=True, maptype='武汉', visual_split_number=10, geo_cities_coords=geo_cities_coords,border_color = '#fff')geo.render('武汉负荷分布.html')import osos.system(r'&quot;C:\\Users\\TanBendong\\AppData\\Local\\Google\\Chrome\\Application/chrome.exe&quot; 武汉负荷分布.html') # 通过浏览器自动打开 最终效果目前只是220KV变电站负荷的结果，可以看出大致的分布。但是需要进一步将110kv的负荷在地图上显示出来，这样会更加直观。","link":"/2019/03/10/%E8%B4%9F%E8%8D%B7%E7%83%AD%E5%8A%9B%E5%9B%BE%E7%9A%84%E7%BB%98%E5%88%B6%E6%80%BB%E7%BB%93/"},{"title":"电力系统暂态计算_时域仿真方法","text":"首页摘要： 被PSS/E折磨半个月，欲仙欲死的我终于来补充了=o= 主要从西门子的电力系统仿真软件PSS/E和时域仿真方法过程两大部分介绍。 PSS/E软件概述及关键使用点介绍PSS/E软件(Power System Simulator / Engineering) 是西门子开发的一款非常优秀的电力系统仿真软件，它支持的功能包括：潮流计算、最优潮流、短路计算、静态等值以及动态等值、机电暂态计算等，它的优秀不在于支持的这些功能，而是它提供了极其丰富变态的API接口，计算速度更不必说，快上MATLAB不止一个级别，同一个程序我用MATLAB计算超过一天，而PSS/E只需要10分钟左右。不论你是想要实现程序自动化还是自定义模型，它都是电力系统仿真居家必备的良品，用一句话描述——只要你能想到怎么实现，它就能做到！相比BPA、PSASP等这些计算速度快但是操作不友好的国产软件，它就是集计算速度快、功能丰富、使用灵活的男神！这里使用灵活是说它可以用window的批处理命令、Fortran、Python等程序与其接口，因此非常方便，当然德国的Digsilent、加拿大的DSAtools也具备类似的功能，PSS/E和DIGSILENT、DSAtools各具优势，在此不作评判。 在这里不多介绍它的具体功能，有需要的自己去啃上万页的英文手册吧！反正我看着这些奇怪的英文词汇，多少次在深夜痛哭。主要介绍它的部分我们经常能用到的基本文件。 这里需要说明的是，PSS/E同一种功能之所以要定义两种格式，自有其道理，具体说明可以参照文档《Program operation manual》2.3.2节，简单来说，raw文件可以保存成sav文件，dyr文件可以保存成snp文件，看其文件类型就知道，根据《Program operation manual》的解释。raw文件和dyr文件可以用文本编辑因此适合和人类交互数据，PSS/E在计算的时候是先将他们转换成PSS/E能够处理的二进制格式也就是sav文件和snp文件，再导入内存，这样做的初衷是节省内存以及方便操作，因为每次导入sav文件和snp都会刷新内存，内存只保存最新一次的sav文件和snp文件，如果读者进行多次暂态计算就知道这样做的好处了（说多了都是泪！） 使用PSS/E的关键就是读帮助文档，因为网上关于PSS/E的资料非常之少，只能靠自己去摸索了。 电力系统时域仿真方法时域仿真方法简单来说就是利用潮流计算的结果作为初值给动态微分和静态代数方程进行数值求解。 动态微分方程组包括(1)各同步发电机暂态、次暂态电势变化规律;(2)同步发电机转子方程;(3)同步发电机励磁调节系统动态特性;(4)同步发电机原动机及其调速系统动态特性;(5)各感应电动机和同步电动机负荷动态特性:(6)直流系统整流器和逆变器控制行为；(7)其他动态装置，如FACTS。 静态代数方程组包括(1)电力网络方程;(2)各同步发电机钉子电压方程及D-Q坐标系与直角坐标系之间的坐标转换方程;(3)各直流线路的电压方程;(4)负荷的电压静态特性方程 具体过程如下：假设在t+s时刻发生故障，t时刻提供微分方程的初值 (1)首先对t时刻的发电机进行诺顿等值，计算出每个发电机节点的注入电流，每个负荷计算出它的等效导纳,进而计算出网络节点电压(因为网络导纳是确定的，自然根据注入电流可以确定网络节点电压)，这样就形成了网络初值x(0)，,需要注意的是发电机功角的计算方法是按照下面的公式来进行计算的： (2)接着我们计算状态量在t时刻的导数，状态量包括发电机功角、角速度和电动机负荷的转差。 这样就可以计算下一个时刻的状态量值 (3)根据下一时刻的状态量值就可以计算出发电机注入电流和网络节点电压，如此交替进行就能够对整个过程进行计算。 总结这里面还有一些诸如facts等控制设备在计算潮流、动态特性未能解释，以后完善","link":"/2018/06/13/%E7%94%B5%E5%8A%9B%E7%B3%BB%E7%BB%9F%E6%9A%82%E6%80%81%E8%AE%A1%E7%AE%97_%E6%97%B6%E5%9F%9F%E4%BB%BF%E7%9C%9F%E6%96%B9%E6%B3%95/"},{"title":"临帖每日记录(持续更新)","text":"首页摘要： 练字日常，最爱把硬笔写成软笔。 2020.09.06更：字帖已临摹完，要开始写作品了哈哈，从今日起不再更新此帖，另开新帖。 2020年2月1日 2020年2月2日 2020年2月4日 2020年2月6日 2020年2月7日 2020年2月8日 2020年2月9日 2020年2月10日 2020年2月11日 2020年2月12日 2020年2月13日 2020年2月14日 2020年2月15日 2020年2月16日 2020年2月17日 2020年2月18日 2020年2月19日 2020年2月20日 2020年2月21日 2020年2月22日 2020年2月23日 2020年2月24日 2020年2月25日 2020年2月26日 2020年2月27日 2020年2月28日 2020年2月29日 2020年3月1日 2020年3月2日 2020年3月3日 2020年3月4日 2020年3月8日 2020年3月9日 2020年3月10日 2020年3月12日 2020年3月14日 2020年3月16日 2020年3月17日 2020年3月18日 2020年3月19日 2020年3月20日 2020年3月21日 2020年3月22日 2020年3月23日 2020年3月24日 2020年3月25日 2020年3月26日 2020年3月27日 2020年3月29日 2020年3月30日 2020年3月31日 2020年4月1日 2020年4月2日 2020年4月3日 2020年4月4日 2020年4月5日 2020年4月6日 从这里开始纠正握笔姿势，坚持！ 2020年4月8日 2020年4月9日 2020年4月14日 2020年4月15日 2020年4月17日 2020年4月18日 2020年4月20日 2020年4月21日 2020年4月22日 2020年4月23日 2020年4月24日 2020年4月25日 2020年4月26日 2020年4月27日 2020年4月28日 2020年4月29日 2020年4月30日 今日感悟：用笔之道在于轻盈，类似画画。这可能是练字以来的一个里程碑 2020年5月1日 2020年5月2日 2020年5月3日 2020年5月6日 2020年5月7日 2020年5月8日 2020年5月9日 2020年5月10日 2020年5月11日 2020年5月12日 2020年5月13日 2020年5月14日 2020年5月15日 2020年5月16日 2020年5月17日 2020年5月18日 2020年5月19日 2020年5月20日 2020年5月22日 2020年5月26日 2020年5月27日 2020年6月11日 2020年6月14日 2020年6月17日 2020年6月21日 2020年6月22日 2020年6月23日 2020年6月24日 2020年6月26日 2020年6月27日 2020年6月30日 2020年7月01日 2020年7月02日 2020年7月03日 2020年7月05日 2020年7月06日 2020年7月07日 2020年7月08日 2020年7月09日 2020年7月10日 2020年7月11日 2020年7月13日 2020年7月14日 2020年7月15日 2020年7月16日 2020年7月17日 2020年7月18日 2020年7月19日 2020年7月20日 2020年7月21日 2020年7月22日 2020年7月23日 2020年7月24日 2020年7月25日 2020年7月26日 2020年7月27日 2020年7月28日 2020年7月29日 2020年7月30日 2020年7月31日 2020年8月01日 2020年8月02日 2020年8月03日 2020年8月04日 2020年8月05日 2020年8月06日 2020年8月07日 2020年8月08日 2020年8月09日 2020年8月10日 2020年8月11日 2020年8月12日 2020年8月13日 2020年8月14日 2020年8月15日 2020年8月16日 2020年8月17日 2020年8月18日 2020年8月19日 2020年8月20日 2020年8月21日 2020年8月22日 2020年8月23日 2020年8月24日 2020年8月25日 2020年8月26日 2020年8月27日 2020年8月28日 2020年8月29日 2020年8月30日 2020年8月31日 2020年9月04日 2020年9月05日 2020年9月06日","link":"/2020/09/06/%E7%BB%83%E5%AD%97%E6%89%93%E5%8D%A1/"},{"title":"阅读、总结、整理文献小记","text":"首页摘要： 总算把主要的工作完成了，虽然做不到三日深省吾身，争取有空就多思考、多总结。以前看论文没有形成好习惯，所有论文都下在一个文件夹，未能及时归纳整理。现在开始下决心改掉这个习惯，做到对研究方向的精彩论文精读、研究领域的一般论文及非研究领域的论文略读，及时总结归纳。 非研究领域论文阅读看完后思考：作者讲了一个什么样的故事？提出了什么问题？用了什么方法来解决？限制条件在哪里？同样的问题能不能用别的方法来解决或者这个方法能不能推广到其它地方去？ 研究领域高水平论文阅读1.阅读及总结文献的过程（1）要解决的问题是什么？ （2）如果换了自己会怎么做？ （3）看别人是如何做的，解决的如何？具体而言，可以问自己几个问题：如果用一句话来概括这篇文章这篇文章到底想告诉我们什么该怎么讲？这篇文章好在哪（创新点在哪，没有这篇文章会怎么样）？ （4）这篇文章可能对自己将来的研究有什么帮助，何有不足，可能的新方案等。 2.整理文献 列1 列2 列3 列4 列5 类别 文章题目 文章总结（阅读论文中的几点） 创新点 有何不足；有何假设；可能的方案 创建excel按照上面表格的形式对阅读的文献记录总结。此外对论文中好的起承转合的英语句子摘抄、模仿。 如何产生新的idea？（1） 第一种弥补缺陷法。即去发现别人论文中的weakness（缺陷）。你在读很多个论文时候，就会逐渐发现，每一篇论文都不是完美的，解决的都是某一方面的问题。很多论文，尤其是经典论，都有很多论文跟着去提高和改善原来论文的效率、方法什么的。因此，你可以根据这个特点，去找你感兴趣的论文的weakness，你提出相应的弥补缺陷的解决方案； （2）第二种新型方案法。就是提出与论文不同的解决方案，你觉得你在性能、方法、效益等方面有新的方法，那就产生了新的idea，不断地磨合，修正，完善你的idea，就慢慢成为一篇比较好的论文； （3） 第三种减少约束法。即减少论文中的assumption（假设），一般来说，所有的假设都是约束条件，去除约束条件就是形成新的方法的过程。 这三种方法是比较简单的、操作性比较强的方法，比较有针对性的产生idea，避免看论文中的茫然状态。值得注意的是，在产生idea过程中，不要想着憋大的idea，不要试图完全推翻或者建立自己的体系。在目前阶段，对大多数人来说，这是不可能的。好高骛远，往往会半途而废。有一点点的贡献就好。没有一篇论文是完美的，而任何人的工作都必须在其他人工作基础上进行的。 后记做了总结就希望能够坚持下去，加油！","link":"/2019/03/16/%E9%98%85%E8%AF%BB%E3%80%81%E6%80%BB%E7%BB%93%E3%80%81%E6%95%B4%E7%90%86%E6%96%87%E7%8C%AE%E5%B0%8F%E8%AE%B0/"},{"title":"随记","text":"您好！这篇博文需要密码，输入正确密码后回车即可阅读。 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","link":"/2020/08/04/%E9%9A%8F%E8%AE%B0/"},{"title":"重要性采样理解","text":"首页摘要： 以前一直不能理解为什么特定分布可以通过均匀分布来进行采样，今天突然就想通了。俗语说得好，文章本天成，“妙手”偶得之。 为什么需要采样采样是机器学习中，特别是生成模型中经常采用的一种技术。为什么要采样呢？因为很多时候我们需要获取的期望很难求得解析式时，利用蒙特卡洛模拟来近似求解是一种非常方便有效的方法。例如对于一个特定的服从$p(x)$分布的函数$f(x)$而言，其期望可以表示为： E(x)=\\int f(x)p(x)dx,x \\sim p(x)对于复杂的$f(x)$或者$p(x)$而言，几无可能求出期望的表达式，这个时候就可以利用蒙特卡洛近似求解了： E(x)\\approx\\frac{1}{N} \\sum_{i=1}^{N}f(x_i),x_i \\sim p(x_i)也就是说，蒙特卡洛是从分布$p(x)$中采样到大量样本取平均来进行近似的，这里涉及到一个问题：如何从$p(x)$进行采样。要知道，计算机只能模拟均匀分布，一旦$p(x)$不是均匀分布就需要另寻他途进行模拟了。事实上，聪明的前人找到了如何基于均匀分布对复杂的$p(x)$进行采样。对于可逆的分布而言，可以利用可逆采样(inverse sampling)来进行采样。 可逆采样假设$p(x)$的累积分布函数为： y=F(x)=\\int_{-\\infty}^{x}p(x)dx那么 $y \\in [0,1]$, $x \\in [- \\infty ,+\\infty]$，其逆分布为 $x=F^{-1}(y)$ 。 定义在区间 $[0,1]$ 上的均匀分布可以用 U(0,1)=P(x)=\\begin{cases} 1 & 0","link":"/2019/03/25/%E9%87%8D%E8%A6%81%E6%80%A7%E9%87%87%E6%A0%B7%E7%90%86%E8%A7%A3/"}],"tags":[{"name":"计划","slug":"计划","link":"/tags/%E8%AE%A1%E5%88%92/"},{"name":"总结","slug":"总结","link":"/tags/%E6%80%BB%E7%BB%93/"},{"name":"TSA","slug":"TSA","link":"/tags/TSA/"},{"name":"智能电网","slug":"智能电网","link":"/tags/%E6%99%BA%E8%83%BD%E7%94%B5%E7%BD%91/"},{"name":"机器学习","slug":"机器学习","link":"/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"博客","slug":"博客","link":"/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"latex","slug":"latex","link":"/tags/latex/"},{"name":"电力系统稳定与控制","slug":"电力系统稳定与控制","link":"/tags/%E7%94%B5%E5%8A%9B%E7%B3%BB%E7%BB%9F%E7%A8%B3%E5%AE%9A%E4%B8%8E%E6%8E%A7%E5%88%B6/"},{"name":"书法","slug":"书法","link":"/tags/%E4%B9%A6%E6%B3%95/"},{"name":"人工智能","slug":"人工智能","link":"/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"凸优化","slug":"凸优化","link":"/tags/%E5%87%B8%E4%BC%98%E5%8C%96/"},{"name":"感悟","slug":"感悟","link":"/tags/%E6%84%9F%E6%82%9F/"},{"name":"强化学习","slug":"强化学习","link":"/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"},{"name":"读后感","slug":"读后感","link":"/tags/%E8%AF%BB%E5%90%8E%E6%84%9F/"},{"name":"旅游","slug":"旅游","link":"/tags/%E6%97%85%E6%B8%B8/"},{"name":"学术活动","slug":"学术活动","link":"/tags/%E5%AD%A6%E6%9C%AF%E6%B4%BB%E5%8A%A8/"},{"name":"优化","slug":"优化","link":"/tags/%E4%BC%98%E5%8C%96/"},{"name":"广域测量系统","slug":"广域测量系统","link":"/tags/%E5%B9%BF%E5%9F%9F%E6%B5%8B%E9%87%8F%E7%B3%BB%E7%BB%9F/"},{"name":"软件","slug":"软件","link":"/tags/%E8%BD%AF%E4%BB%B6/"}],"categories":[{"name":"生活随笔","slug":"生活随笔","link":"/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E7%AC%94/"},{"name":"电力系统","slug":"电力系统","link":"/categories/%E7%94%B5%E5%8A%9B%E7%B3%BB%E7%BB%9F/"},{"name":"各类教程","slug":"各类教程","link":"/categories/%E5%90%84%E7%B1%BB%E6%95%99%E7%A8%8B/"},{"name":"机器学习","slug":"机器学习","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"优化","slug":"优化","link":"/categories/%E4%BC%98%E5%8C%96/"}]}